<html>
<head>
<title>Find Unauthorized Constructions Using Aerial Photography and Deep Learning with Code (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ä½¿ç”¨èˆªæ‹å’Œä»£ç æ·±åº¦å­¦ä¹ å‘ç°æœªç»æˆæƒçš„å»ºç­‘(ç¬¬2éƒ¨åˆ†)</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://pub.towardsai.net/find-unauthorized-constructions-using-aerial-photography-and-deep-learning-with-code-part-2-b56ca80c8c99?source=collection_archive---------1-----------------------#2021-01-15">https://pub.towardsai.net/find-unauthorized-constructions-using-aerial-photography-and-deep-learning-with-code-part-2-b56ca80c8c99?source=collection_archive---------1-----------------------#2021-01-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a9e2" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/machine-learning/deep-learning" rel="noopener ugc nofollow" target="_blank">æ·±åº¦å­¦ä¹ </a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/89af5a16ca9d5ff982a63b4ae8c3bff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QG4F0YMSOjQlNYFoZ0NEvQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">æˆ‘ä»¬æ¢æµ‹å™¨çš„æœ€ç»ˆç»“æœ(å›¾ç‰‡ç”±ä½œè€…æä¾›)</figcaption></figure></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="a287" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated"><strong class="ak">ç›®å½•</strong></h1><p id="bec3" class="pw-post-body-paragraph lq lr iq ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">1.<a class="ae mo" href="#9407" rel="noopener ugc nofollow">ç®€ä»‹</a> <br/> 2ã€‚<a class="ae mo" href="#ddaa" rel="noopener ugc nofollow">è¯¦ç»†é¡¹ç›®å·¥ä½œæµç¨‹</a> <br/> 3ã€‚<a class="ae mo" href="#d11d" rel="noopener ugc nofollow"> U-Netåˆ†å‰²æ¨¡å‹</a> <br/> 4ã€‚<a class="ae mo" href="#b20d" rel="noopener ugc nofollow">ç»“æœ</a> <br/> 5ã€‚<a class="ae mo" href="#19d2" rel="noopener ugc nofollow">èµ„æºå’Œä½œè€…</a></p></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="9407" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">ä»‹ç»</h1><p id="0e01" class="pw-post-body-paragraph lq lr iq ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">è¿™ä¸ªé¡¹ç›®æ—¨åœ¨å¯»æ‰¾ç¼ºä¹å»ºç­‘è®¸å¯çš„æ½œåœ¨å»ºç­‘ã€‚åœ¨æˆ‘ä»¬çš„<a class="ae mo" href="https://zieniewicz-m-1992.medium.com/find-unauthorized-constructions-using-aerial-photography-and-deep-learning-with-code-part-1-6d3ca7ff6fa0" rel="noopener"> <strong class="ls ja">ä¸Šä¸€ç¯‡</strong> </a>ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†é—®é¢˜é™ˆè¿°ä»¥åŠæ”¶é›†å’Œé¢„å¤„ç†æ•°æ®çš„è¿‡ç¨‹ã€‚ç°åœ¨ï¼Œæœ‰äº†50ï¼Œ000å¤šå¼ æ­£å°„å½±åƒå’Œç›¸åº”çš„æ©è†œï¼Œæˆ‘ä»¬å¯ä»¥ä¸“æ³¨äºé¡¹ç›®çš„ç¬¬äºŒé˜¶æ®µâ€”â€”è¯†åˆ«å»ºç­‘ç‰©çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹ã€‚</p><p id="e1e9" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">è¦ç†è§£è¿™ä¸ªè¿‡ç¨‹ï¼Œæ‚¨åº”è¯¥ç†Ÿæ‚‰åœ¨Kerasä¸­åˆ›å»ºæ·±å±‚ç½‘ç»œçš„åŸºç¡€çŸ¥è¯†å’ŒPythonä¸­çš„ç®€å•æ•°æ®æ“ä½œæŠ€æœ¯ã€‚</p><p id="7004" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">ç”±äºæˆ‘ä»¬å¸Œæœ›åœ¨é€æ˜åº¦å’Œéšç§ä¹‹é—´åšå‡ºæƒè¡¡ï¼Œæˆ‘ä»¬å†³å®šä¸å…¬å¸ƒæˆ‘ä»¬çš„æ•°æ®é›†ã€‚è¯·å°è¯•ä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•å’Œå‰ä¸€ç¯‡æ–‡ç« ä¸­æä¾›çš„ä»£ç ï¼Œå¹¶è‡ªè¡Œæ”¶é›†ã€‚</p><p id="afb7" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">æ‚¨å¯ä»¥åœ¨å‚è€ƒèµ„æ–™å’Œä½œè€…éƒ¨åˆ†æ‰¾åˆ°å®˜æ–¹ç¬”è®°æœ¬çš„é“¾æ¥ã€‚</p><figure class="mv mw mx my gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi mu"><img src="../Images/e4ee6c473d8873e36b1cc91b8fadbb25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpPtye1gqAyvmtK-19ibzQ.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">é¡¹ç›®æµç¨‹å›¾(å›¾ç‰‡ç”±ä½œè€…æä¾›)</figcaption></figure></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="ddaa" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated"><strong class="ak">è¯¦ç»†çš„é¡¹ç›®å·¥ä½œæµç¨‹</strong></h1><p id="b292" class="pw-post-body-paragraph lq lr iq ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">æˆ‘ä»¬å°†å°è¯•ä»¥ç®€å•çš„æ–¹å¼æŒ‡å¯¼æ‚¨å®Œæˆè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å„ä¸ªé˜¶æ®µï¼ŒåŒ…æ‹¬:</p><ul class=""><li id="5af8" class="mz na iq ls b lt mp lx mq mb nb mf nc mj nd mn ne nf ng nh bi translated">å°†æ•°æ®é›†åˆ†æˆè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶ä½¿ç”¨åŸºæœ¬çš„æ•°æ®æ‰©å……æŠ€æœ¯åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨ï¼Œ</li><li id="bbe6" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">ä¸ºæˆ‘ä»¬çš„æ¨¡å‹çš„è´¨é‡æ§åˆ¶åˆ›å»ºä¸€ä¸ªå®šåˆ¶çš„åº¦é‡ï¼Œå¹¶ä¸ºä¿å­˜å­¦ä¹ æ›²çº¿çš„å†å²åˆ›å»ºä¸€ä¸ªå®šåˆ¶çš„å›è°ƒï¼Œ</li><li id="99d9" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">ä½¿ç”¨Kerasåˆ›å»ºæ¨¡å‹æ¶æ„å¹¶è®­ç»ƒå®ƒï¼Œ</li><li id="9487" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">ä½¿ç”¨å›è°ƒä¼˜åŒ–åŸ¹è®­è¿‡ç¨‹å¹¶å®æ—¶æ˜¾ç¤ºè¿›åº¦ï¼Œ</li><li id="9dc3" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">å¯¹æµ‹è¯•é›†çš„è¯„ä¼°ï¼Œ</li><li id="5527" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹ç»“æœã€‚</li></ul><p id="ee96" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">æ‰€ä»¥â€¦è®©æˆ‘ä»¬æŠŠæ‰‹å¼„è„å§ã€‚:)</p></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="d11d" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated"><strong class="ak"> U-Netåˆ†å‰²æ¨¡å‹</strong></h1><p id="67c8" class="pw-post-body-paragraph lq lr iq ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬å°†èŠ±ä¸€ç‚¹æ—¶é—´å…³æ³¨è¯­ä¹‰åˆ†å‰²çš„æ¦‚å¿µã€‚è¿™ç§æ–¹æ³•åŒ…æ‹¬ä¸ºæ¯ä¸ªåƒç´ åˆ†é…ä¸€ä¸ªç‰¹å®šç±»åˆ«å­˜åœ¨çš„æ¦‚ç‡å€¼(èŒƒå›´ä»0åˆ°1)ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯â€œå»ºç­‘ç‰©â€ç±»åˆ«ã€‚</p><p id="f9f0" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹å°†åœ¨è®­ç»ƒæœŸé—´å°†æ­£å°„å½±åƒä½œä¸ºè¾“å…¥ï¼Œè€Œè¾“å‡ºå°†æ˜¯å…·æœ‰ç›¸åŒé«˜åº¦å’Œå®½åº¦çš„2DçŸ©é˜µï¼Œæ¯ä¸ªåƒç´ å…·æœ‰ç‰¹å®šç±»åˆ«çš„æ¦‚ç‡å€¼(0æˆ–1)ã€‚ç”±äºè¿™ç§è§£å†³æ–¹æ¡ˆï¼Œç¥ç»ç½‘ç»œå­¦ä¼šäº†å¦‚ä½•å°†å›¾åƒè½¬æ¢ä¸ºåŒ…å«æ‰€éœ€ç±»åˆ«å’ŒèƒŒæ™¯çš„é®ç½©ã€‚</p><p id="4406" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">äº‹å®è¯æ˜ï¼Œç¼–ç å™¨-è§£ç å™¨æ·±åº¦ç¥ç»ç½‘ç»œéå¸¸é€‚åˆè¿™é¡¹ä»»åŠ¡ï¼Œå› ä¸ºå®ƒä»¬é¦–å…ˆè¯•å›¾è¯†åˆ«ç…§ç‰‡ä¸­ä»»ä½•å»ºç­‘ç‰©çš„ç‰¹å¾ï¼Œç„¶åå°†å®ƒä»¬è§£ç åˆ°å…·æœ‰ç»™å®šç±»åˆ«æ¦‚ç‡å€¼çš„æ©æ¨¡ä¸Šã€‚åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨U-Netæ¶æ„ï¼Œè¯¥æ¶æ„æœ€åˆäº2015å¹´æå‡ºï¼Œç”¨äºåŒ»å­¦å›¾åƒçš„åˆ†å‰²ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œ  <strong class="ls ja"> </strong>æ‰¾åˆ°ä¸€ç¯‡å…³äºä¼˜ä¿¡ç½‘çš„ä¼˜ç§€æ–‡ç« <a class="ae mo" href="https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47" rel="noopener" target="_blank"> <strong class="ls ja">(æˆ‘ä»¬å‘ç°å®ƒéå¸¸æœ‰ç”¨)ï¼ŒåŒæ—¶æˆ‘ä»¬ä¸“æ³¨äºè§£å†³æˆ‘ä»¬é—®é¢˜çš„å®ç”¨æ–¹æ³•ã€‚</strong></a></p><figure class="mv mw mx my gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nn"><img src="../Images/9e0849f5f1da0e1f142b413a6a520959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DSLfJXPbHgEeeOgs"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">U-Netæ¨¡å‹æ¶æ„(æ¥æº:å®˜æ–¹U-Net <a class="ae mo" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank">å‡ºç‰ˆç‰©</a>)</figcaption></figure><p id="3969" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥æ‰€éœ€çš„å·¥å…·ï¼Œå°¤å…¶æ˜¯æ¥è‡ªKerasçš„å„ç§å…ƒç´ ï¼Œå®ƒä»¬å°†ç”¨äºåˆ›å»ºæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<a class="ae mo" href="https://p.migdal.pl/livelossplot/" rel="noopener ugc nofollow" target="_blank"> <strong class="ls ja"> livelossplot </strong> </a>æ¥å¯è§†åŒ–æ¯ä¸ªæ—¶æœŸåçš„å­¦ä¹ æ›²çº¿ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="3cd4" class="nt kt iq np b gy nu nv l nw nx">import os<br/>import random<br/>from datetime import datetime<br/><br/>import numpy as np<br/>import pandas as pd<br/><br/>import matplotlib.pyplot as plt<br/>from tqdm import tqdm<br/>from sklearn.model_selection import train_test_split<br/>from skimage.transform import rotate<br/>from tensorflow import keras<br/><br/>from tensorflow.keras.models import Model, load_model<br/>from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, MaxPooling2D, GlobalMaxPool2D, Conv2D, Conv2DTranspose<br/>from tensorflow.keras.layers import concatenate, add<br/>from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img<br/>from tensorflow.keras.metrics import Recall, Precision<br/><br/>import keras.backend as K<br/><br/>from livelossplot import PlotLossesKeras</span></pre><p id="934c" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è®¾ç½®ä»¥ä¸‹å‚æ•°:å¸¦æœ‰ç…§ç‰‡å’Œè’™ç‰ˆçš„ç›®å½•çš„è·¯å¾„ã€å›¾åƒå½¢çŠ¶ã€è®­ç»ƒæ—¶æœŸçš„æ•°é‡å’Œæ‰¹é‡å¤§å°ã€‚æˆ‘ä»¬å»ºè®®çš„è®¾ç½®é€‚åº”å…è´¹çš„Google Colabè®¾ç½®çš„èƒ½åŠ›ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="56ca" class="nt kt iq np b gy nu nv l nw nx"># images attributes <br/>img size = 256 <br/> <br/># training attributes<br/>batch_size = 64<br/>epochs = 50<br/> <br/># data paths<br/>project_path ="./"<br/>orto path = "data/geoportal orto/"<br/>masks_path = project_path + "data/geoportal_build_mask/"<br/>test_orto_path = project_path + "test/geoportal_orto/"<br/>test_masks_path = project_path + "test/geoportal_build_mask/"</span></pre><p id="51c9" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">åœ¨è®­ç»ƒä¹‹å‰ï¼Œè®©æˆ‘ä»¬å°†æ•´ä¸ªæ•°æ®é›†åˆ†æˆä¸€ä¸ªè®­ç»ƒé›†å’Œä¸€ä¸ªéªŒè¯é›†ã€‚åœ¨æ•°æ®æ”¶é›†é˜¶æ®µï¼Œæµ‹è¯•é›†è¢«åˆ†ç¦»ä¸ºä¸€ä¸ªé€‰å®šåŸå¸‚çš„ä¸€ç»„å›¾åƒå’Œè’™ç‰ˆã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="22a9" class="nt kt iq np b gy nu nv l nw nx"># list of names of all images in the given path<br/>ids = sorted(os.listdir(orto_path))<br/>test_ids = sorted(os.listdir(test_orto_path))<br/><br/># split train and valid<br/>ids_train, ids_valid = train_test_split(ids, test_size=0.2, random_state=123)<br/><br/>print("Total images = ", len(ids))<br/>print("Train images = ", len(ids_train))<br/>print("Valid images = ", len(ids_valid))<br/>print("Test images = ", len(test_ids))</span></pre><figure class="mv mw mx my gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ny"><img src="../Images/d3eedf08c4d271e3d88382bc2089e89e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7fkXVCqnd6h2RfY5tSsGEQ.png"/></div></div></figure><p id="dd71" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">ç°åœ¨ï¼Œæˆ‘ä»¬å°†ç€é‡äºåˆ›å»ºä¸€ä¸ªå…·æœ‰ç®€å•æ‰©å……(æ—‹è½¬90åº¦å€æ•°)çš„æ•°æ®ç”Ÿæˆå™¨ã€‚å¯å®šåˆ¶çš„<strong class="ls ja"> </strong>æ•°æ®ç”Ÿæˆå™¨å¸®åŠ©æˆ‘ä»¬åŠ¨æ€åœ°å°†ä¸€æ‰¹ç…§ç‰‡å’Œè’™ç‰ˆåŠ è½½åˆ°æ¨¡å‹ä¸­ï¼Œå¹¶ä¸”æ ¹æ®æˆ‘ä»¬æ˜¯å¦éœ€è¦ï¼Œä½¿ç”¨å¯é€‰çš„<strong class="ls ja"> rotate_image() </strong>å‡½æ•°ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨æ•°æ®æ‰©å……è¿›è¡ŒéªŒè¯å’Œæµ‹è¯•ã€‚å¦‚æœæ‚¨éœ€è¦å¯¹æ‚¨çš„å›¾åƒé›†è¿›è¡Œæ›´é«˜çº§çš„å¢å¼ºï¼ŒKeraså†…ç½®çš„ImageDataGeneratoræ˜¯ä¸€ç§æ–¹æ³•ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="7bfa" class="nt kt iq np b gy nu nv l nw nx">def rotate_image(image, angle=180):<br/>    """Optional augumentation"""<br/>    return rotate(image, angle, resize=True, preserve_range=True)<br/><br/><br/>def data_gen(img_folder, mask_folder, img_ids, img_size, batch_size, random_rotate=True):<br/>    """Function for data generator"""<br/>    c = 0<br/>    random.shuffle(img_ids)<br/><br/>    while True:<br/><br/>        img = np.zeros((batch_size, img_size, img_size, 3)).astype(float)<br/>        mask = np.zeros((batch_size, img_size, img_size, 1)).astype(float)<br/><br/>        for i in range(c, c+batch_size): # initially from 0 to 64, c = 0. <br/><br/>            # load image    <br/>            img_data = img_to_array(load_img(img_folder+img_ids[i]))/255.0<br/>            <br/>            <br/>            # load mask<br/>            img_mask = img_to_array(load_img(mask_folder+img_ids[i], color_mode="grayscale"))<br/>            img_mask = (img_mask &gt; img_mask.min()).astype(int)<br/>            # add extra dimension for parity with train_img size [img_size * img_size * 3]<br/>            img_mask = img_mask.reshape(img_size, img_size, 1)<br/>            <br/>            if random_rotate:<br/>                rotate_angle = random.choice((0, 90, 180, 270))<br/>                img_data = rotate_image(img_data, rotate_angle)<br/>                img_mask = rotate_image(img_mask, rotate_angle)             <br/>            <br/>            # add to array - img[0], img[1], and so on.<br/>            img[i-c] = img_data <br/>            mask[i-c] = img_mask<br/><br/>        c += batch_size<br/>        if c+batch_size &gt;= len(img_ids):<br/>            c=0<br/>            random.shuffle(img_ids)<br/><br/>        yield img, mask<br/><br/># preparing data generators<br/>train_gen = data_gen(orto_path, masks_path, ids_train, img_size, batch_size, random_rotate=True)<br/>valid_gen = data_gen(orto_path, masks_path, ids_valid, img_size, batch_size, random_rotate=False)<br/>test_gen = data_gen(test_orto_path, test_masks_path, test_ids, img_size, batch_size, random_rotate=False)</span></pre><p id="0f94" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">æœ€åï¼Œè®©æˆ‘ä»¬åˆ›å»ºæˆ‘ä»¬çš„æ¶æ„ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥æ„å»ºä¸€ä¸ªå·ç§¯å—ï¼Œå®ƒç”±ä¸¤ä¸ªå·ç§¯å±‚ç»„æˆï¼Œå¯ä»¥å½’ä¸€åŒ–å®ƒä»¬çš„è¾“å‡ºã€‚æ¿€æ´»åŠŸèƒ½æ˜¯ReLUã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="c695" class="nt kt iq np b gy nu nv l nw nx">def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):<br/>    """Function to add 2 convolutional layers with the parameters passed to it"""<br/>    # first layer<br/>    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), kernel_initializer = 'he_normal', padding = 'same')(input_tensor)<br/>    if batch norm:<br/>        x = BatchNormalization()(x)<br/>    x = Activation('relu')(x)<br/>    <br/>    # second layer<br/>    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), kernel_initializer = 'he_normal', padding = 'same')(x)<br/>    if batch norm:<br/>        x = BatchNormalization()(x)<br/>    x = Activation('relu')(x)<br/>    <br/>    return x</span></pre><p id="ef3d" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">ç°åœ¨ï¼Œæˆ‘ä»¬å°†å¤„ç†mainå‡½æ•°ï¼Œè¯¥å‡½æ•°åˆ›å»ºä¸€ä¸ªç»“åˆæ”¶ç¼©å’Œæ‰©å±•è·¯å¾„çš„æ¨¡å‹ï¼Œè¾“å‡ºæ˜¯0.0â€“1.0èŒƒå›´å†…çš„åˆ†æ®µé¢„æµ‹æ©ç ã€‚æˆ‘ä»¬è¿˜æ·»åŠ äº†ä¸€ä¸ªdropoutæ¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°æ¦‚æ‹¬ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="d688" class="nt kt iq np b gy nu nv l nw nx">def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):<br/>    """Function to define the UNET Model"""<br/>    # Contracting Path<br/>    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)<br/>    p1 = MaxPooling2D((2, 2))(c1)<br/>    p1 = Dropout(dropout)(p1)<br/>    <br/>    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)<br/>    p2 = MaxPooling2D((2, 2))(c2)<br/>    p2 = Dropout(dropout)(p2)<br/>    <br/>    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)<br/>    p3 = MaxPooling2D((2, 2))(c3)<br/>    p3 = Dropout(dropout)(p3)<br/>    <br/>    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)<br/>    p4 = MaxPooling2D((2, 2))(c4)<br/>    p4 = Dropout(dropout)(p4)<br/>    <br/>    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)<br/>    <br/>    # Expansive Path<br/>    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)<br/>    u6 = concatenate([u6, c4])<br/>    u6 = Dropout(dropout)(u6)<br/>    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)<br/>    <br/>    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)<br/>    u7 = concatenate([u7, c3])<br/>    u7 = Dropout(dropout)(u7)<br/>    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)<br/>    <br/>    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)<br/>    u8 = concatenate([u8, c2])<br/>    u8 = Dropout(dropout)(u8)<br/>    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)<br/>    <br/>    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)<br/>    u9 = concatenate([u9, c1])<br/>    u9 = Dropout(dropout)(u9)<br/>    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)<br/>    <br/>    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)<br/>    model = Model(inputs=[input_img], outputs=[outputs])<br/>    return model</span></pre><p id="8fda" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated"><strong class="ls ja"> custom_f1 </strong>æŒ‡æ ‡æ˜¯ä½¿ç”¨å¼ é‡è¿ç®—åˆ›å»ºçš„ï¼Œå¦‚ä¸‹æ–‡<a class="ae mo" href="https://medium.com/@aakashgoel12/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d" rel="noopener">å‡ºç‰ˆç‰©</a>æ‰€è¿°ã€‚å®ƒå°†å…è®¸æˆ‘ä»¬é€šè¿‡F1åˆ†æ•°æ¥æ§åˆ¶æ¨¡å‹çš„è´¨é‡ï¼ŒF1åˆ†æ•°æ˜¯ç²¾ç¡®åº¦å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡å€¼ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬è¯•å›¾é¿å…æ¨¡å‹é€šè¿‡é¢„æµ‹å®é™…ä¸Šæ•´ä¸ªæ•°æ®é›†çš„0æˆ–1å€¼è€Œèµ°å‘æå€¼çš„æƒ…å†µï¼Œè¿™ç§æƒ…å†µé€šå¸¸åœ¨è¿™ç§ä¸å¹³è¡¡çš„æ•°æ®ä¸­å‘ç”Ÿã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="d4bb" class="nt kt iq np b gy nu nv l nw nx">def custom_f1(y_true, y_pred): <br/>    """Function to calculate F1-score"""<br/>    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))<br/>    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))<br/>    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))<br/>    precision = true_positives / (predicted_positives + K.epsilon())<br/>    recall = true_positives / (possible_positives + K.epsilon())<br/>    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())<br/>    return f1 val</span></pre><p id="15c7" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">æ˜¯æ—¶å€™ç¼–è¯‘æˆ‘ä»¬çš„æ¨¡å‹å¹¶æ£€æŸ¥å®ƒçš„æ‘˜è¦äº†ã€‚æˆ‘ä»¬ä½¿ç”¨Adam optimizerã€BCE(äºŒè¿›åˆ¶äº¤å‰ç†µ)ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå¹¶å°†å‡†ç¡®åº¦ã€å¬å›ç‡ã€ç²¾ç¡®åº¦å’Œcustom_f1ä½œä¸ºæˆ‘ä»¬å°†åœ¨è®­ç»ƒæœŸé—´ç›‘æ§çš„æŒ‡æ ‡ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="6fd9" class="nt kt iq np b gy nu nv l nw nx">input_img = Input((img_size, img_size, 3), name='img')<br/>model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=False)<br/>model.compile(optimizer=Adam(lr=0.001), <br/>              loss="binary_crossentropy", <br/>              metrics=[ "accuracy", Recall(), Precision(), custom_f1])<br/>model.summary()</span></pre><p id="125c" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">ä¸‹ä¸€æ­¥æ˜¯åˆ›å»ºä¸€ä¸ªå®šåˆ¶çš„å›è°ƒç±»ï¼Œä»¥ä¾¿èƒ½å¤Ÿå°†æˆ‘ä»¬çš„åŸ¹è®­å†å²ä¿å­˜ä¸ºä¸€ä¸ªå•ç‹¬çš„æ–‡ä»¶ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œåœ¨æ¯ä¸ªæ—¶æœŸä¹‹åï¼Œæˆ‘ä»¬ç®€å•åœ°ç”¨å½“å‰çš„æŸå¤±å’Œåº¦é‡å€¼åˆ›å»ºpandas DataFrameï¼Œå¹¶å°†å…¶ä¿å­˜ä¸ºGoogle Driveä¸Šçš„. csvæ–‡ä»¶ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="2000" class="nt kt iq np b gy nu nv l nw nx">class HistoryCallback(keras.callbacks.Callback):<br/>    def on_epoch_end(self, epoch, logs=None):<br/>        """Callback function at the end of each epoch"""      <br/>        history_path = checkpoints_path + "history/"<br/>        if not os.path.exists(history_path): <br/>          os.makedirs(history_path)<br/><br/>        filename = history_path + model_name + "_history.csv"<br/>        keys = list(logs.keys())<br/>        values = np.array(list(logs.values()))<br/>        df = pd.DataFrame(data= [values], columns=keys)<br/>        df['epoch'] = epoch<br/>        df.reset_index(drop=True)<br/>        with open(filename, 'a') as f: <br/>          df.to_csv(f, header=f.tell()==0)<br/><br/>        print(f"Saved history after epoch {epoch} to: {filename}")</span></pre><p id="6d3d" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªå›è°ƒåˆ—è¡¨ï¼ŒåŒ…æ‹¬:</p><ul class=""><li id="fa01" class="mz na iq ls b lt mp lx mq mb nb mf nc mj nd mn ne nf ng nh bi translated">æå‰åœæ­¢(å¦‚æœè®­ç»ƒåœ¨ä¸€å®šæ—¶é—´å†…æ²¡æœ‰è¿›å±•)ï¼Œ</li><li id="68ab" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">å½“éªŒè¯ä¸¢å¤±å¡ä½æ—¶ï¼Œé™ä½ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡ï¼Œ</li><li id="7e13" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">ä½¿ç”¨éªŒè¯é›†ä¸Šçš„æœ€ä½³custom_f1()ä¿å­˜æ¨¡å‹(å¦‚æœæ‚¨ç›‘è§†è‡ªå®šä¹‰æŒ‡æ ‡ï¼Œè¯·è®°ä½è®¾ç½®æœ€å°/æœ€å¤§æ¨¡å¼)ï¼Œ</li><li id="0c97" class="mz na iq ls b lt ni lx nj mb nk mf nl mj nm mn ne nf ng nh bi translated">åœ¨åŸ¹è®­è¿‡ç¨‹ä¸­å®æ—¶ç»˜å›¾ä»¥æŸ¥çœ‹å­¦ä¹ æ›²çº¿ã€‚</li></ul><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="2316" class="nt kt iq np b gy nu nv l nw nx">callbacks = [<br/>    EarlyStopping(patience=10, verbose=1),<br/>    ReduceLROnPlateau(factor=0.33, patience=4, min_lr=0.000001, verbose=1),<br/>    ModelCheckpoint(checkpoints_path + model_name + ".h5", <br/>                    verbose=1, <br/>                    save_best_only=True, <br/>                    save_weights_only=False,<br/>                    monitor='val_custom_f1',<br/>                    mode = "max"),<br/>    PlotLossesKeras(),<br/>    HistoryCallback()<br/>]</span></pre><p id="6237" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">ç°åœ¨ï¼Œæˆ‘ä»¬ç»ˆäºå¯ä»¥æ‹Ÿåˆæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶åœ¨å‡ ä¸ªå°æ—¶å†…æ¬£èµæ‰€æœ‰æŒ‰ç…§é¢„æœŸæ–¹å‘ç»˜åˆ¶çš„ç¾ä¸½å›¾è¡¨ï¼Œå½“F1åˆ†æ•°ä¸Šå‡æ—¶(å¤§å¤šæ•°æ—¶é—´)ï¼ŒæŸå¤±è¶Šæ¥è¶Šä½ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="ef3b" class="nt kt iq np b gy nu nv l nw nx">results = model.fit(<br/>    train_gen, <br/>    steps_per_epoch=len(ids_train)//batch_size,<br/>    epochs=epochs, <br/>    callbacks=callbacks,<br/>    validation_data=valid_gen,<br/>    validation_steps=len(ids_valid)//batch_size, <br/>    verbose=1<br/>)</span></pre></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="b20d" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">ç»“æœ</h1><p id="8f0a" class="pw-post-body-paragraph lq lr iq ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">åœ¨éªŒè¯æœŸé—´ï¼ŒåŸºæœ¬æ¨¡å‹ä¼¼ä¹æ˜¾ç¤ºå‡ºF1åˆ†æ•°é«˜è¾¾0.71çš„æœ‰å¸Œæœ›çš„ç»“æœ(å‚è§åŸºå‡†æµ‹è¯•ç»“æœ<a class="ae mo" href="https://www.diva-portal.org/smash/get/diva2:1417200/FULLTEXT01.pdf" rel="noopener ugc nofollow" target="_blank">æ­¤å¤„</a>ï¼Œç¬¬42é¡µ)ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒèƒ½æä¾›ä»€ä¹ˆã€‚å½“æ‚¨æ£€æŸ¥å­¦ä¹ æ›²çº¿æ—¶ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°val_losså€¼å‡å°‘çš„åœæ»å¯¼è‡´åœ¨epochsé™åˆ¶ä¹‹å‰æå‰åœæ­¢ï¼Œè€ŒéªŒè¯é›†çš„æœ€å¤§F1åˆ†æ•°æ˜¯åœ¨è®­ç»ƒçš„ååŠéƒ¨åˆ†å¼€å§‹æ—¶è·å¾—çš„ã€‚</p><figure class="mv mw mx my gt ka gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/127df7321537bef1aca40fa77759c9ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/0*MwaboefCrAmTwJdB"/></div></figure><figure class="mv mw mx my gt ka gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/cfdf609fbc2f3d56ff43d42be815e76f.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/0*ztF40qkV8WtlRjVc"/></div></figure><p id="546c" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">å¯¹æµ‹è¯•é›†çš„è¯„ä¼°æ˜¾ç¤ºç»“æœç•¥å¥½äºéªŒè¯é›†ï¼Œè·å¾—0.74çš„F1åˆ†æ•°ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="f9b3" class="nt kt iq np b gy nu nv l nw nx">model.evaluate(<br/>    test_gen, <br/>    steps=len(test_ids)//batch_size,<br/>    verbose=1<br/>)</span></pre><figure class="mv mw mx my gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ob"><img src="../Images/8143c78591fa6b6c44469e1e770c0835.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Z9StDWGLvw5hzJEqhsGLw.png"/></div></div><figcaption class="kh ki gj gh gi kj kk bd b be z dk translated">æµ‹è¯•é›†ç»“æœ</figcaption></figure><p id="adcf" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹æˆ‘ä»¬çš„ç»†åˆ†æ¨¡å‹å®é™…ä¸Šæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚æˆ‘ä»¬å°†å¹¶æ’ç»˜åˆ¶æ­£å°„å½±åƒã€çœŸå®é®ç½©ã€é¢„æµ‹é®ç½©ä»¥åŠé˜ˆå€¼é¢„æµ‹å’ŒçœŸå®é®ç½©ä¹‹é—´çš„å·®å¼‚ã€‚</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="4a57" class="nt kt iq np b gy nu nv l nw nx">def plot_sample(img_folder, mask_folder, img_ids, thresh=0.5, i=None):<br/>    """Function to plot the results"""<br/>    if i is None:<br/>        i = random.randint(0, len(img_ids))<br/>    <br/>    img = np.zeros((1, img_size, img_size, 3)).astype(float)<br/>    mask = np.zeros((1, img_size, img_size, 1)).astype(float)<br/>    <br/>    # load image    <br/>    img_data = img_to_array(load_img(img_folder+img_ids[i]))/255.0<br/><br/>    # load mask<br/>    img_mask = img_to_array(load_img(mask_folder+img_ids[i], color_mode="grayscale"))<br/>    img_mask = (img_mask &gt; img_mask.min()).astype(int)<br/>    # add extra dimension for parity with train_img size [img_size * img_size * 3]<br/>    img_mask = img_mask.reshape(img_size, img_size, 1)             <br/><br/>    # add to array<br/>    img[0] = img_data <br/>    mask[0] = img_mask<br/>    <br/>    # print file id for reference<br/>    print(img_ids[i])<br/><br/>    # mask prediction<br/>    mask_pred = model.predict(img)[0]<br/>    mask_pred_t = (mask_pred &gt; thresh).astype(np.uint8)<br/><br/>    # mask diff<br/>    mask_diff = mask_pred_t * (img_mask&lt;1)<br/><br/>    fig, ax = plt.subplots(1, 5, figsize=(30, 10))<br/>    ax[0].imshow(img[0])<br/>    ax[0].set_title('orto rgb')<br/><br/>    ax[1].imshow(mask.squeeze())<br/>    ax[1].set_title('mask')<br/><br/>    ax[2].imshow(mask_pred.squeeze())<br/>    ax[2].set_title('mask predicted')<br/><br/>    ax[3].imshow(mask_pred_t.squeeze())<br/>    ax[3].set_title('mask predicted binary')<br/>    <br/>    ax[4].imshow(mask_diff.squeeze())<br/>    ax[4].set_title('mask predicted binary - mask');</span><span id="6784" class="nt kt iq np b gy oc nv l nw nx">plot_sample(test_orto_path, test_masks_path, img_ids=test_ids, thresh=0.5)</span></pre><figure class="mv mw mx my gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi od"><img src="../Images/2b0c42c8e98395465393fb31a6459692.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ivq_qUi0vjt6dxii"/></div></div></figure><figure class="mv mw mx my gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi od"><img src="../Images/c401395b7fbfc2ff71c142b5415c5675.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2vdoW-q5txB0qWQP"/></div></div></figure><figure class="mv mw mx my gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi od"><img src="../Images/423f211dfd506d5521340416e3086e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gz9LixVMqLrRS-3f"/></div></div></figure><p id="60f6" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">è€Œä¸”â€¦â€¦æ¨¡å‹å·¥ä½œæ­£å¸¸ã€‚ğŸ˜</p></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><p id="569d" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated"><a class="ae mo" href="https://github.com/DataWorkshop-Foundation/olsztyn-project-samowola/blob/main/about/notebooks/2_building_unet_model.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ls ja">é“¾æ¥åˆ°å®˜æ–¹ç¬”è®°æœ¬</strong> </a></p><p id="6b23" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">è®¤è¯†ä¸€ä¸‹æˆ‘ä»¬çš„å›¢é˜Ÿ:<br/> <a class="ae mo" href="https://www.linkedin.com/in/martaaugustynowicz/" rel="noopener ugc nofollow" target="_blank">ç›å°”å¡”Â·å¥¥å¤æ–¯ç‰¹è¯ºç»´å¥‡</a> <br/> <a class="ae mo" href="https://www.linkedin.com/in/sawaniewski/" rel="noopener ugc nofollow" target="_blank">èŒ¹å¡æ–¯å…¹Â·è¨ç“¦å°¼è€¶å¤«æ–¯åŸº</a> <br/> <a class="ae mo" href="https://www.linkedin.com/in/dtanajewski/" rel="noopener ugc nofollow" target="_blank">è¾¾ç•™ä»€Â·å¡”çº³è€¶å¤«æ–¯åŸº</a> <br/> <a class="ae mo" href="https://www.linkedin.com/in/igor-wieczorek/" rel="noopener ugc nofollow" target="_blank">ä¼Šæˆˆå°”Â·ç»´ä¹”é›·å…‹</a> <br/> <a class="ae mo" href="https://www.linkedin.com/in/maciej-zieniewicz/" rel="noopener ugc nofollow" target="_blank">é©¬åˆ‡ä¼ŠÂ·æ°æ¶…ç»´å¥‡</a></p><p id="7211" class="pw-post-body-paragraph lq lr iq ls b lt mp lv lw lx mq lz ma mb mr md me mf ms mh mi mj mt ml mm mn ij bi translated">æœ¬é¡¹ç›®åœ¨<a class="ae mo" href="https://dataworkshop.foundation/" rel="noopener ugc nofollow" target="_blank"> <strong class="ls ja"> DataWorkshopåŸºé‡‘ä¼š</strong> </a> <strong class="ls ja"> </strong>ç¤¾åŒºå†…è¿›è¡Œã€‚</p><figure class="mv mw mx my gt ka gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/175b93acb806829514fda09f4e359140.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*8xyrYQm2fHyKZhnEZxqXDA.jpeg"/></div></figure><blockquote class="of og oh"><p id="2cf7" class="lq lr oi ls b lt mp lv lw lx mq lz ma oj mr md me ok ms mh mi ol mt ml mm mn ij bi translated">DataWorkshop Foundationä¸»è¦æ˜¯å…³äºæœºå™¨å­¦ä¹ å’Œäººã€‚æˆ‘ä»¬ä¸“æ³¨äºäº²ç¤¾ä¼šæ´»åŠ¨ï¼Œåˆ©ç”¨æœºå™¨å­¦ä¹ çš„æ½œåŠ›ã€‚DataWorkshopåŸºé‡‘ä¼šçš„ç›®æ ‡æ˜¯é€šè¿‡å®è·µæ´»åŠ¨ä¼ æ’­æœ‰å…³æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„çŸ¥è¯†ï¼Œä»è€Œè§£å†³å½“å‰çš„é‡è¦é—®é¢˜ã€‚</p></blockquote></div></div>    
</body>
</html>