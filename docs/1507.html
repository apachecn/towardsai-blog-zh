<html>
<head>
<title>What is CLIP (Contrastive Language â€” Image Pre-training) and how it can be used for semantic image search?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CLIP(å¯¹æ¯”è¯­è¨€â€”å›¾åƒé¢„è®­ç»ƒ)æ˜¯ä»€ä¹ˆï¼Œå¦‚ä½•ç”¨äºè¯­ä¹‰å›¾åƒæœç´¢ï¼Ÿ</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://pub.towardsai.net/what-is-clip-contrastive-language-image-pre-training-and-how-it-can-be-used-for-semantic-image-b02ccf49414e?source=collection_archive---------0-----------------------#2021-02-09">https://pub.towardsai.net/what-is-clip-contrastive-language-image-pre-training-and-how-it-can-be-used-for-semantic-image-b02ccf49414e?source=collection_archive---------0-----------------------#2021-02-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ac7b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/computer-vision" rel="noopener ugc nofollow" target="_blank">è®¡ç®—æœºè§†è§‰</a></h2><div class=""/><div class=""><h2 id="2f47" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">æ·±åº¦å­¦ä¹ æœç´¢å›¾åƒçš„æ–¹æ³•</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/2addf57e184359ae01d7cb98d8ff5c4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CuzMp1faYWMDvIbUKl_DvA.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">ç”±<a class="ae lh" href="https://unsplash.com/@miteneva?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">ç›åˆ©äºšÂ·ç‰¹å†…å¨ƒ</a>åœ¨<a class="ae lh" href="https://unsplash.com/s/photos/deep-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>ä¸Šæ‹æ‘„çš„ç…§ç‰‡</figcaption></figure><p id="c0f0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">æœ€è¿‘ï¼ŒOpenAIçš„ç ”ç©¶äººå‘˜å‘è¡¨äº†ä¸€ç§å¤šæ¨¡æ€æ¶æ„ï¼Œä¸€æ—¦åœ¨å¤§çº¦4äº¿ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå°±å¯ä»¥ç”¨äº30ç§ä¸åŒçš„ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•å¹¶ä¸æ–°é²œï¼Œä»¥å‰è®¸å¤šå…¶ä»–ç ”ç©¶äººå‘˜è¯•å›¾ä½¿ç”¨æ–‡æœ¬è½¬æ¢å™¨å’Œé¢„è®­ç»ƒCNNæ¨¡å‹çš„ç»„åˆæ¥é¢„è®­ç»ƒå›¾åƒ-æ–‡æœ¬å¯¹çš„æ¨¡å‹ï¼Œç„¶åå°†å…¶ç”¨äºä¸åŒçš„å‘ä¸‹ä»»åŠ¡ã€‚ä½†æ˜¯ç”±äºç§ç§åŸå› ï¼Œè¿™äº›æ–¹æ³•å¹¶ä¸åƒåœ¨<a class="ae lh" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf" rel="noopener ugc nofollow" target="_blank">è®ºæ–‡</a>ä¸­è®¨è®ºçš„é‚£æ ·æˆåŠŸã€‚å°è¯•äº†å„ç§é¢„è®­ç»ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬é¢„æµ‹å’Œå¯¹æ¯”ï¼›åœ¨ä¸åŒçš„å‘ä¸‹ä»»åŠ¡ä¸­è¾¾åˆ°SOTAæ°´å¹³çš„ç²¾ç¡®åº¦ã€‚åœ¨é¢„æµ‹æ–¹æ³•ä¸­ï¼Œè®­ç»ƒå¤šæ¨¡æ€æ¶æ„æ¥åŸºäºå›¾åƒé¢„æµ‹å­—å¹•ã€‚ä½†è¿™ç§æ–¹æ³•åœ¨å‘ä¸‹çš„ä»»åŠ¡ä¸­å¹¶ä¸å¥æ•ˆï¼Œå› ä¸ºæ¨¡å‹è¯•å›¾åŒ¹é…æ–‡æœ¬ä¸­çš„ç²¾ç¡®å•è¯ã€‚å› æ­¤ï¼Œä½¿ç”¨å¯¹æ¯”æ–¹æ³•é€šè¿‡è”åˆè®­ç»ƒå›¾åƒç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨æ¥ä»å¤šæ¨¡æ€è¡¨ç¤ºä¸­å­¦ä¹ ï¼Œä»¥æœ€å¤§åŒ–æ­£ç¡®(å›¾åƒ-æ–‡æœ¬)å¯¹ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œå¹¶æœ€å°åŒ–ä¸æ­£ç¡®(å›¾åƒ-æ–‡æœ¬)å¯¹ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼æ€§ã€‚</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi me"><img src="../Images/98334f5848aaa1f9664854fd9ab4cccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*ZqjY8IvfM0UDqIp7LVKFIw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">æ¥æº:<a class="ae lh" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf" rel="noopener ugc nofollow" target="_blank">å›å½¢é’ˆ</a></figcaption></figure><p id="5e76" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ç°åœ¨ï¼Œæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨è¿™ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œè¯­ä¹‰å›¾åƒæœç´¢å‘¢ï¼Ÿæˆ‘ä»¬æœ‰ä¸€ä¸ªå›¾åƒæŸ¥è¯¢æ–‡æœ¬Tå’Œä¸€å †ä¸åŒçš„å›¾åƒã€‚æ–‡æœ¬ç¼–ç å™¨æä¾›æŸ¥è¯¢æ–‡æœ¬tçš„æ–‡æœ¬ç‰¹å¾(<code class="fe mf mg mh mi b">Tfeat</code>)ã€‚ç„¶åï¼Œæˆ‘ä»¬éå†å›¾åƒIsï¼Œå¹¶ä½¿ç”¨å›¾åƒç¼–ç å™¨ä¸ºæ¯ä¸ªå›¾åƒIè®¡ç®—å›¾åƒç‰¹å¾(<code class="fe mf mg mh mi b">Ifeat</code>)ï¼Œå¹¶è®¡ç®—å›¾åƒç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾ä¹‹é—´çš„ç‚¹ç§¯ç›¸ä¼¼åº¦ã€‚ç”±äºé¢„è®­ç»ƒç›®æ ‡æœ€å¤§åŒ–äº†æ­£ç¡®(å›¾åƒã€æ–‡æœ¬)å¯¹çš„ç›¸ä¼¼æ€§å¾—åˆ†ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è®¤ä¸ºæœ€å¤§ç‚¹ç§¯å€¼æ„å‘³ç€æœ€å¤§ç›¸ä¼¼æ€§ã€‚æ‰€ä»¥å¯¹äºæ¯å¼ å›¾ç‰‡ï¼Œæˆ‘ä»¬è®¡ç®—ç‚¹ç§¯ç›¸ä¼¼åº¦ï¼Œç„¶åæŒ‰ç…§åˆ†æ•°é™åºæ’åˆ—ã€‚ä½™å¼¦ç›¸ä¼¼æ€§ä¹Ÿå¯ä»¥ç”¨æ¥è®¡ç®—ç›¸ä¼¼æ€§å¾—åˆ†ï¼Œä½†GPUåœ¨çŸ©é˜µä¹˜æ³•ä¸Šæ›´å¿«ï¼Œå› æ­¤ï¼Œè¿™é‡Œæˆ‘å°†ä½¿ç”¨ç‚¹ç§¯ã€‚è®©æˆ‘ä»¬è¿›å…¥ç¼–ç ã€‚åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Unsplash APIä»æŸ¥è¯¢æ–‡æœ¬ä¸­è·å–å›¾åƒã€‚ä½¿ç”¨æ¥è‡ªUnsplash APIçš„æŸ¥è¯¢æ–‡æœ¬å’Œå›¾åƒï¼Œæˆ‘ä»¬å°†æ ¹æ®ä¸Šé¢è®¨è®ºçš„æŠ€æœ¯å¯¹å®ƒä»¬è¿›è¡Œæ’åºã€‚</p><h1 id="9978" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">ä¸‹è½½å‰ªè¾‘æ¨¡å‹å’ŒåŒ…</h1><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="4225" class="nf mk it mi b gy ng nh l ni nj">pip install git+https://github.com/openai/CLIP.git</span></pre><h1 id="f240" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">åŠ è½½æ¨¡å‹å¹¶è®¡ç®—ç›¸ä¼¼æ€§</h1><p id="e916" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä»<strong class="lk jd"> COCO Captions </strong>æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸‰å¼ å›¾ç‰‡ï¼Œå¹¶æä¾›ä¸€ä¸ªæ ‡é¢˜ï¼Œç„¶åæ£€æŸ¥å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚</p><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="e5a3" class="nf mk it mi b gy ng nh l ni nj">import torch<br/>import clip<br/>from PIL import Image</span><span id="839f" class="nf mk it mi b gy np nh l ni nj">images = ['391895.png', '522418.png', '318219.png']<br/>text = 'a man with red helmet on a moped'</span><span id="d99d" class="nf mk it mi b gy np nh l ni nj">simScore = []<br/>tokenizedText = clip.tokenize(text).to(device)<br/>for img in images:<br/>    image = preprocess(Image.open(os.path.join(path, img))).unsqueeze(0).to(device)<br/>    with torch.no_grad():<br/>        image_features = model.encode_image(image)<br/>        text_features = model.encode_text(tokenizedText)<br/>    <br/>		# append image name with similarity score<br/>    simScore.append((img, torch.matmul(text_features, image_features.T)[0][0]))</span><span id="2eb5" class="nf mk it mi b gy np nh l ni nj">print(simScore)</span><span id="e209" class="nf mk it mi b gy np nh l ni nj"># output<br/>[('391895.png', tensor(21.2141)),<br/> ('522418.png', tensor(11.7804)),<br/> ('318219.png', tensor(10.6959))]</span></pre><div class="ks kt ku kv gt ab cb"><figure class="nq kw nr ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/2762df0cab87dc5b856ebf3f4d08e4a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*oigr6byhBbsuwezP6Fbbjg.png"/></div></figure><figure class="nq kw nw ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/1d9f921c3b7e0a8c5aed5a30ab814500.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*xmteQAEynNxDfbqNGVC6Qw.png"/></div></figure><figure class="nq kw nx ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/3b0f286a23b8a09311507b039ec04ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*UwBpc7jBWz8_Ll3HVKkFww.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk ny di nz oa translated">æ¥æº:å¯å¯å­—å¹•æ•°æ®é›†(391895.pngï¼Œ391895.png)</figcaption></figure></div><h1 id="92b0" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">ä½¿ç”¨Streamlit shareéƒ¨ç½²å›¾åƒè¯­ä¹‰æœç´¢åº”ç”¨ç¨‹åº</h1><p id="7727" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">åœ¨<a class="ae lh" href="https://unsplash.com/join" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>ä¸Šæ³¨å†Œä¸€ä¸ªå¼€å‘è€…è´¦æˆ·ï¼Œåˆ›å»ºä¸€ä¸ªåº”ç”¨ç¨‹åºå¹¶è·å¾—è®¿é—®å¯†é’¥ã€‚</p><p id="7ca0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">åˆ›å»º</strong> <code class="fe mf mg mh mi b"><strong class="lk jd">streamlitcliputils.py</strong></code> <strong class="lk jd">æ–‡ä»¶å¹¶è·Ÿéš</strong></p><ul class=""><li id="f01a" class="ob oc it lk b ll lm lo lp lr od lv oe lz of md og oh oi oj bi translated">å¯¼å…¥å’Œæ¨¡å‹åŠ è½½</li></ul><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="b661" class="nf mk it mi b gy ng nh l ni nj">import torch<br/>import clip<br/>from PIL import Image<br/>import os<br/>import re<br/>from tqdm import tqdm, trange<br/>import random<br/>import requests<br/>import numpy as np<br/>import streamlit as st</span><span id="68ef" class="nf mk it mi b gy np nh l ni nj">global model, preprocess, device</span><span id="072d" class="nf mk it mi b gy np nh l ni nj">device = 'cpu'</span><span id="7913" class="nf mk it mi b gy np nh l ni nj">model, preprocess = clip.load("ViT-B/32", device = 'cpu')</span></pre><ul class=""><li id="1a78" class="ob oc it lk b ll lm lo lp lr od lv oe lz of md og oh oi oj bi translated">ä½¿ç”¨APIä»Unsplashè·å–åŸºäºæŸ¥è¯¢æ–‡æœ¬çš„å›¾åƒ</li></ul><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="8dec" class="nf mk it mi b gy ng nh l ni nj">def getImagesFromUnsplash(total: int, query_text: str):<br/>    '''<br/>    Images from query text<br/>    '''<br/>    num_page = 1<br/>    imgs_total = total<br/>    query = query_text<br/>    url = f"&lt;https://api.unsplash.com/search/photos?query={query_text}&amp;page={num_page}&amp;per_page={imgs_total}&gt;"</span><span id="cada" class="nf mk it mi b gy np nh l ni nj">    headers = {<br/>        "Authorization": f"Bearer Client-ID {UPSPLASH_API_KEY}",</span><span id="28f2" class="nf mk it mi b gy np nh l ni nj">    }</span><span id="d6b0" class="nf mk it mi b gy np nh l ni nj">    req = requests.get(url, headers = headers)</span><span id="39f5" class="nf mk it mi b gy np nh l ni nj">    resp = req.json()</span><span id="5bda" class="nf mk it mi b gy np nh l ni nj">    regUrls = [r['urls']['regular'] for r in resp['results']]</span><span id="13a5" class="nf mk it mi b gy np nh l ni nj">    return regUrls</span></pre><ul class=""><li id="dac8" class="ob oc it lk b ll lm lo lp lr od lv oe lz of md og oh oi oj bi translated">å›¾ç‰‡é“¾æ¥åˆ°<code class="fe mf mg mh mi b">PIL.Image</code></li></ul><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="dc35" class="nf mk it mi b gy ng nh l ni nj">def linkToImage(link):<br/>    '''<br/>    Image URL to PIL.Image<br/>    '''<br/>    content = requests.get(link, stream = True)<br/>    content = content.raw<br/>    img = Image.open(content)<br/>    return img</span></pre><ul class=""><li id="cfc0" class="ob oc it lk b ll lm lo lp lr od lv oe lz of md og oh oi oj bi translated">è®¡ç®—ç›¸ä¼¼æ€§å¾—åˆ†</li></ul><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="9362" class="nf mk it mi b gy ng nh l ni nj">@st.cache(show_spinner=False)<br/>def getImageTextSimScore(link, text):<br/>    '''<br/>    Compute similarity score from image feature<br/>    and text feature<br/>    '''<br/>    image = preprocess(linkToImage(link)).unsqueeze(0).to(device)<br/>    tokenizedText = clip.tokenize(text).to(device)<br/>    with torch.no_grad():<br/>        image_features = model.encode_image(image)<br/>        text_features = model.encode_text(tokenizedText)<br/>    <br/>    simScore = torch.matmul(text_features, image_features.T)[0][0]</span><span id="c752" class="nf mk it mi b gy np nh l ni nj">    return simScore.item()</span></pre><ul class=""><li id="6220" class="ob oc it lk b ll lm lo lp lr od lv oe lz of md og oh oi oj bi translated">ä»Unsplashè·å–å›¾åƒå¹¶æ’åº</li></ul><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="4f2b" class="nf mk it mi b gy ng nh l ni nj">@st.cache(show_spinner=False)<br/>def getSortedQuery(text):<br/>    '''<br/>    Get images from text and sort<br/>    using similarity score<br/>    '''</span><span id="b83c" class="nf mk it mi b gy np nh l ni nj">    upSplashImages = getImagesFromUnsplash(10, text)<br/>    <br/>    imgSimScore = []</span><span id="0f46" class="nf mk it mi b gy np nh l ni nj">    for ix, img in enumerate(tqdm(upSplashImages)):</span><span id="e4a6" class="nf mk it mi b gy np nh l ni nj">        imgSimScore.append((img, getImageTextSimScore(img, text)))<br/>    <br/>    imgSimScore = sorted(imgSimScore, key = lambda x: x[1], reverse=True)</span><span id="8d99" class="nf mk it mi b gy np nh l ni nj">    return imgSimScore, upSplashImages</span></pre><p id="fb20" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">åˆ›å»º</strong> <code class="fe mf mg mh mi b"><strong class="lk jd">streamlitapp.py</strong></code> <strong class="lk jd">æ–‡ä»¶</strong></p><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="c1ad" class="nf mk it mi b gy ng nh l ni nj">from streamlitcliputils import *<br/>import streamlit as st<br/>import io<br/>from PIL import Image</span><span id="8cdf" class="nf mk it mi b gy np nh l ni nj">st.set_page_config(<br/>    page_title = 'CLIP',<br/>    page_icon = 'ğŸ‘'<br/>)</span><span id="60df" class="nf mk it mi b gy np nh l ni nj">st.header("CLIP - Semantic Image Search")<br/>imageText = st.text_input("Search Image")</span><span id="3155" class="nf mk it mi b gy np nh l ni nj">if imageText:<br/>    with st.spinner(text = 'Getting Images from Unsplash and sorting with clip ...'):<br/>        <br/>        imgSimScore, upSplashImages = getSortedQuery(imageText)</span><span id="d565" class="nf mk it mi b gy np nh l ni nj">        images = [linkToImage(img) for img, score in imgSimScore]<br/>        simScore = [f'Sim Score: {score:.2f}' for img, score in imgSimScore]</span><span id="49df" class="nf mk it mi b gy np nh l ni nj">        upSplashImages = [linkToImage(img) for img in upSplashImages]<br/>        upSplashIx = [i+1 for i in range(len(upSplashImages))]</span><span id="4505" class="nf mk it mi b gy np nh l ni nj">        col1, col2 = st.beta_columns(2)</span><span id="d458" class="nf mk it mi b gy np nh l ni nj">        col1.header("Semantic Search")<br/>        col1.image(images, width = 300, caption = simScore)</span><span id="06d3" class="nf mk it mi b gy np nh l ni nj">        col2.header("Images from Unsplash")<br/>        col2.image(upSplashImages, width = 300, caption = upSplashIx)</span></pre><p id="98f2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ç°åœ¨ï¼Œè¦ä½¿ç”¨Streamlit shareéƒ¨ç½²åº”ç”¨ç¨‹åºï¼Œæ‚¨éœ€è¦æœ‰ä¸€ä¸ªç»è¿‡æ‰¹å‡†çš„Streamlit Shareå¸æˆ·ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤å¤„æ³¨å†Œä¸€ä¸ª<a class="ae lh" href="https://share.streamlit.io/" rel="noopener ugc nofollow" target="_blank"/>ã€‚è¦ä½¿ç”¨streamlit shareéƒ¨ç½²æ‚¨çš„åº”ç”¨ç¨‹åºï¼Œæ‚¨éœ€è¦ä½¿ç”¨ä¸€ä¸ª<code class="fe mf mg mh mi b">requirements.txt</code>æ–‡ä»¶å°†ä»£ç æ¨é€åˆ°GitHubã€‚</p><ul class=""><li id="5e85" class="ob oc it lk b ll lm lo lp lr od lv oe lz of md og oh oi oj bi translated">å°†åŒ…æ·»åŠ åˆ°<code class="fe mf mg mh mi b">requirements.txt</code></li></ul><pre class="ks kt ku kv gt nb mi nc nd aw ne bi"><span id="439b" class="nf mk it mi b gy ng nh l ni nj">tqdm==4.56.0<br/>git+https://github.com/openai/CLIP.git<br/>requests==2.25.1<br/>streamlit==0.74.1<br/>torch==1.7.1<br/>numpy==1.20.0rc2<br/>Pillow==8.1.0</span></pre><p id="8624" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">æ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ªGitHubå­˜å‚¨åº“å¹¶æ¨é€æ‚¨çš„æ–‡ä»¶ã€‚ç„¶åè½¬åˆ°streamlit shareæ§åˆ¶å°ï¼Œå•å‡»æ–°åº”ç”¨ç¨‹åºä¸‹æ‹‰èœå•ï¼Œé€‰æ‹©â€œFrom Existing Repoâ€ã€‚</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/0e79074c8c390d6c08d36a8243692744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*36TqVenSsxFOzJ3IxDggpA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">æ¥æº:ä½œè€…</figcaption></figure><p id="afeb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">é€‰æ‹©repoåç§°ï¼Œå¹¶åœ¨ä¸»æ–‡ä»¶è·¯å¾„è¾“å…¥ä¸­æä¾›æ–‡ä»¶å</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/bf91b4b98040129cb77ad171cb94c3b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0K_ULffOBjy8Lj6P_JYXgQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">æ¥æº:ä½œè€…</figcaption></figure><p id="f51e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">å•å‡»éƒ¨ç½²ï¼Œæ‚¨å°†è¿›å…¥éƒ¨ç½²å±å¹•ï¼Œæ‚¨çš„åº”ç”¨å°†åœ¨å‡ åˆ†é’Ÿå†…å®Œæˆéƒ¨ç½²ã€‚è¯­ä¹‰æœç´¢çš„å®æ—¶ç‰ˆæœ¬å¯ä»<a class="ae lh" href="https://share.streamlit.io/vatsalsaglani/clipsemanticimagesearch/streamlitClip1/streamlitapp.py" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>è·å¾—</p><p id="3123" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ä½ å¯ä»¥çœ‹çœ‹è¿™ä¸ªè§†é¢‘ï¼Œçœ‹çœ‹è¿™ä¸ªæ¨¡å‹çš„è¡¨ç°ã€‚</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="om on l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">æ¥æº:ä½œè€…</figcaption></figure><p id="9e6e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ä½œä¸ºåšå®¢çš„æ€»ç»“ï¼Œæˆ‘ä»¬è®¨è®ºäº†CLIPçš„è®­ç»ƒæ–¹æ³•ä»¥åŠå¦‚ä½•å°†å…¶ç”¨äºè¯­ä¹‰å›¾åƒæœç´¢ï¼Œç„¶åæˆ‘ä»¬ä½¿ç”¨Unsplash APIæ¥æŸ¥è¯¢å›¾åƒï¼Œå¹¶ä½¿ç”¨ä½¿ç”¨CLIPè®¡ç®—çš„ç›¸ä¼¼æ€§å¾—åˆ†è¿›è¡Œæ’åºã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢çœ‹è¿™ä¸ªåšå®¢ã€‚</p></div></div>    
</body>
</html>