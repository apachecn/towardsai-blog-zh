<html>
<head>
<title>How to Create a Powerful TF-IDF Keyword Research Tool in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">å¦‚ä½•ç”¨Pythonåˆ›å»ºä¸€ä¸ªå¼ºå¤§çš„TF-IDFå…³é”®è¯ç ”ç©¶å·¥å…·</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://pub.towardsai.net/how-to-create-a-powerful-tf-idf-keyword-research-tool-in-python-f23c8265279e?source=collection_archive---------2-----------------------#2021-03-02">https://pub.towardsai.net/how-to-create-a-powerful-tf-idf-keyword-research-tool-in-python-f23c8265279e?source=collection_archive---------2-----------------------#2021-03-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6f64" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsai.net/p/category/programming" rel="noopener ugc nofollow" target="_blank">ç¼–ç¨‹</a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/0c5605aca3497e588ba9b5d2d14189c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iGWJ9JEVgDgEQJJtQs2lkw.jpeg"/></div></div></figure><p id="9e65" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">æˆ‘ä»¬æ­£å¤„äºæ•°å­—è¥é”€çš„æ—¶ä»£ï¼Œç°åœ¨<strong class="km jd">è¿™ä¸ªè¯</strong>æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´é‡è¦ã€‚æ•°å­—è¥é”€æœ€æˆåŠŸçš„æŠ€æœ¯ä¹‹ä¸€æ˜¯ç«äº‰åˆ†æå’Œå…³é”®è¯ç ”ç©¶ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬çš„ç«äº‰å¯¹æ‰‹åœ¨è°ˆè®ºä»€ä¹ˆã€‚è¿™æ˜¯æœ€æœ‰ç”¨çš„æœç´¢å¼•æ“ä¼˜åŒ–ï¼Œä½†ä¹Ÿä¸ºåšå®¢å¸–å­çš„æƒ³æ³•ç­‰ã€‚</p><h1 id="fae5" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">ç¬¬ä¸€æ­¥:ä»ç½‘ç«™ä¸Šè·å–æ–‡æœ¬</h1><p id="e14b" class="pw-post-body-paragraph kk kl it km b kn mg kp kq kr mh kt ku kv mi kx ky kz mj lb lc ld mk lf lg lh im bi translated">åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä»URLä¸­æå–å¹²å‡€æ–‡æœ¬çš„å‡½æ•°ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥åœ¨ä»¥åçš„åˆ†æä¸­ä½¿ç”¨å®ƒã€‚</p><pre class="ml mm mn mo gt mp mq mr ms aw mt bi"><span id="7949" class="mu lj it mq b gy mv mw l mx my">import pandas as pd<br/>import numpy as np<br/>import urllib<br/>from fake_useragent import UserAgent<br/>import requests<br/>import re<br/>from urllib.request import Request, urlopen<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>import math<br/>from nltk.corpus import stopwords<br/>stopWords = list(set(stopwords.words('english')))<br/>from bs4 import BeautifulSoup<br/><br/><br/><br/>def get_text(url):<br/>    try:<br/>        req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})<br/>        webpage = urlopen(req,timeout=5).read()<br/>        soup = BeautifulSoup(webpage, "html.parser")<br/>        texts = soup.findAll(text=True)<br/>        res=u" ".join(t.strip() for t in texts if t.parent.name not in ['style', 'script', 'head', 'title', 'meta', '[document]'])<br/>        return(res)<br/>    except:<br/>        return False</span></pre><p id="0d89" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">æˆ‘ä»¬æ¥ä¸¾ä¸ªä¾‹å­ã€‚</p><pre class="ml mm mn mo gt mp mq mr ms aw mt bi"><span id="58f5" class="mu lj it mq b gy mv mw l mx my">get_text('https://en.wikipedia.org/wiki/Machine_learning')[0:500]<br/>#It will return the first 500 characters<br/></span><span id="83f3" class="mu lj it mq b gy mz mw l mx my">CentralNotice Machine learning From Wikipedia, the free encyclopedia Jump to navigation Jump to search For the journal, see Machine Learning (journal) . "Statistical learning" redirects here. For statistical learning in linguistics, see statistical learning in language acquisition . Scientific study of algorithms and statistical models that computer systems use to perform tasks without explicit instructions Part of a series on Machine learning and data mining Problems Class'</span></pre><p id="75b0" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">æˆåŠŸï¼ç°åœ¨æˆ‘ä»¬å¯ä»¥ä»ç½‘ç«™ä¸Šè·å¾—å¹²å‡€çš„æ–‡æœ¬ï¼ä½†æ˜¯æˆ‘ä»¬åˆ°åº•è¯¥å¦‚ä½•ä½¿ç”¨å®ƒå‘¢ï¼Ÿè®©æˆ‘ä»¬è¿›å…¥ä¸‹ä¸€ç« ã€‚</p><h1 id="569a" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">ç¬¬äºŒæ­¥:è·å–ç«äº‰å¯¹æ‰‹çš„ç½‘å€</h1><p id="f76c" class="pw-post-body-paragraph kk kl it km b kn mg kp kq kr mh kt ku kv mi kx ky kz mj lb lc ld mk lf lg lh im bi translated">æ‰¾åˆ°æœ€ä½³ç«äº‰å¯¹æ‰‹çš„æœ€å¥½æ–¹æ³•æ˜¯åœ¨è°·æ­Œæœç´¢ä¸­è·å¾—æˆ‘ä»¬æ„Ÿå…´è¶£çš„å…³é”®è¯çš„é¡¶éƒ¨ç»“æœã€‚æˆ‘ä»¬å°†ä½¿ç”¨å‰ä¸€ç¯‡æ–‡ç« ä¸­çš„ä»£ç ï¼Œ<a class="ae na" href="https://predictivehacks.com/how-to-scrape-google-results-for-free-using-python/" rel="noopener ugc nofollow" target="_blank">å¦‚ä½•ä½¿ç”¨Python </a>å…è´¹æŠ“å–è°·æ­Œç»“æœã€‚</p><pre class="ml mm mn mo gt mp mq mr ms aw mt bi"><span id="9745" class="mu lj it mq b gy mv mw l mx my">def google_results(keyword, n_results):<br/>    query = keyword<br/>    query = urllib.parse.quote_plus(query) # Format into URL encoding<br/>    number_result = n_results<br/>    ua = UserAgent()<br/>    google_url = "https://www.google.com/search?q=" + query + "&amp;num=" + str(number_result)<br/>    response = requests.get(google_url, {"User-Agent": ua.random})<br/>    soup = BeautifulSoup(response.text, "html.parser")<br/>    result_div = soup.find_all('div', attrs = {'class': 'ZINbbc'})<br/>    results=[re.search('\/url\?q\=(.*)\&amp;sa',str(i.find('a', href = True)['href'])) for i in result_div if "url" in str(i)]<br/>    links=[i.group(1) for i in results if i != None]<br/>    return (links)</span></pre><p id="3ed0" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">æ¯”æ–¹è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›çœ‹åˆ°â€œæœºå™¨å­¦ä¹ åšå®¢â€è¿™ä¸ªå…³é”®è¯çš„â€œç«äº‰å¯¹æ‰‹â€ã€‚è®©æˆ‘ä»¬ä½¿ç”¨google resultså‡½æ•°æ¥è·å–æ’åé å‰çš„URLï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå˜é‡æ˜¯å…³é”®å­—ï¼Œç¬¬äºŒä¸ªå˜é‡æ˜¯ç»“æœçš„æ•°é‡ã€‚</p><pre class="ml mm mn mo gt mp mq mr ms aw mt bi"><span id="c939" class="mu lj it mq b gy mv mw l mx my">google_results('machine learning blog',10)</span><span id="1797" class="mu lj it mq b gy mz mw l mx my">['https://towardsai.net/p/machine-learning/best-machine-learning-blogs-6730ea2df3bd', 'https://machinelearningmastery.com/blog/', 'https://towardsdatascience.com/how-to-start-a-machine-learning-blog-in-a-month-7eaf84692df9', 'http://ai.googleblog.com/', 'https://www.springboard.com/blog/machine-learning-blog/', 'https://blog.ml.cmu.edu/', 'https://blog.feedspot.com/machine_learning_blogs/', 'https://aws.amazon.com/blogs/machine-learning/', 'https://neptune.ai/blog/the-best-regularly-updated-machine-learning-blogs-or-resources', 'https://www.stxnext.com/blog/best-machine-learning-blogs-resources/']</span></pre><h1 id="cf6c" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">ç¬¬ä¸‰æ­¥:åˆ†æè¯¾æ–‡ï¼Œæ‰¾å‡ºæœ€é‡è¦çš„å•è¯ã€‚</h1><p id="2404" class="pw-post-body-paragraph kk kl it km b kn mg kp kq kr mh kt ku kv mi kx ky kz mj lb lc ld mk lf lg lh im bi translated">è®©æˆ‘ä»¬æƒ³æƒ³ã€‚æœ€é‡è¦çš„è¯æ˜¯ä»€ä¹ˆï¼Ÿåœ¨æˆ‘ä»¬çš„åˆ†æä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨3ä¸ªæŒ‡æ ‡ã€‚<strong class="km jd">å¹³å‡TF-IDFã€æœ€å¤§TF-IDF </strong>å’Œ<strong class="km jd">é¢‘ç‡ã€‚</strong>ç®¡é“å¦‚ä¸‹ã€‚æˆ‘ä»¬å°†è·å¾—æ¯ä¸ªç½‘ç«™çš„æ–‡æœ¬(åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯å‰12ä¸ªç»“æœ),å¹¶å°†å®ƒä»¬ç”¨ä½œTF-IDFçŸ¢é‡å™¨çš„è¯­æ–™åº“ã€‚ç„¶åä»è¿™ä¸ªçŸ©é˜µä¸­ï¼Œæˆ‘ä»¬å°†å¾—åˆ°æ¯ä¸ªå•è¯çš„å¹³å‡å’Œæœ€å¤§TF-IDFåˆ†æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°ä»TF-IDFçŸ©é˜µä¸­è·å¾—é¢‘ç‡ï¼Œæ–¹æ³•æ˜¯è¯´å¦‚æœè¿™ä¸ªè¯åœ¨è¿™ä¸€è¡Œä¸­ä¸ç­‰äºé›¶ï¼Œå®ƒå°±åŒ…å«åœ¨URLä¸­ï¼Œæˆ‘ä»¬æ­£åœ¨è®¡ç®—å®ƒçš„ç™¾åˆ†æ¯”ã€‚å®Œæ•´çš„å‡½æ•°å¦‚ä¸‹ã€‚</p><pre class="ml mm mn mo gt mp mq mr ms aw mt bi"><span id="c5c0" class="mu lj it mq b gy mv mw l mx my">def tf_idf_analysis(keyword):<br/>    links=google_results(keyword,12)<br/>    text=[]<br/>    for i in links:<br/>        t=get_text(i)<br/>        if t:<br/>            text.append(t)<br/>            <br/>    v = TfidfVectorizer(min_df=2,analyzer='word',ngram_range=(1,2),stop_words=stopWords)<br/>    x = v.fit_transform(text)<br/><br/>    f = pd.DataFrame(x.toarray(), columns = v.get_feature_names())<br/>    d=pd.concat([pd.DataFrame(f.mean(axis=0)),pd.DataFrame(f.max(axis=0))],axis=1)<br/>    <br/>    <br/>    tf=pd.DataFrame((f&gt;0).sum(axis=0))<br/><br/><br/>    d=d.reset_index().merge(tf.reset_index(),on='index',how='left')<br/><br/>    d.columns=['word','average_tfidf','max_tfidf','frequency']<br/><br/>#you can comment the following part if you want the number of URLs #that the word occurs. The percentage makes sense<br/>#when we have a lot of URLs to check<br/><br/>    d['frequency']=round((d['frequency']/len(text))*100)<br/><br/>    return(d)</span></pre><p id="e01f" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">ç°åœ¨æˆ‘ä»¬çš„æœ€ç»ˆå‡½æ•°å·²ç»å‡†å¤‡å¥½äº†ï¼Œè®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨<strong class="km jd">æœºå™¨å­¦ä¹ åšå®¢</strong>å…³é”®å­—æ¥çœ‹çœ‹æˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ æ–¹é¢çš„ç«äº‰å¯¹æ‰‹ã€‚</p><figure class="ml mm mn mo gt kd gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/0586950f38efcea9ebbe04b06efd9046.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/0*pwr-AnCQ1__JvMew.gif"/></div></figure><pre class="ml mm mn mo gt mp mq mr ms aw mt bi"><span id="dd17" class="mu lj it mq b gy mv mw l mx my">x= tf_idf_analysis('machine learning blog')<br/><br/>#remove the numbers and sort by max tfidf and get the top20 words<br/>x[x['word'].str.isalpha()].sort_values('max_tfidf',ascending=False).head(20)</span><span id="2109" class="mu lj it mq b gy mz mw l mx my">word  average_tfidf  max_tfidf  frequency<br/>929      google       0.098790   0.626160       67.0<br/>254         aws       0.052512   0.550785       25.0<br/>171      amazon       0.060131   0.537993       33.0<br/>1472      model       0.058276   0.521179       33.0<br/>307        blog       0.131429   0.385008      100.0<br/>133          ai       0.109516   0.358522       83.0<br/>1222   learning       0.191090   0.352528      100.0<br/>717         end       0.036682   0.304649       58.0<br/>1332    machine       0.158022   0.295191      100.0<br/>525     cookies       0.023013   0.263509       17.0<br/>1980        see       0.030134   0.255031       58.0<br/>439         cmu       0.028235   0.253162       17.0<br/>2242    towards       0.035054   0.245614       42.0<br/>862   followers       0.022837   0.245576       17.0<br/>1949    science       0.057179   0.240060       58.0<br/>670      domain       0.021410   0.236214       25.0<br/>739       entry       0.022586   0.233097       17.0<br/>944    gradient       0.019838   0.233097       17.0<br/>377    brownlee       0.021105   0.226498       25.0<br/>537     courses       0.024935   0.218224       25.0</span></pre><p id="e2e4" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå…¶ä¸­ä¸€ä¸ªçƒ­é—¨è¯æ±‡æ˜¯äºšé©¬é€ŠAWSã€‚å—¯ï¼Œä¹Ÿè®¸æˆ‘ä»¬ä¹Ÿåº”è¯¥å†™ç‚¹ä»€ä¹ˆğŸ˜‰ã€‚è¿™å¯èƒ½æ˜¯æ•°å­—è¥é”€çš„ä¸€ä¸ªå¼ºå¤§å·¥å…·ï¼Œæœ‰è®¸å¤šä»˜è´¹æœåŠ¡æ­£åœ¨è¿™æ ·åšã€‚æ‰€ä»¥å¼€å§‹å°è¯•å§ï¼</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="02aa" class="pw-post-body-paragraph kk kl it km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><em class="nj">åŸè½½äº</em><a class="ae na" href="https://predictivehacks.com/how-to-create-a-powerful-tf-idf-keyword-research-tool/" rel="noopener ugc nofollow" target="_blank"><em class="nj">https://predictivehacks.com</em></a><em class="nj">ã€‚</em></p></div></div>    
</body>
</html>