# ä½ åº”è¯¥çœ‹çœ‹è¿™ä¸ªæœ‰æ•ˆçš„æ¨¡å‹é€‰æ‹©æ¡†æ¶

> åŸæ–‡ï¼š<https://pub.towardsai.net/a-framework-for-model-selection-ea4dcda2cb3a?source=collection_archive---------0----------------------->

![](img/2cb4e7b2cbb22b027cb6a0a020982fe2.png)

åœ¨ [Unsplash](https://unsplash.com/s/photos/selection?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) ä¸Šç”± [vitamina poleznova](https://unsplash.com/@poleznova?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) æ‹æ‘„çš„ç…§ç‰‡

åœ¨æ¯ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬éƒ½éœ€è¦é€‰æ‹©ä¸€ä¸ªæ¨¡å‹æ¥æ”¹å–„æˆ‘ä»¬çš„èµ·å§‹åŸºçº¿ã€‚

äº‹å®ä¸Šï¼Œå¦‚æœåŸºçº¿ç»™äº†æˆ‘ä»¬ä¸€ä¸ªæœ‰ç”¨çš„èµ·å§‹æ¨¡å‹æ¥ç†è§£æˆ‘ä»¬å¯ä»¥ä»ä¸€ä¸ªéå¸¸ç®€å•çš„è§£å†³æ–¹æ¡ˆä¸­æœŸå¾…ä»€ä¹ˆï¼Œé‚£ä¹ˆé€šè¿‡**ä¸€ä¸ªç‰¹å®šçš„æ–¹æ³•è®º**é€‰æ‹©çš„æ¨¡å‹å¸®åŠ©æˆ‘ä»¬å¹³ç¨³åœ°è¿›å…¥é¡¹ç›®çš„ä¼˜åŒ–é˜¶æ®µã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†ä¸ä½ åˆ†äº«æˆ‘çš„ä¸ªäººæ¡†æ¶(å’Œä»£ç åº“),ä»¥æœ‰ç»„ç»‡å’Œç»“æ„åŒ–çš„æ–¹å¼è¿›è¡Œæ¨¡å‹é€‰æ‹©ã€‚

# è¯¥æ–¹æ³•

å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå›å½’é—®é¢˜è¦è§£å†³ã€‚è®©æˆ‘ä»¬ä»å¯¼å…¥æ‰€éœ€çš„åº“å’Œé…ç½®æ—¥å¿—æœºåˆ¶å¼€å§‹

```
**from** **sklearn** **import** linear_model
**from** **sklearn** **import** ensemble
**from** **sklearn** **import** tree
**from** **sklearn** **import** svm
**from** **sklearn** **import** neighbors
**from** **lightgbm** **import** LGBMRegressor
**from** **xgboost** **import** XGBRegressor
**import** **logging**logging.basicConfig(level=logging.INFO)
```

æˆ‘éµå¾ªçš„æ€ç»´æ¨¡å¼å¦‚ä¸‹:

1.  æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨å¹¶ç”¨å¯¹( *model_name* ï¼Œ *model* )å¡«å……å®ƒ
2.  æˆ‘ä»¬å°†é€šè¿‡ Scikit-Learn KFold äº¤å‰éªŒè¯æ¥å®šä¹‰åˆ†å‰²æ•°æ®çš„å‚æ•°
3.  æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª for å¾ªç¯ï¼Œäº¤å‰éªŒè¯æ¯ä¸ªæ¨¡å‹å¹¶ä¿å­˜å…¶æ€§èƒ½
4.  æˆ‘ä»¬å°†æŸ¥çœ‹æ¯ä¸ªå‹å·çš„æ€§èƒ½ï¼Œä»¥ä¾¿é€‰æ‹©æ€§èƒ½æœ€ä½³çš„å‹å·
5.  æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåˆ—è¡¨å¹¶æ’å…¥æˆ‘ä»¬æƒ³è¦æµ‹è¯•çš„æ¨¡å‹ã€‚

è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåˆ—è¡¨ï¼Œå¹¶æ’å…¥æˆ‘ä»¬æƒ³è¦æµ‹è¯•çš„æ¨¡å‹ã€‚

```
models = []
models.append(('Lasso', linear_model.Lasso()))
models.append(('Ridge', linear_model.Ridge()))
models.append(('EN', linear_model.ElasticNet()))
models.append(('RandomForest', ensemble.RandomForestRegressor()))
models.append(('KNR', neighbors.KNeighborsRegressor()))
models.append(('DT', tree.DecisionTreeRegressor()))
models.append(('ET', tree.ExtraTreeRegressor()))
models.append(('LGBM', LGBMRegressor()))
models.append(('XGB', XGBRegressor()))
models.append(('GBM', ensemble.GradientBoostingRegressor()))
models.append(("SVR", svm.LinearSVR()))
```

å¯¹äºå±äº*æ¨¡å‹çš„*åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å°†é€šè¿‡ [model_selection æ¥è¯„ä¼°å…¶æ€§èƒ½ã€‚KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) ã€‚å®ƒçš„å·¥ä½œæ–¹å¼ç›¸å½“ç®€å•:æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†( *X_trainï¼Œy_train* )å°†è¢«åˆ†æˆç›¸ç­‰çš„éƒ¨åˆ†(ç§°ä¸º *folds* )ï¼Œåˆ†åˆ«è¿›è¡Œæµ‹è¯•ã€‚å› æ­¤ï¼ŒKFold äº¤å‰éªŒè¯å°†**æä¾›æ¯ä¸ªåˆ†å‰²çš„å¹³å‡æ€§èƒ½æŒ‡æ ‡ï¼Œè€Œä¸æ˜¯åŸºäºæ•´ä¸ªè®­ç»ƒæ•°æ®é›†çš„å•ä¸€æŒ‡æ ‡**ã€‚è¿™é¡¹æŠ€æœ¯éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒå…è®¸æ‚¨æ›´ç²¾ç¡®åœ°æµ‹é‡æ¨¡å‹çš„æ€§èƒ½ã€‚

ç”±äºè¿™æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å‡æ–¹å·®(MSE)åº¦é‡ã€‚

è®©æˆ‘ä»¬å®šä¹‰äº¤å‰éªŒè¯çš„å‚æ•°ï¼Œå¹¶åˆå§‹åŒ–å¾ªç¯çš„ã€‚

```
n_folds = **5** # number of splits 
results = [] # save the performances in this list
names = [] # this list helps us save the model names for visualization

# we begin the loop where we'll test each model in the models list
**for** name, model **in** models:
    kfold = model_selection.KFold(n_splits=n_folds)
    logging.INFO("Testing model:", name) cv_results = model_selection.cross_val_score(
        model, # the model picked from the list
        X_train, # feature train set
        y_train, # target train set
        cv=kfold, # current split
        scoring="neg_mean_squared_error", 
        verbose=**0**, 
        n_jobs=-**1**) results.append(cv_results)
    names.append(name) msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std()) logging.INFO(msg+"**\n**")
```

æ¯ä¸ªæ¨¡å‹éƒ½å°†è¿›è¡Œäº¤å‰éªŒè¯å’Œæµ‹è¯•ï¼Œå…¶æ€§èƒ½å°†ä¿å­˜åœ¨*ç»“æœ*ä¸­ã€‚

å¯è§†åŒ–éå¸¸ç®€å•ï¼Œå°†é€šè¿‡ç®±çº¿å›¾æ¥å®Œæˆã€‚

```
# Compare our models in a box plot
fig = plt.figure(figsize=(**12**,**7**))
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(**111**)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()
```

# æœ€åçš„ç»“æœ

æœ€ç»ˆç»“æœå°†æ˜¯è¿™æ ·çš„:

![](img/303621704a543ad26c19f761b7569576.png)

æˆ‘ä»¬çš„æ¨¡å‹é€‰æ‹©è„šæœ¬çš„æœ€ç»ˆè¾“å‡º

ä»è¿™é‡Œå¯ä»¥çœ‹å‡º RandomForest å’Œ GradientBoostingMachine æ˜¯å¦‚ä½•è¡¨ç°æœ€å¥½çš„æœºå‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹åˆ›å»ºæ–°çš„å®éªŒï¼Œå¹¶è¿›ä¸€æ­¥æµ‹è¯•è¿™ä¸¤ä¸ªæ¨¡å‹ã€‚

# æŠŠæ‰€æœ‰çš„æ”¾åœ¨ä¸€èµ·

è¿™æ˜¯ç”¨äºæ¨¡å‹é€‰æ‹©çš„å¤åˆ¶ç²˜è´´æ¨¡æ¿ï¼Œæˆ‘ä¼šåœ¨ model_selection.py è„šæœ¬ä¸­æ–¹ä¾¿åœ°ä½¿ç”¨å®ƒ(æˆ‘åœ¨è¿™é‡Œè®¨è®ºå¦‚ä½•æ„å»ºä¸€ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®

ç”¨äºæ¨¡å‹é€‰æ‹©çš„å¤åˆ¶-ç²˜è´´å°±ç»ªæ¨¡æ¿

# ç»“è®º

å¾ˆé«˜å…´ä½ æ¥äº†ã€‚å¸Œæœ›æ‚¨ä¼šå‘ç°è¿™ç¯‡æ–‡ç« å¾ˆæœ‰ç”¨ï¼Œå¹¶åœ¨æ‚¨çš„ä»£ç åº“ä¸­å®ç°å…¶ä¸­çš„ä¸€äº›ç‰‡æ®µã€‚

å¦‚æœä½ æƒ³æ”¯æŒæˆ‘çš„å†…å®¹åˆ›ä½œæ´»åŠ¨ï¼Œè¯·éšæ—¶å…³æ³¨æˆ‘ä¸‹é¢çš„æ¨èé“¾æ¥ï¼Œå¹¶åŠ å…¥ Medium çš„ä¼šå‘˜è®¡åˆ’ã€‚æˆ‘å°†è·å¾—ä½ æŠ•èµ„çš„ä¸€éƒ¨åˆ†ï¼Œä½ å°†èƒ½å¤Ÿä»¥æ— ç¼çš„æ–¹å¼è®¿é—® Medium çš„å¤§é‡æ•°æ®ç§‘å­¦æ–‡ç« ã€‚

[](https://medium.com/@theDrewDag/membership) [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium-Andrew D # data science

### é˜…è¯» Andrew D #datascience(ä»¥åŠåª’ä½“ä¸Šæˆåƒä¸Šä¸‡çš„å…¶ä»–ä½œè€…)çš„æ¯ä¸€ä¸ªæ•…äº‹ã€‚æ‚¨çš„ä¼šå‘˜è´¹ç›´æ¥â€¦

medium.com](https://medium.com/@theDrewDag/membership) 

ç¥ä½ æ„‰å¿«ã€‚ç•™å¾—å®‰å¥½ğŸ‘‹