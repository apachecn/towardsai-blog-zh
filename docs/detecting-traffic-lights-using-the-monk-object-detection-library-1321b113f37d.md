# ä½¿ç”¨ Monk å¯¹è±¡æ£€æµ‹åº“æ£€æµ‹äº¤é€šç¯

> åŸæ–‡ï¼š<https://pub.towardsai.net/detecting-traffic-lights-using-the-monk-object-detection-library-1321b113f37d?source=collection_archive---------5----------------------->

## [è®¡ç®—æœºè§†è§‰](https://towardsai.net/p/category/computer-vision)

## è¿™ç¯‡æ–‡ç« æ˜¯ä¸€ä¸ªå¦‚ä½•ä½¿ç”¨ MONK å¯¹è±¡æ£€æµ‹åº“çš„ä¾‹å­ã€‚

![](img/af2bef9ca286f03d9fbc4baf04b174c9.png)

ç”±[å…‹é‡Œæ–¯Â·å¥¥ç“¦å°”](https://unsplash.com/@crisovalle?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

å¯¹äºè¿™ä¸ªé¡¹ç›®çš„ç¬”è®°æœ¬è®¿é—®[è¿™é‡Œ](https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Lara%20Traffic%20Lights%20Detection%20Dataset.ipynb)ã€‚

æ¬²äº†è§£æ›´å¤šå…³äºåƒ§ä¾£å¯¹è±¡æ£€æµ‹çš„ç¤ºä¾‹ï¼Œè¯·è®¿é—®[æ­¤å¤„](https://github.com/Tessellate-Imaging/Monk_Object_Detection/tree/master/application_model_zoo)ã€‚

# å…³äºé¡¹ç›®:

åœ¨ä¸€ä¸ªæ— äººé©¾é©¶æ±½è½¦ã€äº¤é€šç¯ğŸš¦ä¼šæˆä¸ºè¿‡å»ã€‚ä½†åªè¦äººç±»åœ¨æ—è¾¹è¡Œé©¶ï¼Œè‡ªåŠ¨é©¾é©¶è½¦è¾†å°±å¿…é¡»éµå¾ªäººç±»åˆ¶å®šçš„è§„åˆ™ã€‚è¿™äº›è§„åˆ™ä¹‹ä¸€æ˜¯éµå®ˆäº¤é€šä¿¡å·ç¯ã€‚è‡ªåŠ¨é©¾é©¶æ±½è½¦ğŸš—å¿…é¡»æ£€æµ‹å’Œè¯†åˆ«äº¤é€šç¯ï¼Œä»¥é¿å…äº‹æ•…å’Œè¡—é“ä¸Šçš„æ··ä¹±ã€‚
è¿™æ˜¯æˆ‘æœ€è¿‘å¯¹ Tessellate Imaging Monk å¯¹è±¡æ£€æµ‹åº“çš„è´¡çŒ®ã€‚æœŸå¾…å°†å…¶éƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡ã€‚

# å…³äºæ•°æ®é›†:

åœ¨æ­¤å¯ä»¥æŸ¥çœ‹æ•°æ®é›†[ã€‚æ•°æ®é›†æ–‡ä»¶åŒ…å«**9168 ä¸ªäº¤é€šç¯å®ä¾‹ï¼Œæ‰‹å·¥æ ‡è®°ä¸º**ã€‚çº¢ç»¿ç¯ç»†èŠ‚å¦‚ä¸‹:**3381â€œç»¿è‰²â€**(å«*â€˜è¡Œâ€™*)**58â€œæ©™è‰²â€**(å«*â€˜è­¦å‘Šâ€™*)**5280â€œçº¢è‰²â€**(å«*â€˜åœâ€™*)**449â€œæš§æ˜§â€ã€‚**](http://www.lara.prd.fr/benchmarks/trafficlightsrecognition)

# é¡¹ç›®ç›®æ ‡:

1.  å®‰è£…[å’Œå°šç‰©ä½“æ£€æµ‹åº“](https://github.com/Tessellate-Imaging/Monk_Object_Detection)
2.  ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ¥æ£€æµ‹äº¤é€šç¯ã€‚
3.  ä»å¤´å¼€å§‹è®­ç»ƒäº¤é€šç¯æ£€æµ‹æ¨¡å‹ã€‚

## 1.å®‰è£…åƒ§ä¾£å›¾ä¹¦é¦†

è¿è¡Œè¿™äº›å‘½ä»¤

```
!git clone [https://github.com/Tessellate-Imaging/Monk_Object_Detection.git](https://github.com/Tessellate-Imaging/Monk_Object_Detection.git)!cd Monk_Object_Detection/16_mmdet/installation
```

é€‰æ‹©æ­£ç¡®çš„æ–‡ä»¶å¹¶è¿è¡Œ

```
!chmod +x install.sh && ./install.sh
```

## 2.ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ¥æ£€æµ‹äº¤é€šç¯ã€‚

è¦ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹åœ¨æµ‹è¯•å›¾åƒä¸ŠåŠ è½½å’Œè¿è¡Œæ¨ç†ï¼Œè¯·éµå¾ªä»¥ä¸‹ä»£ç ã€‚

å¯¼å…¥ MONK å¯¹è±¡æ£€æµ‹å¹¶åˆ›å»ºä¸€ä¸ªæ¨æ–­ç±»çš„å¯¹è±¡ã€‚

```
import os
import sys
sys.path.append("Monk_Object_Detection/16_mmdet/lib")from infer_engine import Infer
gtf = Infer();
```

ä»é©±åŠ¨å™¨ä¸‹è½½é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è§£å‹ã€‚

```
! wget --load-cookies /tmp/cookies.txt "[https://docs.google.com/uc?export=download&confirm=$(wget](https://docs.google.com/uc?export=download&confirm=$(wget) --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate '[https://docs.google.com/uc?export=download&id=1XLSAp7YAYBY8xwKURiehj_uerHTJeq5n'](https://docs.google.com/uc?export=download&id=1XLSAp7YAYBY8xwKURiehj_uerHTJeq5n') -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=1XLSAp7YAYBY8xwKURiehj_uerHTJeq5n" -O obj_traffic2_trained.zip && rm -rf /tmp/cookies.txt! unzip -qq obj_traffic2_trained.zip
```

åŠ è½½æ¨¡å‹å‚æ•°ã€‚

```
gtf.Model_Params("work_dirs/config_updated/config_updated.py", 
                 "work_dirs/config_updated/latest.pth")
```

å¯¹æ‚¨æƒ³è¦çš„å›¾åƒè¿è¡Œ Predict()å‡½æ•°ã€‚

```
result = gtf.Predict(img_path="Test_images/test1.jpg",
           out_img_path="result.jpg",
           thresh=0.8);
from IPython.display import Image
Image(filename='result.jpg')
```

![](img/0305a880e1b2c67c014eb2d992afc624.png)![](img/2ef6f0f00e2ccccf6de4822936ba013f.png)

# ä»å¤´å¼€å§‹è®­ç»ƒäº¤é€šç¯æ£€æµ‹æ¨¡å‹

## æ¶‰åŠçš„æ­¥éª¤

1.  ä¸‹è½½æ•°æ®é›†
2.  å°† CVML æ ‡æ³¨æ ¼å¼è½¬æ¢ä¸º COCO æ ¼å¼
3.  ä½¿ç”¨ [MMDet](https://github.com/open-mmlab/mmdetection) è®­ç»ƒæ¨¡å‹

## 1.ä¸‹è½½æ•°æ®é›†

æ•°æ®é›†å­¦åˆ†:[çº¢ç»¿ç¯è¯†åˆ«(TLR)å…¬å…±åŸºå‡†](http://www.lara.prd.fr/benchmarks/trafficlightsrecognition)ã€‚ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ•°æ®é›†å¯ä»¥ä¸‹è½½åˆ°ä½ çš„æœºå™¨ä¸Šã€‚

```
!wget [http://s150102174.onlinehome.fr/Lara/files/Lara_UrbanSeq1_JPG.zip](http://s150102174.onlinehome.fr/Lara/files/Lara_UrbanSeq1_JPG.zip)
```

è§£å‹ç¼©æ•°æ®é›†:

```
!unzip Lara_UrbanSeq1_JPG.zip
```

## 2.è½¬æ¢ CVML åˆ°å¯å¯æ ¼å¼ã€‚

è¿™ä¸€æ­¥æ˜¯å¿…éœ€çš„ï¼Œå› ä¸ºæ•°æ®é›†çš„æ ‡æ³¨æ˜¯ CVML æ ¼å¼ï¼Œå› æ­¤éœ€è¦è½¬æ¢ä¸º COCO æ ¼å¼ã€‚

æ›´å¤šè¯¦æƒ…è¯·å‚è€ƒæœ¬åšå®¢: [CVML æ³¨è§£â€”â€”ä»€ä¹ˆæ˜¯æ³¨è§£ï¼Œå¦‚ä½•è½¬æ¢ï¼Ÿ](https://medium.com/towards-artificial-intelligence/cvml-annotation-what-it-is-and-how-to-convert-it-7b818dc30c9f)

å°† CVML è½¬æ¢ä¸ºåƒ§ä¾£ç±»å‹çš„ä»£ç 

```
import os
import sys
import numpy as np
import pandas as pd
import xmltodict
import json
from tqdm.notebook import tqdm
import collections
from pycocotools.coco import COCOimg_dir = "Lara3D_UrbanSeq1_JPG/";annoFile="Lara_UrbanSeq1_GroundTruth_cvml.xml"
f = open(annoFile, 'r');
my_xml = f.read();
anno = dict(dict(xmltodict.parse(my_xml))["dataset"])combined=[]
count=0;
for frame in tqdm(anno['frame']):
    fname=file_content[count].strip()
    count+=1
    label_str = "";
    width=640
    height=480
    if(type(frame["objectlist"]) ==collections.OrderedDict):
        if(type(frame["objectlist"]['object']) == list):
            for j,i in enumerate(frame['objectlist']['object']):
                x1=max(int(i['box']['[@xc](http://twitter.com/xc)'])-int(i['box']['[@w](http://twitter.com/w)'])/2,0)
                y1=max(int(i['box']['[@yc](http://twitter.com/yc)'])-int(i['box']['[@h](http://twitter.com/h)'])/2,0)
                x2=min(int(i['box']['[@xc](http://twitter.com/xc)'])+int(i['box']['[@w](http://twitter.com/w)'])/2,width)
                y2=min(int(i['box']['[@yc](http://twitter.com/yc)'])+int(i['box']['[@h](http://twitter.com/h)'])/2,height)
                label=i['hypothesislist']['hypothesis']['subtype']['#text']
                label_str+=str(x1)+" "+str(y1)+" "+str(x2)+" "+str(y2)+" "+label+" "else:
            x1=max(0,int(frame["objectlist"]['object']['box']['[@xc](http://twitter.com/xc)'])-int(frame["objectlist"]['object']['box']['[@w](http://twitter.com/w)'])/2)
            y1=max(0,int(frame["objectlist"]['object']['box']['[@yc](http://twitter.com/yc)'])-int(frame["objectlist"]['object']['box']['[@h](http://twitter.com/h)'])/2)
            x2=min(width,int(frame["objectlist"]['object']['box']['[@xc](http://twitter.com/xc)'])+int(frame["objectlist"]['object']['box']['[@w](http://twitter.com/w)'])/2)
            y2=min(height,int(frame["objectlist"]['object']['box']['[@yc](http://twitter.com/yc)'])+int(frame["objectlist"]['object']['box']['[@h](http://twitter.com/h)'])/2)
            label=frame["objectlist"]['object']['hypothesislist']['hypothesis']['subtype']['#text']
            label_str += str(x1)+" "+str(y1)+" "+str(x2)+" "+str(y2)+" " + label

    combined.append([fname,label_str.strip()])df = pd.DataFrame(combined, columns = ['ID', 'Label']);
df.to_csv("train_labels.csv", index=False);
```

å’Œå°šåˆ°å¯å¯ç±»å‹

```
import os
import numpy as np 
import cv2
import dicttoxml
import xml.etree.ElementTree as ET
from xml.dom.minidom import parseString
from tqdm import tqdm
import shutil
import json
import pandas as pdroot = "./";
img_dir = "Lara3D_UrbanSeq1_JPG/";
anno_file = "train_labels.csv";dataset_path = root;
images_folder = root + "/" + img_dir;
annotations_path = root + "/annotations/";if not os.path.isdir(annotations_path):
    os.mkdir(annotations_path)

input_images_folder = images_folder;
input_annotations_path = root + "/" + anno_file;output_dataset_path = root;
output_image_folder = input_images_folder;
output_annotation_folder = annotations_path;tmp = img_dir.replace("/", "");
output_annotation_file = output_annotation_folder + "/instances_" + tmp + ".json";
output_classes_file = output_annotation_folder + "/classes.txt";if not os.path.isdir(output_annotation_folder):
    os.mkdir(output_annotation_folder);df = pd.read_csv(input_annotations_path);
columns = df.columnsdelimiter = " ";list_dict = [];
anno = [];
for i in range(len(df)):
    img_name = df[columns[0]][i];
    labels = df[columns[1]][i];
    tmp = str(labels).split(delimiter);
    for j in range(len(tmp)//5):
        label = tmp[j*5+4];
        if(label not in anno):
            anno.append(label);
    anno = sorted(anno)

for i in tqdm(range(len(anno))):
    tmp = {};
    tmp["supercategory"] = "master";
    tmp["id"] = i;
    tmp["name"] = anno[i];
    list_dict.append(tmp);anno_f = open(output_classes_file, 'w');
for i in range(len(anno)):
    anno_f.write(anno[i] + "\n");
anno_f.close();coco_data = {};
coco_data["type"] = "instances";
coco_data["images"] = [];
coco_data["annotations"] = [];
coco_data["categories"] = list_dict;
image_id = 0;
annotation_id = 0;for i in tqdm(range(len(df))):
    img_name = df[columns[0]][i];
    labels = df[columns[1]][i];
    tmp = str(labels).split(delimiter);
    image_in_path = input_images_folder + "/" + img_name;
    img = cv2.imread(image_in_path, 1);
    h, w, c = img.shape;images_tmp = {};
    images_tmp["file_name"] = img_name;
    images_tmp["height"] = h;
    images_tmp["width"] = w;
    images_tmp["id"] = image_id;
    coco_data["images"].append(images_tmp);for j in range(len(tmp)//5):
        x1 = float(tmp[j*5+0]);
        y1 = float(tmp[j*5+1]);
        x2 = float(tmp[j*5+2]);
        y2 = float(tmp[j*5+3]);
        label = tmp[j*5+4];
        annotations_tmp = {};
        annotations_tmp["id"] = annotation_id;
        annotation_id += 1;
        annotations_tmp["image_id"] = image_id;
        annotations_tmp["segmentation"] = [];
        annotations_tmp["ignore"] = 0;
        annotations_tmp["area"] = (x2-x1)*(y2-y1);
        annotations_tmp["iscrowd"] = 0;
        annotations_tmp["bbox"] = [x1, y1, x2-x1, y2-y1];
        annotations_tmp["category_id"] = anno.index(label);coco_data["annotations"].append(annotations_tmp)
    image_id += 1;outfile =  open(output_annotation_file, 'w');
json_str = json.dumps(coco_data, indent=4);
outfile.write(json_str);
outfile.close();
```

# 2.åŸ¹è®­æ¨¡å¼

åŠ è½½ monk å¹¶åˆ›å»ºä¸€ä¸ªæ£€æµ‹å™¨ç±»çš„å¯¹è±¡ã€‚

```
import os
import sys
sys.path.append(â€œMonk_Object_Detection/16_mmdet/libâ€)from train_engine import Detector
gtf = Detector();
```

æŸ¥æ‰¾æ‰€éœ€çš„æ–‡ä»¶ã€‚

```
img_dir = "Lara3D_UrbanSeq1_JPG";
annofile = "annotations/instances_Lara3D_UrbanSeq1_JPG.json"
class_file = "annotations/classes.txt"
```

åŠ è½½æ•°æ®é›†ã€ç»™å®šæ•°æ®é›†å‚æ•°ã€åŠ è½½æ¨¡å‹æ¶æ„ä»¥åŠè°ƒæ•´è¶…å‚æ•°:

```
gtf.Train_Dataset(img_dir, annofile, class_file);
gtf.Dataset_Params(batch_size=8, num_workers=2);
gtf.Model_Params(model_name="faster_rcnn_fpn50");
gtf.Hyper_Params(lr=0.02, momentum=0.9, weight_decay=0.0001);
```

å¼€å§‹åŸ¹è®­:

```
gtf.Training_Params(num_epochs=50, val_interval=1);
gtf.Train();
```

## 3.å¯¹æµ‹è¯•å›¾åƒè¿›è¡Œæ¨ç†

è¦ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹åœ¨æµ‹è¯•å›¾åƒä¸ŠåŠ è½½å’Œè¿è¡Œæ¨ç†ï¼Œè¯·éµå¾ªä»¥ä¸‹ä»£ç ã€‚

å¯¼å…¥ MONK å¯¹è±¡æ£€æµ‹å¹¶åˆ›å»ºä¸€ä¸ªæ¨æ–­ç±»çš„å¯¹è±¡ã€‚

```
import os
import sys
sys.path.append(â€œMonk_Object_Detection/16_mmdet/libâ€)from infer_engine import Infer
gtf=Infer();
```

åŠ è½½æ¨¡å‹å‚æ•°ã€‚

```
gtf.Model_Params("work_dirs/config_updated/config_updated.py", 
                 "work_dirs/config_updated/latest.pth")
```

å¯¹æ‚¨æƒ³è¦çš„å›¾åƒè¿è¡Œ Predict()å‡½æ•°ã€‚

```
result = gtf.Predict(img_path="Test_images/test1.jpg",
           out_img_path="result.jpg",
           thresh=0.8);
from IPython.display import Image
Image(filename='result.jpg')
```

![](img/0305a880e1b2c67c014eb2d992afc624.png)![](img/2ef6f0f00e2ccccf6de4822936ba013f.png)![](img/ab523682207907cd22c025f0d67798ee.png)

å¦‚éœ€æ›´å¤šæµ‹è¯•å›¾ç‰‡ï¼Œæˆ–æŸ¥çœ‹å®Œæ•´ç¬”è®°æœ¬ï¼Œè¯·è®¿é—®[æ­¤å¤„](https://github.com/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Lara%20Traffic%20Lights%20Detection%20Dataset.ipynb)ã€‚

# ç»“è®º

1.  Monk library è®©å­¦ç”Ÿã€ç ”ç©¶äººå‘˜å’Œç«äº‰å¯¹æ‰‹å¯ä»¥éå¸¸è½»æ¾åœ°åˆ›å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å°è¯•ä¸åŒçš„è¶…å‚æ•°è°ƒæ•´æ¥æé«˜æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚
2.  é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹å¯ä»¥ç›´æ¥ä¸‹è½½ä½¿ç”¨ï¼Œè€Œæ— éœ€è¿›å…¥æ¨¡å‹åˆ›å»ºéƒ¨åˆ†ã€‚
3.  ä½¿ç”¨ Monk ä½¿è¿™ä¸ªè¿‡ç¨‹å˜å¾—ç®€å•ï¼Œè€—æ—¶æ›´å°‘ã€‚

# æ„Ÿè°¢é˜…è¯»ã€‚

å¦‚æœä½ è¯»åˆ°è¿™é‡Œï¼Œè¯·ä¸ºè¿™ç¯‡æ–‡ç« é¼“æŒã€‚è¿˜æœ‰ï¼Œåœ¨ [LinkedIn](https://www.linkedin.com/in/rohit96/) ä¸Šå’Œæˆ‘è”ç³»ã€‚