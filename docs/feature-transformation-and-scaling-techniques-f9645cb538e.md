# ç‰¹å¾å˜æ¢å’Œç¼©æ”¾æŠ€æœ¯

> åŸæ–‡ï¼š<https://pub.towardsai.net/feature-transformation-and-scaling-techniques-f9645cb538e?source=collection_archive---------1----------------------->

## [æœºå™¨å­¦ä¹ ](https://towardsai.net/p/category/machine-learning)

## æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½çš„ 9 ç§æ–¹æ³•

![](img/a3fcbae28b3d288ae3fbfe8b151b33cc.png)

ç”±[è‹çŠÂ·å¨å»‰å§†æ–¯](https://unsplash.com/@scw1217?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

ç‰¹å¾å˜æ¢åªæ˜¯å°†ç‰¹å¾ä»ä¸€ç§è¡¨ç¤ºå½¢å¼å˜æ¢åˆ°å¦ä¸€ç§è¡¨ç¤ºå½¢å¼çš„å‡½æ•°ã€‚è¦ç´ ç¼©æ”¾æ˜¯ä¸€ç§è½¬æ¢åŒä¸€èŒƒå›´å†…è¦ç´ çš„æ‰€æœ‰å€¼çš„æŠ€æœ¯ã€‚æ¯”å¦‚ 0 æ¯” 1ã€‚

**ä¸ºä»€ä¹ˆç‰¹æ€§è½¬æ¢æ˜¯å¿…è¦çš„ï¼Ÿï¼Ÿ**

æœ‰æ—¶ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†ä¸­ä¸åŒçš„åˆ—æœ‰ä¸åŒçš„å•ä½ï¼Œæ¯”å¦‚ä¸€åˆ—å¯ä»¥ç”¨åƒç±³è¡¨ç¤ºï¼Œè€Œå¦ä¸€åˆ—å¯ä»¥ç”¨ç±³æˆ–å˜ç±³è¡¨ç¤ºã€‚æˆ–è€…åœ¨ç›¸åŒçš„åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå¹´é¾„åˆ—ï¼ŒèŒƒå›´ä» 0 åˆ° 1000ï¼Œå¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªè–ªæ°´åˆ—ï¼Œæ‰€æœ‰å€¼éƒ½å¤§äº 10ï¼Œ000ã€‚é‚£ä¹ˆåœ¨è¿™æ ·çš„åœºæ™¯ä¸‹ï¼Œè¿™äº›å€¼ä¹‹é—´çš„å·®å¼‚å°±å˜å¾—éå¸¸å¤§ã€‚ç”±äºè¿™ç§å·®å¼‚ï¼Œ**å€¼è¶Šå¤§çš„åˆ—å¯¹è¾“å‡ºçš„å½±å“è¶Šå¤§ã€‚**å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ‰§è¡Œç‰¹å¾ç¼©æ”¾å’Œå˜æ¢ï¼Œä»¥ä½¿æ‰€æœ‰å€¼ä½äºç›¸åŒçš„èŒƒå›´å†…ã€‚

åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®º 9 ç§åŠŸèƒ½ç¼©æ”¾å’Œè½¬æ¢æŠ€æœ¯ã€‚

1.  æœ€å°æœ€å¤§ç¼©æ”¾å™¨
2.  æ ‡å‡†ç¼©æ”¾å™¨
3.  MaxAbsScaler
4.  é²æ£’å®šæ ‡å™¨
5.  åˆ†ä½æ•°å˜å‹å™¨å®šæ ‡å™¨
6.  å¯¹æ•°å˜æ¢
7.  ç”µåŠ›å˜å‹å™¨å®šæ ‡å™¨
8.  å•ä½å‘é‡ç¼©æ”¾å™¨/è§„æ ¼åŒ–å™¨

è®©æˆ‘ä»¬ä»ä½¿ç”¨ pandas åˆ›å»ºä¸€ä¸ªæ›´ç®€å•çš„æ•°æ®æ¡†å¼€å§‹

```
### TO REMOVE UNECESSARY WARNINGS #####
import warnings
warnings.filterwarnings('ignore')import numpy as np
import matplotlib.pyplot as plt
import pandas as pd%matplotlib inlinedf = pd.DataFrame({
    'salary':[18000,20000,10000,2600,23000],
    'age':[23,24,20,18,28],
    'department':['HR','Marketing','Development','Managment','Legal']
})
df.head()
```

## 1ï¸âƒ£æœ€å°æœ€å¤§ç¼©æ”¾å™¨

æœ€å°æœ€å¤§ç¼©æ”¾å™¨æ˜¯ç†è§£å’Œå®ç°èµ·æ¥æ¯”è¾ƒç®€å•çš„ç¼©æ”¾å™¨ä¹‹ä¸€ã€‚å®ƒç¼©å° 0 åˆ° 1 ä¹‹é—´çš„æ‰€æœ‰å€¼ã€‚åˆ—ä¸­çš„æœ€å¤§å€¼è¢«èµ‹äºˆå€¼ 1ï¼Œåˆ—ä¸­çš„æœ€å°å€¼è¢«èµ‹äºˆå€¼ 0ï¼Œé™¤æ­¤ä¹‹å¤–çš„æ‰€æœ‰å€¼è¢«èµ‹äºˆ 0 åˆ° 1 ä¹‹é—´çš„å€¼ã€‚

**å…¬å¼:**

## ***x _ scaled =(xâ€”x _ min)/(x _ maxâ€”x _ min)***

x_scaled =ç¼©æ”¾åçš„ col å€¼
x =åŸå§‹å€¼
x_min =åˆ—ä¸­çš„æœ€å°å€¼
x_max =åˆ—ä¸­çš„æœ€å¤§å€¼

```
**### Defining Scaler ###**
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()**#### MinMax Scaling ###** col_names = ['salary', 'age']
features = df[col_names]
features[col_names] = scaler.fit_transform(features.values)
features
```

![](img/a3d46005bd43b942d904df32c6e49764.png)

æœ€å°æœ€å¤§ç¼©æ”¾å™¨å°†ç¼©å° 0 åˆ° 1 ä¹‹é—´çš„æ‰€æœ‰å€¼ã€‚å¦‚æœæˆ‘ä»¬æƒ³åœ¨è‡ªå®šä¹‰èŒƒå›´å†…ç¼©å°æ•°å€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **feature_range** å®šä¹‰æˆ‘ä»¬è‡ªå·±çš„èŒƒå›´ã€‚

```
### Defining Scaler ###
from sklearn.preprocessing import **MinMaxScaler**
**scaler = MinMaxScaler(feature_range=(2,4)) ##Custom Scaling Range**#### MinMax Scaling ###
col_names = ['salary', 'age']
features = df[col_names]
features[col_names] = scaler.fit_transform(features.values)
features
```

![](img/604bcb5f74d2992dd9f5b9ec8b8193db.png)

## 2ï¸âƒ£æ ‡å‡†æ ‡å°º

æ ‡å‡†å®šæ ‡å™¨ä¹Ÿæ˜¯æœ€å¸¸ç”¨å’Œæœ€å®¹æ˜“ç†è§£çš„å®šæ ‡å™¨ä¹‹ä¸€ã€‚å®ƒä¸æ˜¯åœ¨ 0 åˆ° 1 ä¹‹é—´ç¼©æ”¾å€¼ï¼Œè€Œæ˜¯ä»¥å‡å€¼ä¸º 0ã€æ–¹å·®ä¸º 1 çš„æ–¹å¼ç¼©æ”¾å€¼ã€‚

å…¬å¼:-

## **x_scaled = x â€”å¹³å‡å€¼/æ ‡å‡†å·®**

æ ‡å‡†å®šæ ‡å™¨å‡è®¾å˜é‡çš„åˆ†å¸ƒæ˜¯æ­£æ€çš„ã€‚å› æ­¤åœ¨å˜é‡ä¸æ˜¯æ­£æ€åˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼Œ

1.  æˆ–è€…ï¼Œé€‰æ‹©ä¸åŒçš„ç¼©æ”¾å™¨
2.  æˆ–è€…é¦–å…ˆï¼Œå°†å˜é‡è½¬æ¢ä¸ºæ­£æ€åˆ†å¸ƒï¼Œç„¶ååº”ç”¨ scalerã€‚

```
from sklearn.preprocessing import **StandardScaler**
scaler = StandardScaler()col_names = ['salary', 'age']
features = df[col_names]
features[col_names] = scaler.fit_transform(features.values)
features
```

![](img/b0af8c031b988211fe9b85a5273d7c5a.png)

## 3ï¸âƒ£é©¬å…‹æ–¯å¸ƒæ–¯å¡å‹’

è¿™ä¸ªç¼©æ”¾å™¨çš„å·¥ä½œåŸç†ä¸å…¶ä»–ä¸¤ä¸ªæ²¡æœ‰ä»€ä¹ˆä¸åŒã€‚å®ƒå–æ¯åˆ—çš„ç»å¯¹æœ€å¤§å€¼ï¼Œç„¶åç”¨è¯¥å€¼é™¤ä»¥è¯¥åˆ—ä¸­çš„æ¯ä¸ªå€¼ã€‚è¿™æ˜¯ä¸€ä¸ªåˆ†ä¸‰æ­¥èµ°çš„è¿‡ç¨‹ã€‚

1.  è·å–åˆ—ä¸­æ¯ä¸ªå€¼çš„ç»å¯¹å€¼ã€‚
2.  æ±‚è¯¥åˆ—çš„æœ€å¤§å€¼ã€‚
3.  å°†æœ€å¤§å€¼é™¤ä»¥åˆ—ä¸­çš„æ¯ä¸ªå€¼ã€‚

è®©æˆ‘ä»¬åœ¨ä¸Šé¢åˆ›å»ºçš„æ•°æ®æ¡†ä¸­å†æ·»åŠ ä¸€åˆ—ã€‚

```
features = df[['salary','age']]
features['balance'] = [100.0, 25245.567, 134.567, 4567.2345,2345.345]
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸¤ä¸ªè¿‡ç¨‹æ¥è¡¡é‡è¿™äº›å€¼ã€‚

```
**ğŸ”° Using Sklearn Library** from sklearn.preprocessing import **MaxAbsScaler**
scaler = MaxAbsScaler()
col_names = ['salary','age','balance']
features[col_names] = scaler.fit_transform(features.values)
print(features.balance)ğŸ”° **Using Custom Code**values = [100.0, 25245.567, 134.567, 4567.2345,2345.345]
abs_values = [abs(ele) for ele in values]
max_val = max(abs_values)
val = [ele/max_val for ele in abs_values]
val
```

![](img/531731e3606faad84dcfcc4a508acb24.png)

å¹³è¡¡æ ->ä½¿ç”¨ Sklearn |è‡ªå®šä¹‰ä»£ç 

ç°åœ¨æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†ä¸‰ä¸ªå®šæ ‡å™¨ï¼Œä½†æ˜¯å®ƒä»¬éƒ½ä½¿ç”¨åˆ—çš„æœ€å¤§å€¼æˆ–æœ€å°å€¼æ¥å®šæ ‡æ•°æ®ã€‚è¿™äº›å€¼å¯¹å¼‚å¸¸å€¼å¾ˆæ•æ„Ÿï¼Œå¦‚æœæ•°æ®é›†ä¸­æœ‰è®¸å¤šå¼‚å¸¸å€¼ï¼Œé‚£ä¹ˆè¿™äº›å€¼å¾ˆå®¹æ˜“å—åˆ°å¼‚å¸¸å€¼çš„å½±å“ã€‚é²æ£’å®šæ ‡å™¨æ˜¯ä¸€ç§å¯¹å¼‚å¸¸å€¼ ***ä¸æ•æ„Ÿçš„å®šæ ‡å™¨ã€‚***

## 4ï¸âƒ£é²æ£’å®šæ ‡å™¨

é²æ£’å®šæ ‡å™¨çš„å…³é”®ç‰¹æ€§å’Œä¼˜åŠ¿ä¹‹ä¸€æ˜¯å®ƒå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿã€‚å®ƒä½¿ç”¨ IQR(å››åˆ†ä½æ•°é—´è·)æ¥ç¼©æ”¾æ•°æ®ã€‚

1.  å®ƒä»æ•°æ®ä¸­å»é™¤äº†ä¸­é—´å€¼ã€‚
2.  å¹¶ä¸”ï¼Œä½¿ç”¨ IQR ç¼©æ”¾æ•°æ®

**å…¬å¼:**

IQR = Q3-Q1

X_scaled = (X-Q1)/(Q3-Q1)

```
from sklearn.preprocessing import **RobustScaler**
scaler = RobustScaler()col_names = ['salary', 'age']
features = df[col_names]
features[col] = scaler.fit_transform(features.values)
features
```

![](img/0b3984bb8c8287e61b005328ca9bd967.png)

## 5ï¸âƒ£åˆ†ä½æ•°å˜å‹å™¨å®šæ ‡å™¨

è¿™ç§æŠ€æœ¯å°±åƒä¸€ç§ç¥å¥‡çš„ç»“åˆã€‚å®ƒå°†æ•°æ®çš„åˆ†å¸ƒè½¬æ¢ä¸ºæ­£æ€åˆ†å¸ƒï¼Œå¹¶ç›¸åº”åœ°è¿›è¡Œç¼©æ”¾ã€‚å› ä¸ºå®ƒä½¿å˜é‡å‘ˆæ­£æ€åˆ†å¸ƒï¼Œæ‰€ä»¥å®ƒä¹Ÿå¤„ç†å¼‚å¸¸å€¼ã€‚

âœ”å¼‚å¸¸å€¼å‰”é™¤
âœ”æ ‡åº¦æ•°æ®
âœ”è½¬æ¢æˆæ­£æ€åˆ†å¸ƒ

**æµç¨‹**

1.  é¦–å…ˆï¼Œå®ƒè®¡ç®—å˜é‡çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
2.  ç„¶åï¼Œå®ƒä½¿ç”¨è¯¥ CDF å°†å€¼æ˜ å°„åˆ°æ­£æ€åˆ†å¸ƒ
3.  æœ€åï¼Œå®ƒä½¿ç”¨ç›¸å…³è”çš„åˆ†ä½æ•°å‡½æ•°å°†è·å¾—çš„å€¼æ˜ å°„åˆ°æœŸæœ›çš„è¾“å‡ºåˆ†å¸ƒ

```
from sklearn.preprocessing import **QuantileTransformer**
scaler = QuantileTransformer()col_names = ['salary', 'age']
features = df[col_names]
features[col_names] = scaler.fit_transform(features.values)
features
```

![](img/db0a7b39da2793779c8e1258c68b3b8a.png)

## 6ï¸âƒ£å¯¹æ•°å˜æ¢

**ç”¨äºå°†åæ€åˆ†å¸ƒè½¬æ¢ä¸ºæ­£æ€åˆ†å¸ƒæˆ–ä¸åæ€åˆ†å¸ƒã€‚**åœ¨è¿™ç§æŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬å–åˆ—çš„å€¼çš„å¯¹æ•°ï¼Œå¹¶å°†å®ƒä»¬ä½œä¸ºä¸€åˆ—ã€‚

è®©æˆ‘ä»¬ç”¨ä¸€äº›å€¾æ–œçš„æ•°æ®æ¡ç›®å†æ¬¡æ·»åŠ  balance åˆ—ã€‚

```
features = df2[['salary','age']]
features['balance'] = [15000, 1800, 120000, 10000,12000]
features.balance.hist()
```

![](img/8e6e5cdb440b6aee67927ba20872ce22.png)

å·¦åæ•°æ®

ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨æ—¥å¿—è½¬æ¢å™¨è¿›è¡Œç¼©æ”¾ã€‚

```
import numpy as np
features['balance'] = np.log(features['balance'])
print(features.balance)
features.balance.hist(bins=5)
```

![](img/bcf812fc781e21f5230ab5246536e47e.png)

æ­£æ€åˆ†å¸ƒæ•°æ®

ä¸Šå›¾æ˜¾ç¤ºäº†å¦‚ä½•å°†å¯¹æ•°è½¬æ¢åˆ†å¸ƒè½¬æ¢ä¸ºæ­£æ€åˆ†å¸ƒã€‚

## 7ï¸âƒ£ç”µåŠ›å˜å‹å™¨å®šæ ‡å™¨

å®ƒè¿˜å°†å˜é‡çš„åˆ†å¸ƒæ›´æ”¹ä¸ºæ›´æ¥è¿‘é«˜æ–¯(æ­£æ€)çš„åˆ†å¸ƒã€‚æœ‰ä¸¤ç§ç±»å‹ã€‚

1.  [Box-Cox å˜æ¢](https://www.statisticshowto.com/box-cox-transformation/)
2.  [æ¨-çº¦ç¿°é€Šå˜æ¢](https://www.stat.umn.edu/arc/yjpower.pdf)

```
from sklearn.preprocessing import **PowerTransformer**
scaler = **PowerTransformer(method = 'box-cox')**'''
parameters:
method = 'box-cox' or 'yeo-johnson'
'''col_names = ['salary', 'age']
features = df[col_names]
features[col] = scaler.fit_transform(features.values)
features
```

![](img/d1425a72198325c7b78025086ebeef4c.png)

åšå…‹æ–¯-è€ƒå…‹æ–¯å˜æ¢

## 8ï¸âƒ£å•ä½å‘é‡å®šæ ‡å™¨/è§„æ ¼åŒ–å™¨

å®ƒå’Œå…¶ä»–çš„ä¸ä¸€æ ·ã€‚å®ƒä½œç”¨äºæ•°æ®æ¡†çš„æ¯ä¸€è¡Œï¼Œè€Œä¸æ˜¯åˆ—ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªè§„èŒƒ l1 å’Œ l2ã€‚

*   å¦‚æœæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ L1 èŒƒæ•°ï¼Œé‚£ä¹ˆæ¯ä¸€åˆ—ä¸­çš„å€¼éƒ½ä¼šè¢«è½¬æ¢ï¼Œè¿™æ ·å®ƒä»¬åœ¨è¿™ä¸€è¡Œä¸­çš„ç»å¯¹å€¼ä¹‹å’Œå°±æ˜¯ 1ã€‚
*   å¦‚æœæˆ‘ä»¬ä½¿ç”¨ L2 èŒƒæ•°ï¼Œé‚£ä¹ˆæ¯ä¸€åˆ—ä¸­çš„å€¼é¦–å…ˆè¢«å¹³æ–¹å¹¶ç›¸åŠ ï¼Œä½¿å¾—å®ƒä»¬æ²¿ç€è¡Œçš„ç»å¯¹å€¼ä¹‹å’Œæ˜¯ 1ã€‚

```
from sklearn.preprocessing import Normalizer
scaler = **Normalizer(norm='l2')**# norm = 'l2' is defaultcol_names = ['salary', 'age']
features = df[col_names]
features[col] = scaler.fit_transform(features.values)
features
```

![](img/71b6916a0a7c6ea7cb9a663b8ac24fdd.png)

ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬å°†å‰ä¸¤åˆ—ç›¸åŠ ï¼Œé‚£ä¹ˆæ€»å’Œå¤§çº¦ä¸º 1ã€‚

```
features['sum']=abs(features['age'])+abs(features['salary'])
features
```

![](img/1a38cd8178b70e6bf054256c1482a63c.png)

## 9ï¸âƒ£å®šåˆ¶å˜å‹å™¨

è€ƒè™‘è¿™æ ·ä¸€ç§æƒ…å†µï¼Œæ‚¨æœ‰è‡ªå·±çš„ python å‡½æ•°æ¥è½¬æ¢æ•°æ®ã€‚Sklearn æä¾›äº†ä½¿ç”¨ FunctionTransformer å¯¹æ•°æ®åº”ç”¨æ‚¨è‡ªå·±çš„å‡½æ•°çš„èƒ½åŠ›ã€‚

è®©æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ›´ç®€å•çš„å‡½æ•°ï¼Œæˆ‘ä»¬éœ€è¦å–è¯¥åˆ—ä¸­æ‰€æœ‰å€¼çš„ log2ã€‚

```
from sklearn.preprocessing import FunctionTransformer
transformer  = FunctionTransformer(np.log2,validate=True)col_names = ['salary', 'age']
features = df[col_names]
features[col] = transformer.fit_transform(features.values)
features
```

[***ç¬”è®°æœ¬& Github é“¾æ¥***](https://github.com/Abhayparashar31/feature-engineering/blob/main/Feature%20Transformation%20Methods%20.ipynb)

## é¢å¤–å°è´¹

![](img/30a85ee90b7be5c1b452d752526e969f.png)

[æ¥æº](https://i.stack.imgur.com/kRbSk.png)

## -:æ¨èè¯»ç‰©ğŸš€:-

[å¤„ç†æœºå™¨å­¦ä¹ ä¸­çš„å¼‚å¸¸å€¼](https://medium.com/towards-artificial-intelligence/handling-outliers-in-machine-learning-f842d8f4c1dc)

[ä¸åŒçš„ç‰¹å¾é€‰æ‹©æŠ€æœ¯](https://medium.com/towards-artificial-intelligence/different-feature-selection-techniques-f47ec43f71b8)

[å¤„ç†åˆ†ç±»å€¼çš„ä¸åŒæ–¹æ³•](https://medium.com/towards-artificial-intelligence/different-approaches-to-handle-categorical-values-a2e35fbd6128)

[æœºå™¨å­¦ä¹ ä¸­å¤„ç†ç¼ºå¤±å€¼çš„ 9 ç§æ–¹æ³•](https://medium.com/towards-artificial-intelligence/9-ways-to-handle-missing-values-in-machine-learning-1bbda345699a)

> ***æ„Ÿè°¢é˜…è¯»ğŸ˜ƒï¼Œæ›´å¤šè¯·è·Ÿæˆ‘æ¥*** [***è¿™é‡Œ***](https://parasharabhay13.medium.com/) ***ğŸ‘ˆ***