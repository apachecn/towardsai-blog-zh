# ä½¿ç”¨ Python æ•™ç¨‹çš„æœºå™¨å­¦ä¹ (ML) 101 çš„æ¢¯åº¦ä¸‹é™

> åŸæ–‡ï¼š<https://pub.towardsai.net/gradient-descent-algorithm-for-machine-learning-python-tutorial-ml-9ded189ec556?source=collection_archive---------0----------------------->

![](img/e2a7647ef05fb5b66e38c508ec20a49e.png)

éæ ‡å‡†åŒ– sin(x)å‡½æ•°çš„ä¸‰ç»´çº¿æ¡†å›¾ã€‚æ¥æº:ç»´åŸºåª’ä½“çŸ¥è¯†å…±äº«[ [1](https://commons.wikimedia.org/wiki/File:MATLAB_mesh_sinc3D.svg) ]

## [æ•°æ®ç§‘å­¦](https://towardsai.net/p/category/data-science)ï¼Œ[ç¼–è¾‘](https://towardsai.net/p/category/editorial)ï¼Œ[ç¼–ç¨‹](https://towardsai.net/p/category/programming)

## ä½¿ç”¨ Python æ·±å…¥ç ”ç©¶æœºå™¨å­¦ä¹ (ML)çš„æ¢¯åº¦ä¸‹é™ç®—æ³•çš„æ•™ç¨‹

æœ€åæ›´æ–°ï¼Œ2021 å¹´ 1 æœˆ 7 æ—¥

**ä½œè€…:**è¨å¦®å¨…Â·å¸•ç»´æ–¯ï¼Œ[ç½—ä¼¯æ‰˜Â·ä¼Šé‡Œç¿å¤š](https://mktg.best/vguzs)

**æœ¬æ•™ç¨‹çš„ä»£ç å¯åœ¨**[**Github**](https://github.com/towardsai/tutorials/tree/master/gradient_descent_tutorial)**ä¸Šè·å¾—ï¼Œå…¶å®Œæ•´å®ç°ä¹Ÿå¯åœ¨**[**Google Colab**](https://colab.research.google.com/drive/1bSHQVqbVD7ZqDHfyDy03dSWCdYmrUYmF?usp=sharing)**ä¸Šè·å¾—ã€‚**

> *ğŸ¤–èµ°å‘ AI æ˜¯ä¸€ä¸ªè®¨è®ºäººå·¥æ™ºèƒ½ã€æ•°æ®ç§‘å­¦ã€æ•°æ®å¯è§†åŒ–ã€æ·±åº¦å­¦ä¹ ã€æœºå™¨å­¦ä¹ ã€NLPã€è®¡ç®—æœºè§†è§‰ã€ç›¸å…³æ–°é—»ã€æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€ç¼–ç¨‹ã€æŠ€æœ¯ç­‰çš„ç¤¾åŒºï¼* [***åŠ å…¥æˆ‘ä»¬***](https://towardsai.net/backers) *ğŸ¤–*

# ç›®å½•

*   [ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™ï¼Ÿ](#dbf9)
*   [æˆæœ¬å‡½æ•°](#d0c8)
*   [æ¸å˜](#7fd3)
*   [Python å®ç°](#32ea)
*   [å­¦ä¹ ç‡](#b7a5)
*   [æ”¶æ•›](#183b)
*   [å‡¸å‡½æ•°](#1c83)
*   [æ‰¹é‡æ¢¯åº¦ä¸‹é™](#2f3c)
*   [éšæœºæ¢¯åº¦ä¸‹é™](http://30cb)
*   [å°æ‰¹é‡æ¢¯åº¦ä¸‹é™](#340b)
*   [ç»“è®º](#340b)
*   [èµ„æº](#a6ee)
*   [å‚è€ƒæ–‡çŒ®](#93c5)

> ğŸ“šæŸ¥çœ‹æˆ‘ä»¬çš„[å·ç§¯ç¥ç»ç½‘ç»œ](https://towardsai.net/p/deep-learning/convolutional-neural-networks-cnns-tutorial-with-python-417c29f0403f)æ•™ç¨‹ã€‚ğŸ“š

# ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™ï¼Ÿ

![](img/396deb5630e1e57de393cb4d8c5e085d.png)

å›¾ 1:æ¸å˜ä¸‹é™å›¾|æ¥æº:ç»´åŸºåª’ä½“çŸ¥è¯†å…±äº«[ [3](https://commons.wikimedia.org/wiki/File:Gradient_descent.gif) ]

**æ¢¯åº¦ä¸‹é™**æ˜¯ç¥ç»ç½‘ç»œ[ [7](https://www.researchgate.net/publication/221653420_Large-scale_matrix_factorization_with_distributed_stochastic_gradient_descent) ]ã€æ•°æ®ç§‘å­¦ã€ä¼˜åŒ–å’Œæœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„æœºå™¨å­¦ä¹ ç®—æ³•ä¹‹ä¸€ã€‚æ¢¯åº¦ä¸‹é™ç®—æ³•åŠå…¶å˜ä½“å‡ ä¹å¯ä»¥åœ¨æ¯ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ä¸­æ‰¾åˆ°ã€‚

æ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­è°ƒæ•´å‚æ•°çš„æµè¡Œä¼˜åŒ–æ–¹æ³•ã€‚å®ƒçš„ç›®æ ‡æ˜¯åº”ç”¨ä¼˜åŒ–æ¥æ‰¾åˆ°æœ€å°æˆ–æœ€å°çš„è¯¯å·®å€¼ã€‚å®ƒä¸»è¦ç”¨äºæ›´æ–°æ¨¡å‹çš„å‚æ•°ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå‚æ•°æ˜¯æŒ‡å›å½’ä¸­çš„ç³»æ•°å’Œç¥ç»ç½‘ç»œä¸­çš„æƒé‡ã€‚

**æ¢¯åº¦**æ˜¯ä¸€ä¸ªå‘é‡å€¼å‡½æ•°ï¼Œå®ƒæè¿°äº†ä¸€ä¸ªå‡½æ•°å›¾å½¢çš„åˆ‡çº¿æ–œç‡ï¼ŒæŒ‡å‘è¯¥å‡½æ•°æœ€æ˜¾è‘—çš„å¢é•¿ç‡çš„æ–¹å‘ã€‚å®ƒæ˜¯ä¸€ä¸ªå¯¼æ•°ï¼Œè¡¨ç¤ºä¸€ä¸ªæˆæœ¬å‡½æ•°[ [6](http://sites.science.oregonstate.edu/math/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/grad/grad.html) ]çš„å€¾æ–œåº¦æˆ–æ–œç‡ã€‚

ä¾‹å¦‚:

> å‡è®¾çº¦ç¿°åœ¨å±±é¡¶ä¸Šï¼Œä»–çš„ç›®æ ‡æ˜¯åˆ°è¾¾åº•ç”°ï¼Œä½†çº¦ç¿°æ˜¯ç›²äººï¼Œçœ‹ä¸åˆ°åº•çº¿ã€‚ä»–å°†å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿ

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä»–å°†é‡‡å–å°æ­¥éª¤ï¼Œå¹¶å‘æ›´é«˜çš„å€¾æ–œæ–¹å‘ç§»åŠ¨ï¼Œé€šè¿‡ä¸€æ¬¡ç§»åŠ¨ä¸€æ­¥æ¥åå¤åº”ç”¨è¿™äº›æ­¥éª¤ï¼Œç›´åˆ°ä»–æœ€ç»ˆåˆ°è¾¾å±±è„šã€‚

æ¢¯åº¦ä¸‹é™çš„æ‰§è¡Œæ–¹å¼ä¸ç¤ºä¾‹ä¸­æåˆ°çš„æ–¹å¼ç›¸åŒã€‚å®ƒçš„ä¸»è¦ç›®çš„æ˜¯åˆ°è¾¾å±±çš„æœ€ä½ç‚¹ã€‚

![](img/c09a2d60b7e336420c12860eeff66625.png)

å›¾ 2:æ¢¯åº¦ä¸‹é™å¯è§†åŒ–ã€‚[ [2](https://ithelp.ithome.com.tw/articles/10218912)

ä¸ºäº†æ·±å…¥äº†è§£æ¢¯åº¦ä¸‹é™ï¼Œå¿…é¡»è¯¦ç»†äº†è§£ä»¥ä¸‹ä¸»é¢˜:

*   ä»·å€¼å‡½æ•°
*   æˆæœ¬å‡½æ•°çš„æœ€å°åŒ–
*   æœ€å°å€¼å’Œæœ€å¤§å€¼
*   å‡¸å‡½æ•°
*   æ¢¯åº¦
*   åœæ­¢æ¡ä»¶
*   å­¦ä¹ ç‡

# ä»·å€¼å‡½æ•°

æˆæœ¬å‡½æ•°è¡¡é‡æœºå™¨å­¦ä¹ ç®—æ³•å¯¹åˆ†é…æ•°æ®çš„æ€§èƒ½ã€‚å®ƒé‡åŒ–äº†é¢„æµ‹å€¼å’ŒæœŸæœ›å€¼ä¹‹é—´çš„è¯¯å·®ï¼Œå¹¶ä»¥å•ä¸ªå®æ•°çš„å½¢å¼æ¨¡æ‹Ÿå®ƒã€‚ä»æ ¹æœ¬ä¸Šè¯´ï¼Œå®ƒè¡¡é‡çš„æ˜¯ç”±ç®—æ³•é€ æˆçš„é¢„æµ‹è¯¯å·®ã€‚å®ƒæ˜¾ç¤ºäº†ç»™å®šæ•°æ®é›†çš„é¢„æµ‹å€¼å’Œå®é™…å€¼ä¹‹é—´çš„å·®å¼‚ã€‚å¦‚æœæˆæœ¬å‡½æ•°å…·æœ‰è¾ƒä½çš„å€¼ï¼Œåˆ™æ¨¡å‹å¯ä»¥å…·æœ‰æ›´å¥½çš„é¢„æµ‹èƒ½åŠ›ã€‚æˆæœ¬å‡½æ•°çš„ä¸€ä¸ªä¼˜ç§€å€¼æ˜¯é›¶â€” **æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ¥æœ€å°åŒ–æˆæœ¬å‡½æ•°**ã€‚

è¿™äº›æ˜¯æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨çš„é‡è¦æˆæœ¬å‡½æ•°:

*   å‡æ–¹è¯¯å·®
*   å¯¹æ•°æŸå¤±æˆ–äº¤å‰ç†µ
*   KL-æ•£åº¦

**å‡æ–¹å·®æ–¹ç¨‹:**

![](img/88e81dc91d348cbb50289336015c4c25.png)

å›¾ 3:å‡æ–¹è¯¯å·®æ–¹ç¨‹

å…¶ä¸­:

![](img/598bad802de6beca591696903e6df727.png)

å›¾ 4:å›¾ 4:å‡æ–¹è¯¯å·®æ–¹ç¨‹çš„æ¡ä»¶ã€‚

å‡æ–¹è¯¯å·®ç”¨äºæœºå™¨å­¦ä¹ ä¸­çš„å›å½’ç®—æ³•ã€‚

Python ä»£ç ç¤ºä¾‹:

```
def sum_of_squares(v):
    val = sum(item ** 2 for item in v)
```

**å¯¹æ•°æŸå¤±æˆ–äº¤å‰ç†µæ–¹ç¨‹:**

![](img/b34639410bd4e95a7e1a72a8ac11a5d4.png)

å›¾ 5:å¯¹æ•°æŸå¤±æˆ–äº¤å‰ç†µçš„ç­‰å¼ã€‚

åœ¨åˆ†ç±»é—®é¢˜ä¸­ä½¿ç”¨äº†ä»£ä»·å‡½æ•° log loss æˆ–äº¤å‰ç†µã€‚

## æˆæœ¬å‡½æ•°ä¸æ¢¯åº¦ä¸‹é™çš„å…³ç³»

æˆæœ¬å‡½æ•°æ˜¯æœ€å°åŒ–çš„æƒ…å†µã€‚æˆæœ¬å‡½æ•°å¯ä»¥æ˜¯è®­ç»ƒé›†çš„è¯¯å·®å¹³æ–¹å’Œã€‚æ¢¯åº¦ä¸‹é™æ³•æ˜¯ä¸€ç§æ±‚å¤šå…ƒå‡½æ•°æœ€å°å€¼çš„æ–¹æ³•[ [8](https://towardsdatascience.com/minimizing-the-cost-function-gradient-descent-a5dd6b5350e1) ]ï¼Œå¯ä»¥ç”¨æ¥æœ€å°åŒ–ä»£ä»·å‡½æ•°ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œå¦‚æœ**æˆæœ¬å‡½æ•°**æ˜¯ **K** å˜é‡çš„å‡½æ•°ï¼Œé‚£ä¹ˆ**æ¢¯åº¦**å°±æ˜¯ä»£è¡¨æˆæœ¬å¢é•¿æœ€å¿«æ–¹å‘çš„**é•¿åº¦-K** å‘é‡ã€‚

ä¾‹å¦‚:

å‡è®¾å­˜åœ¨å›å½’æ¨¡å‹å°†è¢«åº”ç”¨äºäºŒå…ƒåˆ†ç±»çš„æƒ…å†µã€‚æ€»æ˜¯æœŸæœ›ä»¥é«˜ç²¾åº¦å’Œæœ€å°çš„è¯¯å·®æˆ–æŸå¤±æ¥æ‰§è¡Œæ¨¡å‹ã€‚

æ‰€ä»¥ï¼Œçº¿æ€§æ–¹ç¨‹â†’ **y= mx + c** ä¸­ï¼Œä¸€èˆ¬éƒ½æ˜¯è®¡ç®—å‚æ•°å€¼ **m** å’Œ **c** ã€‚æœŸæœ›æœ€å°çš„è¯¯å·®æˆ–æŸå¤±ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„æˆæœ¬å‡½æ•°æˆ–æŸå¤±å‡½æ•°ã€‚

å¯»æ‰¾æŸå¤±æœ€å°çš„å‚æ•°å€¼ **m** å’Œ **c** æ€»æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ**æ¢¯åº¦ä¸‹é™**ç®—æ³•è¿›å…¥ç”»é¢ã€‚æœ¬è´¨ä¸Šï¼Œå®ƒæœ‰åŠ©äºæ¨¡å‹æ‰¾åˆ°æŸå¤±æœ€å°çš„ç‚¹ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒä¸æˆæœ¬å‡½æ•°æœ‰å¯†åˆ‡çš„å…³ç³»ã€‚

# æ¢¯åº¦

ç›´çº¿çš„å¡åº¦è¡¨ç¤ºç›´çº¿æœ‰å¤šé™¡[ [17](https://www.mathsisfun.com/gradient.html) ]ã€‚

æ¢¯åº¦æ–¹ç¨‹:

![](img/dd53954c5e5e79f344c89df6e0452d13.png)

å›¾ 6:æ¢¯åº¦çš„æ–¹ç¨‹å¼ã€‚

![](img/495e2174f59483acdcb0b74041aeb9ae.png)

å›¾ 7:æ¸å˜å›¾ã€‚

ä¸æ¢¯åº¦ç›¸å…³çš„å‡ ç‚¹:

*   å‘ä¸Šä¸ºæ­£ï¼Œå‘ä¸‹ä¸ºè´Ÿ
*   ä»å·¦è¾¹å¼€å§‹ï¼Œç©¿è¿‡å³è¾¹æ˜¯ç§¯æçš„ã€‚

è®¾ e1ï¼Œe2ï¼Œ.ã€‚ã€‚ï¼Œed 2 Rd æ˜¯ä¸€ç»„ç‰¹å®šçš„å•ä½å‘é‡ï¼Œä½¿å¾— ei = (0ï¼Œ0ï¼Œ.ã€‚ã€‚, 0, 1, 0, .ã€‚ã€‚ï¼Œ0)å…¶ä¸­å¯¹äº eiï¼Œ1 åœ¨ç¬¬ I ä¸ªåæ ‡ä¸­ã€‚

![](img/01d75f9a322fe47011fc1c273f1d65a1.png)

å›¾ 8:æ¢¯åº¦çš„æ–¹ç¨‹å¼ã€‚

æ¢¯åº¦ä¸‹é™æ˜¯æœºå™¨å­¦ä¹ ä¸­ç”¨äºä¼°è®¡æ¨¡å‹å‚æ•°çš„å¸¸ç”¨ä¼˜åŒ–ç®—æ³•ã€‚æ ¹æ®å¾®ç§¯åˆ†ï¼Œè¿™æ˜¯ä¸€ä¸ªçº¯åå¯¼æ•°ï¼Œç»™å‡ºäº†å‡½æ•°å¢åŠ æœ€å¿«çš„è¾“å…¥æ–¹å‘ã€‚

![](img/22eabacbfc0d64dc0c3e4e8b824328f1.png)

å›¾ 9:ä½¿ç”¨æ¢¯åº¦ä¸‹é™å¯»æ‰¾æœ€å°å€¼ã€‚

åŸºæœ¬ä¸Šï¼Œä¸ºäº†æœ€å¤§åŒ–ä¸€ä¸ªå‡½æ•°ï¼Œç®—æ³•é€‰æ‹©ä¸€ä¸ªéšæœºçš„èµ·ç‚¹ï¼Œæµ‹é‡æ¢¯åº¦ï¼Œåœ¨æ¢¯åº¦çš„æ–¹å‘ä¸Šè¿ˆå‡ºä¸€å°æ­¥ï¼Œç„¶åç”¨æ–°çš„èµ·ç‚¹é‡å¤ã€‚ç±»ä¼¼åœ°ï¼Œé€šè¿‡åœ¨ç›¸åçš„æ–¹å‘ä¸Šé‡‡å–å°çš„æ­¥éª¤ï¼ŒåŠŸèƒ½è¢«æœ€å°åŒ–ã€‚æˆ‘ä»¬åŸºäºå…¶åˆå§‹å€¼æ¥è®¡ç®—æˆæœ¬å‡½æ•°ï¼Œå¹¶ä¸”å‚æ•°ä¼°è®¡åœ¨å„ä¸ªæ­¥éª¤ä¸Šè¢«ç»†åŒ–ï¼Œä½¿å¾—æˆæœ¬å‡½æ•°æœ€ç»ˆæš—ç¤ºæœ€å°å€¼ã€‚

**æ¢¯åº¦ä¸‹é™ç®—æ³•**:

![](img/7b5d03ac666f08dc160f108fe528534a.png)

å›¾ 10:æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚

![](img/90aeaf108bdd4d96240c5c5f575aaaac.png)

å›¾ 11:æ¸å˜æ­¥éª¤ã€‚

![](img/1b16e47ff544cc40ec7489fb1b0ca5c6.png)

å›¾ 12:æˆæœ¬å‡½æ•°æœ€å°åŒ–è¿‡ç¨‹ã€‚[ [9](https://www.mygreatlearning.com/blog/understanding-learning-rate-in-machine-learning/)

æ¢¯åº¦ä¸‹é™æ–¹ç¨‹:

![](img/15bb10bc18e3d1390b1c0b0e8c166895.png)

å›¾ 13:æ¢¯åº¦ä¸‹é™ç®—æ³•çš„ç­‰å¼ã€‚

é¦–å…ˆï¼Œè¿™ä¸ªå…¬å¼å‘Šè¯‰æˆ‘ä»¬å®ƒéœ€è¦å»çš„ä¸‹ä¸€ä¸ªä½ç½®ï¼Œä¹Ÿå°±æ˜¯æœ€é™¡çš„ä¸‹é™æ–¹å‘ã€‚

```
#Pseudocode
train(Î¸) = (1/2m) Î£( hÎ¸(x(i)) - y^(i))^2Repeat {
 Î¸j = Î¸j â€“ (learning-rate/m) * Î£( hÎ¸(x^(i)) - y^(i))xj^(i)
    For every j = 0 â€¦ n 
}
```

åœ¨è¿™ç§æƒ…å†µä¸‹:

**xj^(i)** æ˜¯ **i^th** è®­ç»ƒç¤ºä¾‹çš„ç¬¬ j ä¸ªç‰¹å¾ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é‡å¤ç›´åˆ°å®ƒè¾¾åˆ°æ”¶æ•›:

1.  ç»™å®šæ¢¯åº¦ï¼Œè®¡ç®—å‚æ•°éšå­¦ä¹ ç‡çš„å˜åŒ–ã€‚
2.  ç”¨æ–°çš„å‚æ•°å€¼é‡æ–°è®¡ç®—æ–°çš„æ¢¯åº¦ã€‚
3.  é‡å¤æ­¥éª¤ 1ã€‚

æœ‰ä¸‰ç§**å¸¸è§çš„æ¢¯åº¦ä¸‹é™ç±»å‹**:

*   **æ‰¹é‡æ¢¯åº¦ä¸‹é™**
*   **éšæœºæ¢¯åº¦ä¸‹é™**
*   **å°æ‰¹é‡æ¢¯åº¦ä¸‹é™**

# ç”¨ Numpy å®ç°æ¢¯åº¦ä¸‹é™çš„ Python å®ç°:

å¯¼å…¥æ‰€æœ‰å¿…éœ€çš„åŒ…:

```
import pandas as pdimport numpy as npimport matplotlib.pyplot as plt%matplotlib inline
```

ä» CSV è¯»å–æ•°æ®:

```
column_names = ['Population', 'Profit']df = pd.read_csv('/content/data.txt', header=None, names=column_names)df.head()
```

![](img/93b7df1d4a0fd210f76a036daeb430a0.png)

å›¾ 14:æ•°æ®è¾“å‡ºã€‚

è·å– X å’Œ Y çš„å€¼:

```
df.insert(0, 'Theta0', 1)cols = df.shape[1]X = df.iloc[:,0:cols-1]Y = df.iloc[:,cols-1:cols]theta = np.matrix(np.array([0]*X.shape[1]))X = np.matrix(X.values)Y = np.matrix(Y.values)
```

ç»˜åˆ¶æ•°æ®:

```
df.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))
```

![](img/9cc501e2cdd40b311afd1404a8fa202c.png)

å›¾ 15:æ•°æ®çš„ç»˜åˆ¶ã€‚

è®¡ç®— RSS çš„æ–¹æ³•:

```
def calculate_RSS(X, y, theta):  
    inner = np.power(((X * theta.T) - y), 2)
    return np.sum(inner) / (2 * len(X))
```

è®¡ç®—æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•:

```
def gradientDescent(X, Y, theta, alpha, iters):  
    t = np.matrix(np.zeros(theta.shape))
    parameters = int(theta.ravel().shape[1])
    cost = np.zeros(iters)

    for i in range(iters):
        error = (X * theta.T) - Y    for j in range(parameters):
         term = np.multiply(error, X[:,j])
         t[0,j] = theta[0,j] - ((alpha / len(X)) * np.sum(term))     theta = t
     cost[i] = calculate_RSS(X, Y, theta)     return theta, cost
```

ä¸åº”ç”¨æ¢¯åº¦ä¸‹é™è®¡ç®—è¯¯å·®:

```
error = calculate_RSS(X, Y, theta)error
```

![](img/e07fc679bf5b636f22dd4c89e06f191b.png)

å›¾ 16:æ²¡æœ‰åº”ç”¨æ¢¯åº¦ä¸‹é™çš„é”™è¯¯ã€‚

é€šè¿‡åº”ç”¨æ¢¯åº¦ä¸‹é™è®¡ç®—è¯¯å·®:

```
g, cost = gradientDescent(X, Y, theta, 0.01, 1000)g
```

![](img/9b58d45581ac8de216792e46949affb8.png)

å›¾ 17:è¯¯å·®çŸ©é˜µã€‚

åº”ç”¨æ¢¯åº¦ä¸‹é™åè®¡ç®—è¯¯å·®:

```
error = calculate_RSS(X, Y, g)error
```

![](img/ac1f12ba7e489946cabd5e8dc8f2b713.png)

å›¾ 18:åº”ç”¨æ¢¯åº¦ä¸‹é™åçš„é”™è¯¯ã€‚

æ•°æ®ç»˜å›¾:

```
x = np.linspace(df.Population.min(), df.Population.max(), 100)f = g[0, 0] + (g[0, 1] * x)fig, ax = plt.subplots(figsize=(12,8))ax.plot(x, f, 'r', label='Prediction')ax.scatter(df.Population, df.Profit, label='Traning Data')ax.legend(loc=2)ax.set_xlabel('Population')ax.set_ylabel('Profit')ax.set_title('Predicted Profit vs. Population Size')
```

![](img/b2ca18848d992495bb2a0b7dd0f45f0c.png)

å›¾ 19:æ•°æ®çš„ç»˜åˆ¶ã€‚

# å­¦ä¹ ç‡

å­¦ä¹ é€Ÿç‡æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨äºæ§åˆ¶ç®—æ³•æ›´æ–°å‚æ•°ä¼°è®¡å€¼æˆ–å­¦ä¹ å‚æ•°å€¼[ [9](https://www.mygreatlearning.com/blog/understanding-learning-rate-in-machine-learning/) ]çš„é€Ÿç‡ã€‚å®ƒä¸»è¦æ˜¯ä¼˜åŒ–ç®—æ³•ä¸­çš„ä¸€ä¸ªè°ƒæ•´å‚æ•°ï¼Œå¹¶åœ¨å‘æœ€å°æŸå¤±å‡½æ•°ç§»åŠ¨æ—¶ç¡®å®šæ¯æ¬¡è¿­ä»£çš„æ­¥é•¿ã€‚å®ƒç”¨äºç¼©æ”¾æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­å‚æ•°æ›´æ–°çš„å¹…åº¦ã€‚å®ƒå°†æ¢¯åº¦ä¹˜ä»¥ä¸€ä¸ªæ•°å­—(å­¦ä¹ ç‡æˆ–æ­¥é•¿)æ¥ç¡®å®šä¸‹ä¸€ä¸ªç‚¹ã€‚

ç¤ºä¾‹:

æœ‰ä¸€ä¸ª**å¤§å°**ä¸º **4.2** å’Œ**å­¦ä¹ é€Ÿç‡**ä¸º **0.01 çš„æ¢¯åº¦ï¼Œç„¶å**æ¢¯åº¦ä¸‹é™ç®—æ³•å°†é€‰å–ä¸‹ä¸€ä¸ªç‚¹ï¼Œè·ç¦»ä¸Šä¸€ä¸ªç‚¹ **0.042** ã€‚

ç†è§£**å±€éƒ¨æœ€å¤§å€¼**å’Œ**å±€éƒ¨æœ€å°å€¼æ¦‚å¿µ**å¯¹äºè¯¦ç»†ç†è§£å­¦ä¹ ç‡æ¦‚å¿µè‡³å…³é‡è¦ã€‚

# å±€éƒ¨æå¤§

ä¸€ä¸ªå‡½æ•° **f(x)** åœ¨ **x = aï¼Œ**å¤„æœ‰ä¸€ä¸ªå±€éƒ¨æœ€å¤§å€¼ï¼Œå¦‚æœ **f(a)** çš„å€¼æ¯” **f(x)** åœ¨ **x=a** çš„ä¸€ä¸ªå°é‚»åŸŸå†…çš„æ‰€æœ‰å€¼éƒ½é‡è¦ã€‚å› æ­¤ï¼Œåœ¨ä¸‹é¢æ‰€ç¤ºçš„æ•°å­¦ç­‰å¼ä¸­:

> ***f(a)>f(a-h)****å’Œ****f(a)>f(a+h)****ã€‚å…¶ä¸­ï¼Œ****h>0****ï¼Œåˆ™***ç§°ä¸ºå±€éƒ¨æœ€å¤§å€¼çš„ç‚¹ã€‚**

*ä»æ ¹æœ¬ä¸Šè¯´ï¼Œå±€éƒ¨æœ€å¤§å€¼æ˜¯æ™¯è§‚ä¸­å¤§äºå…¶æ¯ä¸ªç›¸é‚»çŠ¶æ€çš„å³°å€¼ä½ç½®ã€‚*

*![](img/4ecb266329c4ce639fdaa9bdf7954a32.png)*

*å›¾ 20:å±€éƒ¨æœ€å¤§å€¼ã€‚*

# *å±€éƒ¨æå°*

*å¦‚æœåœ¨ **x = a** å¤„çš„å‡½æ•°å€¼å°äºåœ¨ **x = a** çš„ç›¸é‚»ç‚¹å¤„çš„å‡½æ•°å€¼ï¼Œåˆ™å‡½æ•° **f(x)** åœ¨**x = a**å¤„å…·æœ‰å±€éƒ¨æœ€å°å€¼ã€‚å› æ­¤ï¼Œåœ¨ä¸‹é¢æ‰€ç¤ºçš„æ•°å­¦ç­‰å¼ä¸­:*

> ****f(a)<f(a-h)****å’Œ* ***f (a) < f (a + h)ã€‚*** *å…¶ä¸­****h>0****ï¼Œåˆ™ a ç§°ä¸ºå±€éƒ¨æœ€å°å€¼çš„ç‚¹ã€‚**

*![](img/e8932a41c71e773e0a4edac1e19f6ace.png)*

*å›¾ 21:å±€éƒ¨æœ€å¤§å€¼å’Œå±€éƒ¨æœ€å°å€¼|æ¥æº:ç»´åŸºç™¾ç§‘[ [4](https://en.wikipedia.org/wiki/Maxima_and_minima#/media/File:Extrema_example_original.svg) ]ï¼Œè®¸å¯è¯ [GFDPL 1.2](http://www.gnu.org/licenses/old-licenses/fdl-1.2.html)*

# *å­¦ä¹ é€Ÿåº¦çš„é‡è¦æ€§*

*ä¸ºäº†åœ¨æ¢¯åº¦ä¸‹é™ä¸­è¾¾åˆ°å±€éƒ¨æœ€å°å€¼ï¼Œå°†å­¦ä¹ ç‡è®¾ç½®ä¸ºæ—¢ä¸å¤ªä½ä¹Ÿä¸å¤ªé«˜çš„é€‚å½“å€¼æ˜¯è‡³å…³é‡è¦çš„ã€‚å­¦ä¹ ç‡æ˜¯å®ƒçš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ï¼Œå› ä¸ºå¦‚æœå®ƒé‡‡å–çš„æ­¥éª¤å¤ªå¤§ï¼Œå®ƒå¯èƒ½è¾¾ä¸åˆ°**æœ¬åœ°æœ€å°å€¼ã€‚**æ¯•ç«Ÿ**ï¼Œ**å®ƒåœ¨æ¢¯åº¦ä¸‹é™çš„å‡¸å‡½æ•°ä¹‹é—´æ¥å›å¼¹è·³ã€‚*

*å¦‚æœå­¦ä¹ ç‡è®¾ç½®ä¸ºæœ€å°å€¼ï¼Œé‚£ä¹ˆæ¢¯åº¦ä¸‹é™å°†æœ€ç»ˆè¾¾åˆ°å±€éƒ¨æœ€å°å€¼ï¼Œç„¶è€Œï¼Œè¿™å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´[ [16](https://builtin.com/data-science/gradient-descent) ]ã€‚*

*å­¦ä¹ ç‡å¯èƒ½å‡ºç°ä¸¤ç§ä¸åŒçš„æƒ…å†µ:*

*   *å¤§å­¦ä¹ ç‡*
*   *å°å­¦ä¹ ç‡*

*![](img/0faf3b48afbefc433c29412653b8df6e.png)*

*å›¾ 22:ä¸åŒçš„å­¦ä¹ ç‡ã€‚*

*å› æ­¤ï¼Œæ ¹æ®ä¸Šé¢æ˜¾ç¤ºçš„ä¸åŒåœºæ™¯ï¼Œå­¦ä¹ ç‡ä¸åº”è¯¥å¤ªé«˜æˆ–å¤ªä½ã€‚å¦‚æœå­¦ä¹ ç‡å¤ªå¤§ï¼ŒæŒ¯è¡å°±ä¼šå‘æ•£ã€‚*

*æ˜¾ç¤ºå­¦ä¹ ç‡:*

```
*def step_gradient(b_current, m_current, points, learning_rate):
    b_gradient = 0
    m_gradient = 0
    n = float(len(points))

    for i in range(0, len(points)):
        x = points[i, 0]
        y = points[i, 1]
        b_gradient += -(2/n) * (y - ((m_current * x) + b_current))
        m_gradient += -(2/n) * x * (y - ((m_current * x) + b_current))

    latest_b = b_current - (learning_rate * b_gradient)
    latest_m = m_current - (learning_rate * m_gradient)
    return [latest_b, latest_m]*
```

# *è¶‹åŒï¼›èšé›†*

*æ”¶æ•›æ˜¯æŒ‡æŸå¤±å‡½æ•°æ²¡æœ‰æ˜æ˜¾æ”¹å–„çš„ä½ç½®ï¼Œæˆ‘ä»¬åœç•™åœ¨æœ€å°å€¼é™„è¿‘çš„ä¸€ä¸ªç‚¹ä¸Šã€‚å¦‚æœæˆæœ¬å‡½æ•°åœ¨æ¯æ¬¡è¿­ä»£åéƒ½ä¸‹é™ï¼Œé‚£ä¹ˆå°±è¯´æ¢¯åº¦ä¸‹é™æ˜¯æ­£ç¡®çš„ã€‚å¦‚æœæ¢¯åº¦ä¸‹é™ä¸å†é™ä½æˆæœ¬å‡½æ•°ï¼Œå¹¶ä¸”æˆ–å¤šæˆ–å°‘åœ°ä¿æŒåœ¨åŒä¸€æ°´å¹³ï¼Œåˆ™å®ƒæ”¶æ•›ã€‚*

*å½“æ¢¯åº¦ä¸‹é™å¼€å§‹è¶³å¤Ÿæ¥è¿‘æœ€å°å€¼æ—¶ï¼Œå®ƒæ”¶æ•›åˆ°å±€éƒ¨æœ€å°å€¼ã€‚å¦‚æœæœ‰å¤šä¸ªå±€éƒ¨æå°å€¼ï¼Œå…¶æ”¶æ•›æ€§å–å†³äºè¿­ä»£å¼€å§‹çš„ç‚¹ã€‚æ”¶æ•›åˆ°å…¨å±€æœ€å°å€¼æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚*

*æ”¶æ•›æ€§æ€»æ˜¯å–å†³äºä¼˜åŒ–æ‰€ä½¿ç”¨çš„å‡½æ•°ç±»å‹ã€‚å¦‚æœç›®æ ‡å‡½æ•°æ˜¯å‡¸çš„ï¼Œæ¢¯åº¦ä¸‹é™æ€»æ˜¯æ”¶æ•›åˆ°åŒä¸€ä¸ªå±€éƒ¨æå°å€¼ï¼Œå®ƒä¹Ÿæ˜¯å…¨å±€æå°å€¼ã€‚*

*![](img/53c02b65d6326d9cd2ef649d33f626e6.png)*

*å›¾ 23:æ¢¯åº¦ä¸‹é™ä¸­çš„æ”¶æ•›ã€‚*

# *å‡¸å‡½æ•°*

*å¦‚æœå‡½æ•°çš„å›¾ä¸Šä»»æ„ä¸¤ç‚¹ä¹‹é—´çš„çº¿æ®µä½äºå›¾ [15](https://towardsdatascience.com/gradient-descent-unraveled-3274c895d12d) ä¹‹ä¸Šæˆ–ä¹‹ä¸Šï¼Œåˆ™ä¸ºå‡¸å‡½æ•°ã€‚*

*æ•°å­¦ä¸Šï¼Œå‡¸å‡½æ•°å¯ä»¥å®šä¹‰ä¸º:*

> **å‡¸å‡½æ•°æ˜¯æŒ‡åœ¨å…¶å®šä¹‰åŸŸå†…æ¯ä¸ªåŒºé—´ä¸­ç‚¹çš„å€¼ä¸è¶…è¿‡å…¶åœ¨åŒºé—´ä¸¤ç«¯çš„å€¼çš„ç®—æœ¯å¹³å‡å€¼çš„å‡½æ•°[* [*14*](https://artofproblemsolving.com/wiki/index.php/Convex_function) *]ã€‚**

*![](img/25bfef76b2884bca562bdaf2f633fc23.png)*

*å›¾ 24:å‡¸å‡½æ•°å›¾ã€‚*

*ä»è€Œè¿›å…¥æ•°å­¦æ–¹ç¨‹å¼:*

*æœ‰ä¸€ä¸ªåŒºé—´ã€T8ã€aï¼Œbã€‘**f(x)**æ˜¯ä¸€ä¸ªå‡½æ•° **x1** å’Œ **x2** æ˜¯åŒºé—´ã€T16ã€aï¼Œbã€‘å’Œä»»æ„ **Î»** ä¸­çš„ä¸¤ç‚¹å…¶ä¸­ **0 < Î» < 1** ã€‚æ‰€ä»¥ï¼Œ*

*![](img/750aeedc7784c9570af35ac0235916ae.png)*

*å›¾ 25:å‡¸çš„æ–¹ç¨‹å¼ã€‚*

*![](img/5402f1d5ab51ec1080f01dfee5725b73.png)*

*å›¾ 26:åŒºé—´ä¸Šçš„å‡¸å‡½æ•°|æ¥æº:ç»´åŸºç™¾ç§‘[ [5](https://en.wikipedia.org/wiki/Convex_function#/media/File:ConvexFunction.svg) ]ï¼Œè®¸å¯è¯ [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0)*

# *æ¢¯åº¦ä¸‹é™çš„ä¸»è¦ç±»å‹*

## *æ‰¹é‡æ¢¯åº¦ä¸‹é™(BGD)*

*æ‰¹é‡æ¢¯åº¦ä¸‹é™ä¸ºè®­ç»ƒæ•°æ®é›†ä¸­çš„æ¯ä¸ªç¤ºä¾‹è®¡ç®—è¯¯å·®ï¼Œä½†ä»…åœ¨è¯„ä¼°äº†æ‰€æœ‰è®­ç»ƒç¤ºä¾‹åæ›´æ–°æ¨¡å‹[ [13](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/) ]ã€‚è¿™å¯¹äºå‡¸çš„æˆ–ç›¸å¯¹å…‰æ»‘çš„è¯¯å·®æµå½¢æ˜¯éå¸¸å¥½çš„ã€‚è¿™ç§æ–¹æ³•è®¡ç®—é‡å¾ˆå¤§ï¼Œä½†éšç€ç‰¹å¾æ•°é‡çš„å¢åŠ ï¼Œå®ƒçš„è§„æ¨¡ä¹Ÿå¾ˆå¤§ã€‚ä»¥ä¸‹å†…å®¹å¯¹äºæ‰¹é‡æ¢¯åº¦ä¸‹é™è‡³å…³é‡è¦:*

*   *è¿™æ˜¯éå¸¸ç¼“æ…¢å’Œè®¡ç®—æ˜‚è´µçš„ã€‚*
*   *ä»ä¸å»ºè®®ä½¿ç”¨åºå¤§çš„è®­ç»ƒæ•°æ®é›†ã€‚*
*   *åœ¨è¿™é‡Œï¼Œæ”¶æ•›æ˜¯ç¼“æ…¢çš„ã€‚*
*   *å®ƒä½¿ç”¨æ•´ä¸ªè®­ç»ƒæ•°æ®é›†è®¡ç®—æ¢¯åº¦ã€‚*

## *éšæœºæ¢¯åº¦ä¸‹é™*

*æ‰¹é‡æ¢¯åº¦ä¸‹é™ä¸­æœ‰ä¸€ç§æƒ…å†µï¼Œå¦‚ä¸‹æ‰€è¿°:*

> **å‡è®¾æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œæœ‰ 500 ä¸‡ä¸ªä¾‹å­ã€‚æ‰€ä»¥ï¼Œèµ°ä¸€æ­¥ï¼Œæ¨¡å‹å°†è®¡ç®—æ‰€æœ‰ 500 ä¸‡ä¸ªä¾‹å­çš„æ¢¯åº¦ã€‚è¿™ç§æƒ…å†µå‘ç”Ÿåœ¨æ‰¹é‡æ¢¯åº¦ä¸‹é™ä¸­ã€‚**

*ä¸Šè¿°æƒ…å†µæ˜¯ä½æ•ˆçš„ï¼Œæ‰€ä»¥éšæœºæ¢¯åº¦ä¸‹é™æ˜¯åœ¨å›¾ç‰‡ä¸­å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚æœ¬è´¨ä¸Šï¼Œå®ƒä¼šè®¡ç®—é”™è¯¯ï¼Œå¹¶æ›´æ–°è®­ç»ƒèµ„æ–™é›†ä¸­æ¯ä¸ªèŒƒä¾‹çš„æ¨¡å‹ã€‚*

*éšæœºæ¢¯åº¦ä¸‹é™æœ‰ä»¥ä¸‹å‡ ç‚¹:*

*   *å®ƒä½¿ç”¨å•ä¸ªè®­ç»ƒæ ·æœ¬è®¡ç®—æ¢¯åº¦ã€‚*
*   *å»ºè®®ä½¿ç”¨å¤§å‹è®­ç»ƒæ ·æœ¬ã€‚*
*   *ä¸æ‰¹é‡æ¢¯åº¦ä¸‹é™ç›¸æ¯”ï¼Œå®ƒé€Ÿåº¦æ›´å¿«ï¼Œè®¡ç®—æˆæœ¬æ›´ä½ã€‚*
*   *å®ƒæ›´å¿«åœ°è¾¾åˆ°æ”¶æ•›ã€‚*
*   *å®ƒèƒ½æ›´å®¹æ˜“åœ°æµ…åŒ–å±€éƒ¨æå°å€¼ã€‚*

## *å°æ‰¹é‡æ¢¯åº¦ä¸‹é™(MBGD)*

*å°æ‰¹é‡æ¢¯åº¦ä¸‹é™å°†è®­ç»ƒæ•°æ®é›†åˆ†æˆå°æ‰¹é‡ï¼Œè¿™äº›æ‰¹é‡ç”¨äºè®¡ç®—æ¨¡å‹è¯¯å·®å’Œæ›´æ–°æ¨¡å‹ç³»æ•°ã€‚å®ƒå¯ä»¥ç”¨äºæ›´å¹³æ»‘çš„æ›²çº¿ã€‚*

*å°æ‰¹é‡æ¢¯åº¦ä¸‹é™å…·æœ‰ä»¥ä¸‹è¦ç‚¹:*

*   *å½“æ•°æ®é›†å¾ˆå¤§æ—¶ï¼Œå¯ä»¥ä½¿ç”¨å®ƒã€‚*
*   *å®ƒç›´æ¥æ”¶æ•›åˆ°æœ€å°å€¼ã€‚*
*   *å¯¹äºè¾ƒå¤§çš„æ•°æ®é›†ï¼Œé€Ÿåº¦æ›´å¿«ã€‚*
*   *ç”±äºåœ¨ SGD ä¸­ï¼ŒåŒæ—¶ä½¿ç”¨çš„åªæœ‰ä¸€ä¸ªä¾‹å­ï¼Œæ‰€ä»¥æ— æ³•å®ç°çŸ¢é‡åŒ–å®ç°ã€‚*
*   *å®ƒå¯ä»¥é™ä½è®¡ç®—é€Ÿåº¦â€”â€”ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ··åˆä½¿ç”¨äº†æ‰¹é‡æ¢¯åº¦ä¸‹é™å’Œ SGDã€‚*

*![](img/2da16a91d1584d4efc567943d48a1945.png)*

*å›¾ 27:æœ€å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ã€‚*

# *ç»“è®º*

*æ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§ä¸€é˜¶è¿­ä»£ä¼˜åŒ–ç®—æ³•[ [10](https://en.wikipedia.org/wiki/Gradient_descent) ]ï¼Œç”¨äºè·å¾—å¯å¾®å‡½æ•°çš„å±€éƒ¨æœ€å°å€¼ã€‚å®ƒåŸºäºä¸€ä¸ªå‡¸å‡½æ•°ï¼Œå¹¶åå¤è°ƒæ•´å…¶å‚æ•°ï¼Œä½¿ç»™å®šçš„å‡½æ•°æœ€å°åŒ–åˆ°å…¶å±€éƒ¨æœ€å°å€¼ã€‚*

*å°±æ¢¯åº¦ä¸‹é™çš„ç±»å‹è€Œè¨€ï¼Œæ‰¹é‡æ¢¯åº¦ä¸‹é™(BGD)æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„æ¢¯åº¦ä¸‹é™å½¢å¼[ [12](https://machinelearningmastery.com/master-machine-learning-algorithms/) ]ã€‚ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ä¼˜åŒ–ç³»æ•°çš„ä¸€äº›æ—¥å¸¸ç®—æ³•æ˜¯çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’[ [11](https://machinelearningmastery.com/gradient-descent-for-machine-learning/) ]ã€‚*

***æŸå¤±å‡½æ•°**è§£é‡Šäº†æ¨¡å‹åœ¨å½“å‰å‚æ•°é›†(æƒé‡å’Œåå·®)ä¸‹çš„è¡¨ç°ï¼Œè€Œ**æ¢¯åº¦ä¸‹é™**ç”¨äºå¯»æ‰¾æœ€ä½³å‚æ•°é›†ã€‚*

***å…è´£å£°æ˜:**æœ¬æ–‡è¡¨è¾¾çš„è§‚ç‚¹ä»…ä»£è¡¨ä½œè€…ä¸ªäººè§‚ç‚¹ï¼Œä¸ä»£è¡¨å¡å†…åŸºæ¢…éš†å¤§å­¦æˆ–å…¶ä»–(ç›´æ¥æˆ–é—´æ¥)ä¸ä½œè€…ç›¸å…³çš„å…¬å¸çš„è§‚ç‚¹ã€‚è¿™äº›æ–‡ç« å¹¶ä¸æ‰“ç®—æˆä¸ºæœ€ç»ˆäº§å“ï¼Œè€Œæ˜¯å½“å‰æ€æƒ³çš„åæ˜ ï¼ŒåŒæ—¶ä¹Ÿæ˜¯è®¨è®ºå’Œæ”¹è¿›çš„å‚¬åŒ–å‰‚ã€‚*

***é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡æ¥è‡ªä½œè€…ã€‚***

*é€šè¿‡[å‘ AI](https://towardsai.net/) å‘å¸ƒ*

# *èµ„æº*

*[Github åº“](https://github.com/towardsai/tutorials/tree/master/gradient_descent_tutorial)ã€‚*

*[Google colab å®ç°](https://colab.research.google.com/drive/1bSHQVqbVD7ZqDHfyDy03dSWCdYmrUYmF?usp=sharing)ã€‚*

# *å‚è€ƒ*

*[1] MATLAB mesh sic3D.svgï¼ŒWikimedia Commonsï¼Œ[https://Commons . Wikimedia . org/wiki/File:MATLAB _ mesh _ sinc3d . SVG](https://commons.wikimedia.org/wiki/File:MATLAB_mesh_sinc3D.svg)*

*[2] å¾ Gradient Descent to Optimizer, by ITHome, [https://ithelp.ithome.com.tw/articles/10218912](https://ithelp.ithome.com.tw/articles/10218912)*

*[3]æ¢¯åº¦ä¸‹é™ï¼Œç»´åŸºå…±äº«èµ„æºï¼Œ[https://Commons . Wikimedia . org/wiki/File:Gradient _ descent . gif](https://commons.wikimedia.org/wiki/File:Gradient_descent.gif)*

*[4]æœ¬åœ°å’Œå…¨çƒæœ€å¤§å€¼å’Œæœ€å°å€¼ï¼Œç»´åŸºç™¾ç§‘ï¼Œè®¸å¯ GFDL 1.2ï¼Œ[https://en . Wikipedia . org/wiki/Maxima _ and _ Minima #/media/File:Extrema _ example _ original . SVG](https://en.wikipedia.org/wiki/Maxima_and_minima#/media/File:Extrema_example_original.svg)*

*[5]åŒºé—´ä¸Šçš„å‡¸å‡½æ•°ï¼Œç»´åŸºç™¾ç§‘ï¼ŒLicense CC BY-SA 3.0ï¼Œ[https://en . Wikipedia . org/wiki/Convex _ Function #/media/File:Convex Function . SVG](https://en.wikipedia.org/wiki/Convex_function#/media/File:ConvexFunction.svg)*

*[6]ã€Šæ¢¯åº¦ä¸æ–¹å‘å¯¼æ•°ã€‹ï¼Œä¿„å‹’å†ˆå·ç«‹å¤§å­¦ï¼Œ[http://sites . science . oregonstate . edu/math/home/programs/underbrad/CalculusQuestStudyGuides/vcalc/grad/grad . html](http://sites.science.oregonstate.edu/math/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/grad/grad.html)*

*[7]æ°ç©†æ‹‰ã€è±çº³&å°¼åæ™®ã€åŸƒé‡Œå…‹&å“ˆæ–¯ã€å½¼å¾—&è¥¿æ–¯é©¬å°¼æ–¯ã€äºšå°¼æ–¯ã€‚(2011).åˆ†å¸ƒå¼éšæœºæ¢¯åº¦ä¸‹é™çš„å¤§è§„æ¨¡çŸ©é˜µåˆ†è§£ã€‚ACM SIGKDD çŸ¥è¯†å‘ç°å’Œæ•°æ®æŒ–æ˜å›½é™…ä¼šè®®å½•ã€‚69â€“77.10.1145/2020408.2020426.*

*[8]æœ€å°åŒ–æˆæœ¬å‡½æ•°:æ¢¯åº¦ä¸‹é™ï¼ŒXuanKhanh Nguyenï¼Œèµ°å‘æ•°æ®ç§‘å­¦ï¼Œ[https://towardsdatascience . com/Minimizing-the-cost-function-Gradient-descent-a5dd 6b 5350 e 1](https://towardsdatascience.com/minimizing-the-cost-function-gradient-descent-a5dd6b5350e1)*

*[9]ç†è§£æœºå™¨å­¦ä¹ ä¸­çš„å­¦ä¹ ç‡ï¼Œä¼Ÿå¤§çš„å­¦ä¹ å›¢é˜Ÿï¼Œ[https://www . mygreatlearning . com/blog/Understanding-Learning-Rate-in-Machine-Learning/](https://www.mygreatlearning.com/blog/understanding-learning-rate-in-machine-learning/)*

*[10]æ¢¯åº¦ä¸‹é™ï¼Œç»´åŸºç™¾ç§‘ï¼Œ[https://en.wikipedia.org/wiki/Gradient_descent](https://en.wikipedia.org/wiki/Gradient_descent)*

*[11]ç”¨äºæœºå™¨å­¦ä¹ çš„æ¢¯åº¦ä¸‹é™ï¼Œæœºå™¨å­¦ä¹ æŒæ¡ï¼Œ[https://Machine Learning Mastery . com/Gradient-Descent-for-Machine-Learning/](https://machinelearningmastery.com/gradient-descent-for-machine-learning/)*

*[12]Master Machine Learning Algorithmsï¼ŒJason Brownlee åšå£«ï¼Œ[https://Machine Learning mastery . com/Master-Machine-Learning-Algorithms/](https://machinelearningmastery.com/master-machine-learning-algorithms/)*

*[13]å…³äºå°æ‰¹é‡æ¢¯åº¦ä¸‹é™å’Œå¦‚ä½•é…ç½®æ‰¹é‡å¤§å°çš„æ¸©å’Œä»‹ç»ï¼Œæœºå™¨å­¦ä¹ æŒæ¡ï¼Œ[https://machinelementmastery . com/Gentle-Introduction-Mini-Batch-Gradient-Descent-Configure-Batch-Size/](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/)*

*[14]å‡¸å‡½æ•°ï¼Œè§£é¢˜çš„è‰ºæœ¯ï¼Œ[https://artofproblemsolution . com/wiki/index . PHP/Convex _ Function](https://artofproblemsolving.com/wiki/index.php/Convex_function)*

*[15] Gradient Descent Unraveledï¼ŒManpreet Singh Minhasï¼Œ[https://towardsdatascience . com/Gradient-Descent-Unraveled-3274 c 895d 12d](https://towardsdatascience.com/gradient-descent-unraveled-3274c895d12d)*

*[16]æ¢¯åº¦ä¸‹é™:æœºå™¨å­¦ä¹ æœ€æµè¡Œçš„ç®—æ³•ä¹‹ä¸€ä»‹ç»ï¼Œå°¼å…‹æ‹‰æ–¯Â·ä¸œæ ¼æ–¯ï¼Œ[https://builtin.com/data-science/gradient-descent](https://builtin.com/data-science/gradient-descent)*

*ã€17ã€‘ç›´çº¿çš„å¡åº¦(æ–œç‡)ï¼Œæ•°å­¦å¾ˆå¥½ç©ï¼Œ[https://www.mathsisfun.com/gradient.html](https://www.mathsisfun.com/gradient.html)*