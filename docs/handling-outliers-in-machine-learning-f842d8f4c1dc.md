# æœºå™¨å­¦ä¹ ä¸­å¼‚å¸¸å€¼çš„å¤„ç†

> åŸæ–‡ï¼š<https://pub.towardsai.net/handling-outliers-in-machine-learning-f842d8f4c1dc?source=collection_archive---------1----------------------->

## [æœºå™¨å­¦ä¹ ](https://towardsai.net/p/category/machine-learning)

## ç®€å•ä¸”æ˜“äºå®æ–½çš„æ–¹æ³•

![](img/8683c0114517d08c3ae46ee08c100148.png)

[ä¹”Â·å‡¯æ©](https://unsplash.com/@joeyc?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

ä»»ä½•æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½éƒ½å–å†³äºå®ƒè¢«è®­ç»ƒçš„æ•°æ®ï¼Œå¹¶ä¸”å®ƒå¾ˆå®¹æ˜“å—åˆ°æ”¹å˜åˆ†å¸ƒæˆ–åœ¨è¾“å…¥æ•°æ®ä¸­æ·»åŠ ä¸€äº›ç¦»ç¾¤å€¼çš„å½±å“ã€‚ç¦»ç¾¤å€¼ä¼šå¯¼è‡´æœºå™¨å­¦ä¹ æ¨¡å‹çš„å‡†ç¡®æ€§é™ä½ï¼Œè®­ç»ƒæ—¶é—´å¢åŠ ã€‚åœ¨ä¸ºè®­ç»ƒæä¾›æ•°æ®ä¹‹å‰ï¼Œå¤„ç†æ‰€æœ‰å¼‚å¸¸å€¼å˜å¾—å¾ˆé‡è¦ã€‚

åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘å°†å°è¯•å›ç­”å…³äºç¦»ç¾¤å€¼çš„ä¸¤ä¸ªæœ€å¸¸è§çš„é—®é¢˜ã€‚

1.  å¦‚ä½•æ‰¾åˆ°ä»–ä»¬
2.  å¦‚ä½•å¤„ç†å®ƒä»¬

## ä»€ä¹ˆæ˜¯ç¦»ç¾¤å€¼ï¼Ÿ

å¼‚å¸¸å€¼æ˜¯ä¸æ ·æœ¬çš„å…¶ä½™éƒ¨åˆ†æ˜¾è‘—ä¸åŒçš„å¼‚å¸¸æ•°æ®ç‚¹ã€‚è¿™äº›ç‚¹ç¦»å…¶ä»–ç±»ä¼¼çš„ç‚¹å¾ˆè¿œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æ­£åœ¨åˆ†æä¸€æ‰€å­¦æ ¡å­¦ç”Ÿçš„å¹´é¾„æ•°æ®ã€‚åœ¨æ•°æ®ä¸­ï¼Œå¹´é¾„èŒƒå›´åœ¨ 5-25 å²æ˜¯å¸¸è§çš„ï¼Œä½† 50 å²æˆ– 100 å²æ˜¯ä¸å¸¸è§çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ã€‚å®ƒä»¬å¯èƒ½æ˜¯ç”±äºæ•°æ®æ”¶é›†ä¸­çš„ä¸€äº›é”™è¯¯æˆ–è¾“å…¥æ•°æ®æ€§è´¨çš„å˜åŒ–è€Œå‘ç”Ÿçš„ã€‚

## ç¦»ç¾¤å€¼çš„ç±»å‹

æœ‰ä¸‰ç§å¼‚å¸¸å€¼ã€‚

1.**ç‚¹æˆ–å…¨å±€å¼‚å¸¸å€¼:**å¦‚æœæ•°æ®ç‚¹çš„å€¼è¿œåœ¨æ•´ä¸ªæ•°æ®é›†ä¹‹å¤–ï¼Œåˆ™è¯¥æ•°æ®ç‚¹è¢«è§†ä¸ºå…¨å±€å¼‚å¸¸å€¼ã€‚

2.**ä¸Šä¸‹æ–‡(æ¡ä»¶)å¼‚å¸¸å€¼:**å¦‚æœä¸€ä¸ªå•ç‹¬çš„æ•°æ®å®ä¾‹åœ¨ç‰¹å®šçš„ä¸Šä¸‹æ–‡æˆ–æ¡ä»¶ä¸‹æ˜¯å¼‚å¸¸çš„ï¼Œé‚£ä¹ˆå®ƒè¢«ç§°ä¸ºä¸Šä¸‹æ–‡å¼‚å¸¸å€¼ã€‚

3.**é›†ä½“å¼‚å¸¸å€¼:**å½“æ•°æ®ç‚¹çš„é›†åˆå¯¹äºæ•´ä¸ªæ•°æ®é›†æ¥è¯´æ˜¯å¼‚å¸¸çš„æ—¶ï¼Œå€¼æœ¬èº«ä¸æ˜¯å¼‚å¸¸çš„ã€‚

![](img/e83f68df2b348cd0a591918bd84710fa.png)![](img/145f850110a41284bc28d0804655f45b.png)![](img/80dbf1ac95844dcb8acf9632055cd925.png)

é›†ä½“-ä¸Šä¸‹æ–‡-å…¨å±€ç¦»ç¾¤å€¼

# å‘ç°å¼‚å¸¸å€¼çš„æ–¹æ³•

ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†ä»€ä¹ˆæ˜¯å¼‚å¸¸å€¼ä»¥åŠå¼‚å¸¸å€¼çš„ä¸åŒç±»å‹ï¼Œç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹å‘ç°å¼‚å¸¸å€¼çš„ä¸åŒæ–¹æ³•ã€‚

æœ‰ä¸¤ç§åŸºæœ¬æ–¹æ³•:

1.  ç™¾åˆ†ä½
2.  ç®±å½¢å›¾

## ç™¾åˆ†ä½

åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªæœ€å°ç™¾åˆ†ä½æ•°å’Œæœ€å¤§ç™¾åˆ†ä½æ•°ã€‚é€šå¸¸ï¼Œæœ€å°ç™¾åˆ†ä½æ•°æ˜¯ 5%ï¼Œæœ€å¤§ç™¾åˆ†ä½æ•°æ˜¯ 95%ã€‚ç„¶åï¼Œæˆ‘ä»¬å–å‡ºç™¾åˆ†ç‚¹èŒƒå›´ä¹‹å¤–çš„æ‰€æœ‰æ•°æ®ç‚¹ï¼Œè¿™æ„å‘³ç€é‚£äº›å¤§äº 95%å€¼æˆ–å°äº 5%å€¼çš„å€¼ï¼Œå¹¶å°†å®ƒä»¬è§†ä¸ºå¼‚å¸¸å€¼ã€‚

ä¾‹å¦‚:åœ¨ä¸€ä¸ªæ•°æ®é›†ä¸­ï¼Œå¦‚æœ 5%æ˜¯ 45ï¼Œ95%æ˜¯ 1000ï¼Œé‚£ä¹ˆæ‰€æœ‰ä½äº 45 æˆ–å¤§äº 1000 çš„å€¼éƒ½è¢«è§†ä¸ºå¼‚å¸¸å€¼ã€‚

å®é™…ä¾‹å­:

```
**## Let's First Create a Dummy DataFrame With Outliers**
lst = [random.randint(0,100) for i in range(0,100)]
**## Adding a manual outlier**
global_outlier = [300]
df = pd.DataFrame(lst+global_outlier,columns=['number'])**## Minimum Percentile Value** min_val = df.quantile(0.05)**## Maximum Percentile Value** max_val = df.quantile(0.95)**## Finding All the Outliers** df[(df['number']<min_val[0])| (df['number']>max_val[0])]##############OUTPUT################
    number
23    2
64    1
66    99
84    2
89    99
100   300           

######YOUR OUTPUT MAY BE DIFFERENT BECAUSE WE ARE USING RANDOM MODULE TO GENERATE SAMPLE DATAFRAME####
```

## ç®±å½¢å›¾

ç®±çº¿å›¾æ˜¯æè¿°æ•°æ®åˆ†å¸ƒçš„å›¾å½¢æ˜¾ç¤ºã€‚ç®±çº¿å›¾ä½¿ç”¨ä¸­é—´å€¼å’Œä¸Šä¸‹å››åˆ†ä½æ•°ã€‚

ç†ŠçŒ«æ•°æ®æ¡†å…·æœ‰å†…ç½®çš„ç®±çº¿å›¾åŠŸèƒ½ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ä¸Šè¿°æ–¹æ³•åˆ›å»ºä¸€ä¸ªæ•°æ®æ¡†ï¼Œå¹¶å°è¯•æ‰¾å‡ºå¼‚å¸¸å€¼ã€‚

```
df.boxplot(column=['number'])
```

![](img/9c73f7731ff3d56d8abb423d424f572b.png)

300 å€¼ä½œä¸ºå¼‚å¸¸å€¼

è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸¤ç§æŠ€æœ¯ï¼Œå¹¶å°è¯•åœ¨åƒæ³°å¦å°¼å…‹å·è¿™æ ·çš„çœŸå®æ•°æ®é›†ä¸­å‘ç°å¼‚å¸¸å€¼ã€‚è®¿é—®æˆ‘çš„ Github repoï¼Œä»[**è¿™é‡Œ**](https://raw.githubusercontent.com/Abhayparashar31/feature-engineering/main/data/titanic_with_no_nan.csv) ä¸‹è½½æ²¡æœ‰ nan å€¼çš„æ•°æ®é›†çš„æ¸…ç†ç‰ˆæœ¬ã€‚

**ç™¾åˆ†ä½æ•°**

```
**########## DETECTING OUTLIERS USING PERCENTILE ###############**
df = pd.read_csv('data/titanic_with_no_nan.csv')
max_val = df.Age.quantile(0.95)
min_val = df.Age.quantile(0.05)
df2 = df[(df['Age']<min_val) | (df['Age']>max_val)]
print("Number of Outliers Detected in Age:",df2.shape[0])#########OUTPUT#########
Number of Outliers Detected in Age: **86**
```

**æ–¹æ¡†å›¾**

```
**########## DETECTING OUTLIERS USING BOX PLOT ###############**
df = pd.read_csv('data/titanic_with_no_nan.csv')*### LET'S USE SEABORN BOX PLOTS* import seaborn as sns
sns.boxplot(df['Age'])
```

![](img/eb5a9d68073c52fd81b089eb8886834d.png)

Titanic æ•°æ®é›†ä¸­â€œ**å¹´é¾„**â€åˆ—ä¸­çš„å¼‚å¸¸å€¼

# å¤„ç†å¼‚å¸¸å€¼çš„ä¸åŒæ–¹æ³•

æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å¤„ç†å¼‚å¸¸å€¼ã€‚

1.  ç§»é™¤æ‰€æœ‰å¼‚å¸¸å€¼ã€‚
2.  ç”¨åˆé€‚çš„å€¼æ›¿æ¢å¼‚å¸¸å€¼

## ç§»é™¤æ‰€æœ‰å¼‚å¸¸å€¼

åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæ‰¾åˆ°æœ€å°å€¼å’Œæœ€å¤§å€¼åˆ†ä½æ•°ï¼Œç„¶åé€šè¿‡åœ¨è¿›ä¸€æ­¥å¤„ç†ä¸­ä¸é€‰å–å®ƒä»¬æ¥ç®€å•åœ°åˆ é™¤æ‰€æœ‰å€¼ã€‚

```
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import pandas as pd
warnings.filterwarnings("ignore")
fig, axes = plt.subplots(1,2)
plt.tight_layout(0.2)**## DataFrame**
df = pd.read_csv('data/titanic_with_no_nan.csv')
print("Before Shape:",df.shape)**## Max and Min Quantile**
max_val = df.Age.quantile(0.95)
min_val = df.Age.quantile(0.05)**## Removing all the outliers**
df2 = df[(df['Age']>min_val) & (df['Age']<max_val)]**## Visulization**
print("After Shape:",df2.shape)
sns.boxplot(df['Age'],orient='v',ax=axes[0])
axes[0].title.set_text("Before")
sns.boxplot(df2['Age'],orient='v',ax=axes[1])
axes[1].title.set_text("After")
plt.show()
```

![](img/8a079a899cbf67a1e40d21462ab7b95b.png)

## ç”¨åˆé€‚çš„å€¼æ›¿æ¢å¼‚å¸¸å€¼

**ä½¿ç”¨åˆ†ä½æ•°æ³•**

åœ¨è¿™ä¸ªæ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæ‰¾åˆ°æœ€å°å’Œæœ€å¤§åˆ†ä½æ•°ã€‚ä¹‹åï¼Œæˆ‘ä»¬æ‰¾åˆ°åˆ†ä½æ•°èŒƒå›´ä¹‹å¤–çš„æ‰€æœ‰å€¼ï¼Œå¹¶ç›¸åº”åœ°ç”¨æœ€å°æˆ–æœ€å¤§åˆ†ä½æ•°å€¼æ›¿æ¢å®ƒä»¬ã€‚

```
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")
fig, axes = plt.subplots(1,2)
plt.tight_layout(0.2)
df = pd.read_csv('data/titanic_with_no_nan.csv')
print("Previous Shape With Outlier: ",df.shape)
sns.boxplot(df['Age'],orient='v',ax=axes[0])
axes[0].title.set_text("Before")**########### HANDLING OUTLIER ######**
max_val = df.Age.quantile(0.95)
min_val = df.Age.quantile(0.05)df2 = df**####### REPLACING ALL THE Large values with MAX QUANTILE VALUE ####** df2['Age'] = np.where(df2['Age']>max_val,max_val,df2['Age'])print("Shape After Removing Outliers:", df2.shape)sns.boxplot(df2['Age'],orient='v',ax=axes[1])
axes[1].title.set_text("After")
plt.show()
```

![](img/aff57009b63c7247a942e9f74a2fad40.png)

## ä½¿ç”¨ IQR

IQR æˆ–**å››åˆ†ä½æ•°èŒƒå›´**æ˜¯åŸºäºå°†æ•°æ®é›†åˆ’åˆ†ä¸ºä¸åŒåˆ†ä½æ•°çš„å¯å˜æ€§åº¦é‡ã€‚

åˆ†ä½æ•°åˆ†ä¸º Q1ã€Q2 å’Œ Q3ï¼Œå…¶ä¸­ Q1 æ˜¯æ•°æ®é›†å‰åŠéƒ¨åˆ†çš„ä¸­é—´å€¼ã€‚Q2 æ˜¯ä¸­é—´å€¼ï¼ŒQ3 æ˜¯æ•°æ®é›†ååŠéƒ¨åˆ†çš„ä¸­é—´å€¼ã€‚

IQR ç­‰äº Q3 å‡å» Q1ã€‚

Q1 = df . column . quantile(0.25)
Q3 = df . column . quantile(0.75)

IQR = Q3-Q1

è®¡ç®— IQR åï¼Œæˆ‘ä»¬è®¡ç®—ä¸‹é™å’Œä¸Šé™ï¼Œç„¶åç®€å•åœ°ä¸¢å¼ƒæ‰€æœ‰å°äºæˆ–å¤§äºé™åˆ¶çš„å€¼ï¼Œå¹¶ç›¸åº”åœ°ç”¨ä¸‹é™å’Œä¸Šé™æ›¿æ¢å®ƒä»¬ã€‚

**æ³¨æ„**:å®ƒä¹Ÿé€‚ç”¨äºå·¦åæˆ–å³åçš„æ•°æ®

```
df = pd.read_csv('data/titanic_with_no_nan.csv')
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")
fig, axes = plt.subplots(1,2)
plt.tight_layout(0.2)
print("Previous Shape With Outlier: ",df.shape)
sns.boxplot(df['Age'],orient='v',ax=axes[0])
axes[0].title.set_text("Before")########### HANDLING OUTLIER ######
Q1 = df.Age.quantile(0.25)
Q3 = df.Age.quantile(0.75)
print(Q1,Q3)IQR = Q3-Q1
print(IQR)lower_limit = Q1 - 1.5*IQR
upper_limit = Q3 + 1.5*IQR
print(lower_limit,upper_limit)df2 = df
df2['Age'] = np.where(df2['Age']>upper_limit,upper_limit,df2['Age'])
df2['Age'] = np.where(df2['Age']<lower_limit,lower_limit,df2['Age'])print("Shape After Removing Outliers:", df2.shape)sns.boxplot(df2['Age'],orient='v',ax=axes[1])
axes[1].title.set_text("After")
plt.show()
```

![](img/d86e1e90e4a76df27406b954bca220d2.png)

## **å¥–åŠ±æç¤º**

å‘ç°å¼‚å¸¸å€¼å¹¶å¤„ç†å®ƒä»¬å¹¶ä¸æ€»æ˜¯é‚£ä¹ˆå®¹æ˜“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿçš„ä¸åŒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

```
1\. Naivye Bayes Classifier--- Not Sensitive To Outliers
2\. SVM-------- Not Sensitive To Outliers
3\. Decision Tree Regressor or Classifier---- Not Sensitive
4\. Ensemble(RF,XGboost,GB)------------Not Sensitive
5\. KNN--------------------------- Not Sensitive6\. Linear Regression------------- Sensitive
7\. Logistic Regression----------- Sensitive 
8\. Kmeans------------------------ Sensitive
9\. Hierarichal------------------- Sensitive
10\. PCA-------------------------- Sensitive
11\. Neural Networks-------------- Sensitive
```

[***Github &ç¬”è®°æœ¬é“¾æ¥***](https://github.com/Abhayparashar31/feature-engineering/blob/main/Handling%20Outliers.ipynb)

> ***æ„Ÿè°¢é˜…è¯»ğŸ˜ƒï¼Œå…³æ³¨æˆ‘æ›´å¤šç›¸å…³æ–‡ç« ***

[](https://medium.com/towards-artificial-intelligence/9-ways-to-handle-missing-values-in-machine-learning-1bbda345699a) [## æœºå™¨å­¦ä¹ ä¸­å¤„ç†ç¼ºå¤±å€¼çš„ 9 ç§æ–¹æ³•

### ç®€å•ä½†æœ‰æ•ˆ

medium.com](https://medium.com/towards-artificial-intelligence/9-ways-to-handle-missing-values-in-machine-learning-1bbda345699a) [](https://medium.com/towards-artificial-intelligence/feature-transformation-and-scaling-techniques-f9645cb538e) [## ç‰¹å¾å˜æ¢å’Œç¼©æ”¾æŠ€æœ¯

### æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½çš„ 9 ç§æ–¹æ³•

medium.com](https://medium.com/towards-artificial-intelligence/feature-transformation-and-scaling-techniques-f9645cb538e)