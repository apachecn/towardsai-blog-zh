# ç”¨ Python è¿›è¡Œå›¾åƒåˆ†ç±»:CNN ä¸å˜å½¢é‡‘åˆš

> åŸæ–‡ï¼š<https://pub.towardsai.net/image-classification-with-python-cnn-vs-transformers-fe509cbbc2d0?source=collection_archive---------0----------------------->

![](img/bf7a59d41b19f964ce71b34753c515bf.png)

## è®¡ç®—æœºè§†è§‰&ç”¨å·ç§¯ç¥ç»ç½‘ç»œã€è¿ç§»å­¦ä¹ ã€ViTã€TensorFlow å’Œ HuggingFace è¿›è¡Œè§£é‡Š

## æ‘˜è¦

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†ä½¿ç”¨è®¡ç®—æœºè§†è§‰å’Œ Python æ¥è§£é‡Š 3 ç§ä¸åŒçš„å›¾åƒåˆ†ç±»ç­–ç•¥:ä»å¤´å¼€å§‹æ„å»ºä¸€ä¸ª *CNN* ï¼Œåˆ©ç”¨ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¹¶åº”ç”¨å°–ç«¯çš„*Vison Transformers*(*ViT)*ã€‚

![](img/b47a3df98ed8688d5cd8334e1326e2fe.png)

ç…§ç‰‡ç”±[æ°ç±³è¡—](https://unsplash.com/@jamie452?utm_source=medium&utm_medium=referral)ä¸Šçš„ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

[**ã€è®¡ç®—æœºè§†è§‰(CV)**](https://en.wikipedia.org/wiki/Computer_vision) äººå·¥æ™ºèƒ½é¢†åŸŸç ”ç©¶è®¡ç®—æœºå¦‚ä½•è·å¾—å¯¹æ•°å­—å›¾åƒæˆ–è§†é¢‘çš„é«˜å±‚æ¬¡ç†è§£ã€‚CV å§‹äº 20 ä¸–çºª 60 å¹´ä»£çš„éº»çœç†å·¥å­¦é™¢ï¼Œå½“æ—¶ä¸€åæš‘æœŸå­¦ç”Ÿçš„ä»»åŠ¡æ˜¯é€šè¿‡å°†ç›¸æœºè¿æ¥åˆ°è®¡ç®—æœºæ¥æè¿°å›¾åƒä¸­çš„ç‰©ä½“ã€‚è™½ç„¶è¿™ä¸ªé¡¹ç›®ä¸æ˜¯å¾ˆæˆåŠŸï¼Œä½†å®ƒä¸ºå‡ åå¹´æ¥å¼€å‘ç°ä»£è®¡ç®—æœºè§†è§‰çš„å®éªŒå¥ å®šäº†åŸºç¡€ã€‚

CV çš„ä¸»è¦ä»»åŠ¡æ˜¯å›¾åƒåˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ã€‚**å›¾åƒåˆ†ç±»**æ˜¯æ ¹æ®ç‰¹å®šçš„è§„åˆ™æˆ–æ¨¡å‹å¯¹å›¾åƒä¸­çš„åƒç´ ç»„è¿›è¡Œåˆ†ç±»å’Œæ ‡è®°çš„è¿‡ç¨‹ã€‚

æœ¬æ•™ç¨‹æ¯”è¾ƒäº†è‘—åçš„*å·ç§¯ç¥ç»ç½‘ç»œ*å’Œæœ€å…ˆè¿›çš„*T21*åŸºäºæ³¨æ„åŠ›çš„*å˜å½¢é‡‘åˆš*ï¼Œå®ƒä»¬å½»åº•æ”¹å˜äº†äººå·¥æ™ºèƒ½çš„é¢è²Œã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘è¿˜å°†å±•ç¤ºå¦‚ä½•ä»å¤´å¼€å§‹æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œè½¬ç§»å­¦ä¹ ï¼Œå¹¶è§£é‡Šæ¨¡å‹ç»“æœã€‚

æˆ‘å°†å±•ç¤ºä¸€äº›æœ‰ç”¨çš„ Python ä»£ç ï¼Œè¿™äº›ä»£ç å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºå…¶ä»–ç±»ä¼¼çš„æƒ…å†µ(åªéœ€å¤åˆ¶ã€ç²˜è´´ã€è¿è¡Œ)ï¼Œå¹¶é€šè¿‡æ³¨é‡Šéå†æ¯ä¸€è¡Œä»£ç ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥å¤åˆ¶è¿™ä¸ªç¤ºä¾‹(ä¸‹é¢æ˜¯å®Œæ•´ä»£ç çš„é“¾æ¥)ã€‚

[](https://github.com/mdipietro09/DataScience_ArtificialIntelligence_Utils/blob/master/computer_vision/example_img_classification.ipynb) [## data science _ artificial intelligence _ Utils/example _ img _ classification . ipynb at masterâ€¦

### æ•°æ®ç§‘å­¦é¡¹ç›®å’Œäººå·¥æ™ºèƒ½ç”¨ä¾‹çš„ç¤ºä¾‹â€¦

github.com](https://github.com/mdipietro09/DataScience_ArtificialIntelligence_Utils/blob/master/computer_vision/example_img_classification.ipynb) 

æˆ‘å°†ä½¿ç”¨â€œ**çŠ¬ç§**â€**æ•°æ®é›†ï¼Œå…¶ä¸­ä¸ºæ‚¨æä¾›äº†å‡ å¹…ä¸åŒçŠ¬ç§çš„å›¾ç‰‡(é“¾æ¥å¦‚ä¸‹)ã€‚**

**[](https://www.kaggle.com/competitions/dog-breed-identification/overview) [## çŠ¬ç§è¯†åˆ«

### ç¡®å®šå›¾åƒä¸­ç‹—çš„å“ç§

www.kaggle.com](https://www.kaggle.com/competitions/dog-breed-identification/overview) 

ç‰¹åˆ«æ˜¯ï¼Œæˆ‘å°†ç»å†:

*   è®¾ç½®:å¯¼å…¥åŒ…ã€æ•°æ®åˆ†æã€é¢„å¤„ç†
*   ç”¨*å¼ é‡æµã€*è¯„ä¼°&å¯è§£é‡Šæ€§ã€æ•°æ®æ‰©å……ä»é›¶å¼€å§‹æ„å»º CNN
*   CNN è¿ç§»å­¦ä¹ ä¸*å¼ é‡æµï¼Œ*è¯„ä¼°&å¯è§£é‡Šæ€§
*   ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„ *ViT* å’Œ*å˜å‹å™¨*** 

## **è®¾ç½®**

**é¦–å…ˆï¼Œæˆ‘éœ€è¦å¯¼å…¥ä»¥ä¸‹åº“:**

```
***## for data*** import **os**
import **pandas** as pd
import **numpy** as np
from **tqdm**.notebook  import tqdm

***## for plotting*** import **matplotlib**.pyplot as plt
import **seaborn** as sns
import **plotly**.express as px

***## for metrics*** from **sklearn** import metrics

***## for cnn*** from **tensorflow**.keras import models, layers, callbacks ***#(2.6.0)***

***## for explainer*** from **lime** import lime_image
from **skimage** import segmentation

***## for vit*** import **transformers** ***#(4.18.0)***
```

**å½“å¤„ç†å›¾åƒæ—¶ï¼Œæœ‰ä¸¤ä¸ªä¸»è¦çš„ Python åŒ…:[](https://pillow.readthedocs.io/en/stable/)**å’Œ [*OpenCV*](https://github.com/opencv/opencv-python) ã€‚å®ƒä»¬éƒ½æ‰§è¡Œç›¸åŒçš„ä»»åŠ¡ï¼Œä½†åè€…è¦å¿«ä¸€ç‚¹ï¼Œå› æ­¤æˆ‘å€¾å‘äºä½¿ç”¨***ã€OpenCVã€‘****ã€cv2ã€‘*ã€‚****

```
*****## for images***
import **cv2****
```

****ä¸ºäº†è¯»å–æ•°æ®ï¼Œåº”è¯¥å°†å›¾åƒä¿å­˜åœ¨æœ¬åœ°ï¼Œå¹¶åŠ è½½å°†å›¾ç‰‡ id ä¸å…¶æ ‡ç­¾è¿›è¡Œæ˜ å°„çš„æ•°æ®å¸§ã€‚****

```
****## for this tutorial I will use a subset of labels**
labels = ["scottish_deerhound", "maltese_dog", "afghan_hound", "entlebucher", "bernese_mountain_dog"]

dtf = pd.read_csv("dogs_labels.csv").rename(columns={"breed":"label"})dtf = dtf[dtf["label"].isin(labels)].sort_values("id").reset_index(drop=True)

dtf["y"] = dtf["label"].factorize(sort=True)[0]dic_y_mapping = dict( dtf[['y','label']].drop_duplicates().sort_values('y').values )print(dic_y_mapping)
dtf**
```

****![](img/876052d08904bf65b67fe5a75bbc11da.png)****

****ä½œè€…å›¾ç‰‡****

****å¯¹äºè®¡ç®—æœºæ¥è¯´ï¼Œå›¾åƒåªæ˜¯ä¸€ä¸ªåƒç´ çŸ©é˜µï¼Œæ¯ä¸ªåƒç´ æ˜¯ä¸€ä¸ªä»£è¡¨ RGB é¢œè‰²ç»„åˆçš„ç‚¹ã€‚æ¢å¥è¯è¯´ï¼Œå½©è‰²å›¾åƒæ˜¯ä¸€ä¸ª 3D çŸ©é˜µï¼Œå…¶å€¼åœ¨ 0 åˆ° 255 ä¹‹é—´ï¼Œå…¶ä¸­å€¼ 0 è¡¨ç¤ºé»‘è‰²ï¼Œå€¼ 255 è¡¨ç¤ºç™½è‰²ã€‚****

****![](img/a2aece58ae1da758faa71fb2ada9843d.png)****

****ä½œè€…å›¾ç‰‡****

****æˆ‘å°†å†™ä¸‹ä¸¤ä¸ªæœ‰ç”¨çš„å‡½æ•°æ¥åŠ è½½å’Œç»˜åˆ¶è¿™äº› 3D æ•°ç»„(plot å‡½æ•°å¯ä»¥åº”ç”¨äºå•ä¸ªå›¾åƒï¼Œä¹Ÿå¯ä»¥åº”ç”¨äºå¤šä¸ªå›¾ç‰‡)ã€‚****

****è®©æˆ‘ä»¬åœ¨ä¸€å¼ å›¾ç‰‡ä¸Šå°è¯•ä¸€ä¸‹:****

```
**img = **load_img**(file="data_dogs/0042188c895a2f14ef64a918ed9c7b64.jpg")
**plot_imgs**(img, "shape: "+str(img.shape))**
```

****![](img/c56a7c4b41af1b0ef83200d95d6a720f.png)****

****å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³åˆ†è§£è¿™å¼ å›¾ç‰‡çš„ RGB é€šé“ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åš:****

```
**lst = []
for i in range(3):
    tmp = np.zeros(img.shape, dtype='uint8')
    tmp[:,:,i] = img[:,:,i]
    lst.append(tmp)

**plot_imgs**(lst, ["r","g","b"])**
```

****![](img/6984a5c69c186b1c7ec1dc9f5fc88395.png)****

****ä½œè€…å›¾ç‰‡****

****ç°åœ¨è®©æˆ‘ä»¬åŠ è½½æ•´ä¸ªæ•°æ®é›†:****

```
*****## load all***
dirpath = "folder name here"
ext = ['.png','.jpg','.jpeg','.JPG']

lst_imgs = []
errors = 0
for file in **tqdm**(sorted(**os**.listdir(dirpath))):
    try:
        if file.endswith(tuple(ext)):
            img = load_img(file=**os**.path.join(dirpath, file), 
                           ext=ext)
            lst_imgs.append(img)
    except Exception as e:
        print("failed on:", file, "| error:", e)
        errors += 1
        lst_imgs.append(np.nan)
        pass

dtf["img"] = lst_imgs
dtf = dtf[["id","img","label","y"]]print("check:", len(lst_imgs), "=", len(dtf), " |  Nas:", errors, "=", dtf["img"].isna().sum())
dtf.head()**
```

****![](img/ec84ba95694aaa77bb896f5b398cc5c7.png)****

****ä½œè€…å›¾ç‰‡****

```
****plot_imgs**(dtf["img"].head(), dtf["label"].head())**
```

****![](img/8f13541a82ce1e83c068a058ef94ed00.png)****

****ä½œè€…å›¾ç‰‡****

****åœ¨å¼€å§‹ç ”ç©¶è¿™äº›æ¨¡å‹ä¹‹å‰ï¼Œæœ‰ä¸€äº›**æ•°æ®åˆ†æ**è¦åšã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘å°†å›ç­” 3 ä¸ªé—®é¢˜:****

****1.æ•°æ®é›†å¹³è¡¡å—ï¼Ÿä¼¼ä¹æ˜¯è¿™æ ·ï¼Œä¸è¿‡å®ƒå¾ˆå°ã€‚****

```
**dtf["y"].value_counts().plot(kind="barh", title="Y", figsize=(5,3)).grid(axis='x')
plt.show()**
```

****![](img/5be0aa34f4f85a715940346a8d127739.png)****

****ä½œè€…å›¾ç‰‡****

****2.æ—¢ç„¶æ‰€æœ‰çš„å›¾åƒéƒ½å¿…é¡»æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼Œé‚£ä¹ˆé€‰æ‹©ä»€ä¹ˆæ ·çš„å°ºå¯¸æ‰æ˜¯åˆé€‚çš„å‘¢ï¼Ÿé€šå¸¸ï¼Œæˆ‘ä¼šé€‰æ‹©æœ€å¸¸ç”¨çš„å½¢çŠ¶ï¼Œå¹¶æ ¹æ®å®ƒæ¥è°ƒæ•´å¤§å°ã€‚****

```
**width = [img.shape[0] for img in dtf["img"]]
height = [img.shape[1] for img in dtf["img"]]fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))

***## all***
ax[0].scatter(x=width, y=height, color="black")
ax[0].set(xlabel='width', ylabel="height", title="Size distribution")
ax[0].grid()

***## zoom***
ax[1].scatter(x=width, y=height, color="black")
ax[1].set(xlabel='width', ylabel="height", xlim=[100,700], ylim=[100,700], title="Zoom")
ax[1].grid()

plt.show()**
```

****![](img/4033886424ac0f689fb52acac931b945.png)****

****ä½œè€…å›¾ç‰‡****

```
*****## resize***
img_size = (500,500)  ***#<-- 500x500***dtf["img"] = [cv2.resize(img, img_size) for img in dtf["img"]]plot_imgs(dtf["img"].head(), dtf["y"].head())**
```

****![](img/b7e82b91d97b8a4ce50b5c3ee419ba90.png)****

****ä½œè€…å›¾ç‰‡****

****3.æˆ‘åº”è¯¥ä¿ç•™é¢œè‰²è¿˜æ˜¯è½¬æ¢é»‘ç™½å›¾åƒ(2D é˜µåˆ—è€Œä¸æ˜¯ 3D)ï¼Ÿä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœæœºå™¨èƒ½å¤Ÿå¤„ç†è®­ç»ƒï¼Œæˆ‘ä¼šè¯´ä¿ç•™é¢œè‰²ã€‚æ— è®ºå¦‚ä½•ï¼Œå¦‚æœæœ‰äººæƒ³æ£€æŸ¥é¢œè‰²å’Œç±»åˆ«ä¹‹é—´æ˜¯å¦å­˜åœ¨ç›¸å…³æ€§(å³æ‰€æœ‰ 1 éƒ½ç³»ç»Ÿåœ°æ¯” 0 æš—)ï¼Œæˆ‘å»ºè®®ä»æ¯ä¸ªå›¾åƒä¸­æå–ä¸»è‰²ï¼Œå¹¶ç»˜åˆ¶ RGB åˆ†å¸ƒã€‚å› æ­¤ï¼Œå¦‚æœæœ‰ä¸€ä¸ªæ¨¡å¼ï¼Œå›¾åƒæ•°æ®ç‚¹å°†å‡ºç°åœ¨é›†ç¾¤ä¸­ã€‚****

```
*****## try one***
i = 0

rgb = dtf["img"][i].copy()
unique, counts = np.unique(rgb.reshape(-1,3), axis=0, return_counts=True)
rgb[:,:,0], rgb[:,:,1], rgb[:,:,2] = unique[np.argmax(counts)]plot_imgs([dtf["img"][i], rgb], ["image","main color"])**
```

****![](img/b7b97e2e2e5d5c8de627b0ce7f5959d1.png)****

****ä½œè€…å›¾ç‰‡****

```
*****## do all***
r,g,b,y = [],[],[],[]
for img,label in tqdm(zip(dtf["img"],dtf["y"])):
    unique, counts = np.unique(img.reshape(-1,3), axis=0, 
                               return_counts=True)
    red, green, blue = unique[np.argmax(counts)]
    r.append(red)
    g.append(green)
    b.append(blue)
    y.append(label)

***## plot 3D (with plotly)***
data = pd.DataFrame({"r":r,"g":g,"b":b,"y":y})
data["y"] = data["y"].astype(str)
fig = px.scatter_3d(data, x='r', y='g', z='b', color='y',
                    labels={"r":"red","g":"green","b":"blue"})
fig.show()**
```

****![](img/ce738151611ba63343460059917ca069.png)****

****ä½œè€…å›¾ç‰‡****

****æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­è¿›è¡Œ**é¢„å¤„ç†** : scale(å› ä¸ºå½“æˆ‘ä»¬å¤„ç†ç¥ç»ç½‘ç»œæ—¶ï¼Œæ•°æ®æœ€å¥½åœ¨ 0 å’Œ 1 ä¹‹é—´)å¹¶å°†å…¶åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚****

```
****## scaling**
dtf["img"] = dtf["img"]/255 **## partitioning** split = 500X_train = np.array([x for x in dtf["img"].head(split).values])
y_train = np.array([y for y in dtf["y"].head(split).values])

X_test = np.array([x for x in dtf["img"].tail(len(dtf)-split).values])
y_test = np.array([y for y in dtf["y"].tail(len(dtf)-split).values])**
```

****ç°åœ¨ä¸€åˆ‡éƒ½å‡†å¤‡å¥½è¿›å…¥æ¨¡å‹äº†ã€‚****

## ****å·ç§¯ç¥ç»ç½‘ç»œ****

****[*CNN*](https://en.wikipedia.org/wiki/Convolutional_neural_network) æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºå¤„ç†åƒç´ æ•°æ®çš„äººå·¥ç¥ç»ç½‘ç»œã€‚å®ƒä»¬æ˜¯åœ¨ 90 å¹´ä»£å‘æ˜çš„ï¼Œä½†åœ¨ 2012 å¹´å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œå½“æ—¶æŠ€æœ¯å¼€å§‹å…è®¸é‡å‹æ¨¡å‹é€šè¿‡åˆ©ç”¨ GPU åœ¨ç¬”è®°æœ¬ç”µè„‘ä¸Šè¿è¡Œ([*tensor flow*](https://www.tensorflow.org/)*äº 2015 å¹´å‘å¸ƒ)ã€‚*****

******CNN çš„*è§£å†³äº†ä¸€ä¸ªå…·ä½“é—®é¢˜:å¦‚ä½•ä» 3D çŸ©é˜µä¸­æå–ç‰¹å¾ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„æ•°æ®ç»“æ„ã€‚ä¸»è¦æ€æƒ³æ˜¯ç®—æ³•å­¦ä¹ å¦‚ä½•ç”¨ä¸€ä¸ªæ•°å­¦å…¬å¼(å³å‡å€¼)æ¥æ¦‚æ‹¬ä¸€ç»„åƒç´ ï¼Œè€Œä¸æ˜¯åšæ‰‹å·¥çš„ç‰¹å¾å·¥ç¨‹ã€‚*****

****![](img/21ed1e0cb131d223a2dd9892ae856fe5.png)****

****[æ¥æº](https://miro.medium.com/max/2340/1*Fw-ehcNBR9byHtho-Rxbtw.gif)****

****è¿™æ ·ï¼Œç»´æ•°é€æ¸å‡å°‘ï¼Œç›´åˆ°æ¯ä¸ªå›¾åƒç”±å•ä¸ªç‰¹å¾å‘é‡è¡¨ç¤ºã€‚****

****![](img/ea23d1a0223f046eb0e468f4e2a8b0e8.png)****

****[æ¥æº](https://www.domsoria.com/2019/10/come-funziona-una-rete-neurale-cnn-convolutional-neural-network/)****

****æˆ‘å‡†å¤‡ä»é›¶å¼€å§‹è®­ç»ƒä¸€ä¸ªåŸºæœ¬çš„*CNN*(2 å±‚ [*å·ç§¯*](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) + [*æ± åŒ–*](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) )ä½œä¸ºå…¶ä»–æ¨¡å‹çš„åŸºçº¿ã€‚æˆ‘å°†ä½¿ç”¨*tensor flow*/*Keras:*ä¸­çš„ [*æ¨¡å‹*](https://www.tensorflow.org/api_docs/python/tf/keras/Model) ç±»****

```
*****## Input***
x_in = layers.Input(name="x_in", shape=(500,500,3))

***## Conv + MaxPool***
x_conv2d = layers.**Conv2D**(name="x_conv2d", filters=32, kernel_size=(3,3), activation="relu")(x_in)
x_maxpool = layers.**MaxPooling2D**(name='x_maxpool', pool_size=(2,2))(x_conv2d)

***## Conv + MaxPool***
x_conv2d2 = layers.**Conv2D**(name="x_conv2d2", filters=32, kernel_size=(3,3), activation="relu")(x_maxpool)
x_maxpool2 = layers.**MaxPooling2D**(name='x_maxpool2', pool_size=(2,2))(x_conv2d2)

***## Flat + Dense***
flat = layers.**Flatten**(name="flat")(x_maxpool2)
dense = layers.**Dense**(name="dense", units=128, activation='relu')(flat)

***## Output***
y_out = layers.**Dense**(name="y_out", units=n_classes, activation="softmax")(dense) ***#if binary -> 1 neuron & sigmoid***

***## Compile***
model = models.**Model**(inputs=x_in, outputs=y_out, name="CNN")
model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"]) ***#if binary -> binary_crossentropy loss***model.summary()**
```

****![](img/7cad8294c9b74f0ec3410a2fd5e6f900.png)****

****ä½œè€…å›¾ç‰‡****

****å¦‚æœæ‚¨æƒ³è¦æ£€æŸ¥å›¾åƒåœ¨æ¯ä¸€å±‚ä¸­ç»å†äº†ä»€ä¹ˆæ ·çš„å˜æ¢ï¼Œæ‚¨å¯ä»¥åƒè¿™æ ·å°†å…¶å¯è§†åŒ–(è€ƒè™‘åˆ°è¿™äº›å±‚ä»ç„¶æ˜¯éšæœºçš„ï¼Œå› ä¸ºæ¨¡å‹è¿˜æ²¡æœ‰è¢«è®­ç»ƒ):****

```
*****## check layers***
x = X_train[0]
convx = model.layers[1](x)
maxpx = model.layers[2](convx)
convx2 = model.layers[3](maxpx)
maxpx2 = model.layers[4](convx2)

print("shape:", maxpx2.shape[1:])

plot_imgs([x[0], convx[0][:,:,24:27], maxpx[0][:,:,22:25], 
          convx2[0][:,:,10:13], maxpx2[0][:,:,13:16]], 
          ["input","conv2d","maxpool","2nd conv2d","2nd maxpool"])**
```

****![](img/f3f1bd7d7fe7576d10a68448df287c41.png)****

****ä½œè€…å›¾ç‰‡****

****æˆ‘ä»¬å¯ä»¥**è®­ç»ƒæ¨¡å‹**ï¼Œå¹¶åœ¨å®é™…æµ‹è¯•é›†ä¸Šæµ‹è¯•ä¹‹å‰ï¼Œæ£€æŸ¥ç”¨äºéªŒè¯çš„è®­ç»ƒé›†å­é›†çš„æ€§èƒ½ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½æ¥å¯è§†åŒ–åŸ¹è®­:****

```
*****## Train***
training = model.fit(x=X_train, y=y_train, 
                     epochs=100, batch_size=64, shuffle=True, 
                     verbose=0, validation_split=0.2,
                     callbacks=[callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)])model = training.model
**utils_plot_training**(training)**
```

****![](img/d37ba092cf99b00993756c5ae7bab07e.png)****

****ä½œè€…å›¾ç‰‡****

****è¯·æ³¨æ„ï¼Œæˆ‘åœ¨å›è°ƒä¸­ä½¿ç”¨äº† [*æå‰åœæ­¢*](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) å·¥å…·ï¼Œå½“å—ç›‘æ§çš„æŒ‡æ ‡(å³éªŒè¯æŸå¤±)åœæ­¢æ”¹å–„æ—¶ï¼Œè¯¥å·¥å…·å°†ç»ˆæ­¢åŸ¹è®­ã€‚****

****è®©æˆ‘ä»¬**æµ‹è¯•**è¿™ä¸ªæ¨¡å‹:****

```
*****## Test***
predicted_prob = model.predict(X_test)
predicted = [np.argmax(pred) for pred in predicted_prob]**
```

****ä¸ºäº†**è¯„ä¼°**CNN çš„è¡¨ç°ï¼Œæˆ‘å°†ä½¿ç”¨ä»¥ä¸‹æŒ‡æ ‡:****

*   *****å‡†ç¡®æ€§*:æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹ã€‚****
*   *****æ··æ·†çŸ©é˜µ*:ä¸€ä¸ªæ±‡æ€»è¡¨ï¼ŒæŒ‰ç±»åˆ«ç»†åˆ†äº†æ­£ç¡®å’Œé”™è¯¯é¢„æµ‹çš„æ•°é‡ã€‚****
*   *****ROC* :å›¾ç¤ºåœ¨å„ç§é˜ˆå€¼è®¾ç½®ä¸‹çš„çœŸé˜³æ€§ç‡å¯¹å‡é˜³æ€§ç‡çš„æ›²çº¿å›¾ã€‚æ›²çº¿ä¸‹çš„é¢ç§¯( *AUC* )è¡¨ç¤ºåˆ†ç±»å™¨å°†éšæœºé€‰æ‹©çš„é˜³æ€§è§‚å¯Ÿå€¼æ’åºé«˜äºéšæœºé€‰æ‹©çš„é˜´æ€§è§‚å¯Ÿå€¼çš„æ¦‚ç‡ã€‚****
*   *****ç²¾åº¦*:ç›¸å…³å®ä¾‹åœ¨æ£€ç´¢åˆ°çš„å®ä¾‹ä¸­æ‰€å çš„æ¯”ä¾‹ã€‚****
*   *****Recall:* å®é™…æ£€ç´¢åˆ°çš„ç›¸å…³å®ä¾‹æ€»æ•°çš„ä¸€éƒ¨åˆ†ã€‚****

```
**evaluate_multi_classif(y_test, predicted, predicted_prob, figsize=(15,5))**
```

****![](img/ecbcd950182f167f60b63e5bb0ff6d8a.png)****

****ä½œè€…å›¾ç‰‡****

****ä¸æ˜¯å¾ˆå¥½ï¼Œå®ƒæœ‰å¾ˆå¤šæƒ…å†µï¼Œä½†æ˜¯ä¹Ÿæœ‰å¾ˆå¤šé”™è¯¯ï¼Œç‰¹åˆ«æ˜¯å¯¹äºç±» 3 å’Œç±» 4ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœ€å¥½ç†è§£æ¨¡å‹ä¸ºä»€ä¹ˆç”¨æŸä¸ªæ ‡ç­¾å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»ï¼Œå¹¶è¯„ä¼°é¢„æµ‹çš„**å¯è§£é‡Šæ€§**ã€‚ [*çŸ³ç°*åŒ…](https://github.com/marcotcr/lime)å¯ä»¥å¸®åŠ©æˆ‘ä»¬å»ºç«‹ä¸€ä¸ªè§£é‡Šå™¨ã€‚ä¸ºäº†ä¸¾ä¾‹è¯´æ˜ï¼Œæˆ‘å°†ä»æµ‹è¯•é›†ä¸­éšæœºè§‚å¯Ÿï¼Œçœ‹çœ‹æ¨¡å‹é¢„æµ‹äº†ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆã€‚****

```
*****## img instance*** i = 10
img_instance = X_test[i]***## explain*** explainer = **lime_image**.LimeImageExplainer()
explained = explainer.explain_instance(img_instance, model.predict, num_samples=1000)***## visualize*** fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))
ax[0].imshow(img_instance)
temp, mask = explained.get_image_and_mask(explained.top_labels[0], positive_only=False, hide_rest=False)
ax[1].imshow(segmentation.mark_boundaries(temp/2+0.5, mask))
plt.show()**
```

****![](img/97226c94440fcff3f998379d344f8bd3.png)****

****ä½œè€…å›¾ç‰‡****

****æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¯¥æ¨¡å‹æ²¡æœ‰ä½¿ç”¨æ­£ç¡®çš„ç‰¹å¾(å³ç‹—çš„åƒç´ )ï¼Œå› æ­¤å®ƒå˜å¾—æ··ä¹±ï¼Œä¸»è¦åŸå› æ˜¯æ•°æ®é›†å¯¹äºè®¡ç®—æœºè§†è§‰ç”¨ä¾‹æ¥è¯´ä¸å¤Ÿå¤§ã€‚****

****æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜:æ•°æ®æ‰©å……å’Œè¿ç§»å­¦ä¹ ã€‚ [**æ•°æ®æ‰©å……**](https://en.wikipedia.org/wiki/Data_augmentation) æ˜¯ä¸€ç§é€šè¿‡æ·»åŠ å¯¹å·²æœ‰å›¾åƒç¨åŠ ä¿®æ”¹çš„å‰¯æœ¬æ¥å¢åŠ æ•°æ®é‡çš„æŠ€æœ¯ã€‚å®ƒå……å½“æ­£åˆ™åŒ–å™¨ï¼Œæœ‰åŠ©äºåœ¨è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹æ—¶å‡å°‘è¿‡æ‹Ÿåˆã€‚ä½¿ç”¨ *TensorFlow:* å¯ä»¥è½»æ¾è®¾ç½®æ•°æ®æ‰©å……****

```
**data_augmentation = models.Sequential(name="data_augmentation", layers=[
    layers.**RandomFlip**("horizontal_and_vertical"),
    layers.**RandomRotation**(factor=0.2),
    layers.**RandomZoom**(height_factor=0.2, width_factor=0.2)
])***## try one***
plot_imgs([X_train[0], **data_augmentation**(X_train[0])], ["original","augmented"])**
```

****![](img/3e30187901b5302cb9afbd3a804e845d.png)****

****ä½œè€…å›¾ç‰‡****

****æ•°æ®æ‰©å……å¯åœ¨è®­ç»ƒå‰åº”ç”¨äºæ•°æ®é›†ï¼Œæˆ–ä½œä¸ºå›¾å±‚æ·»åŠ åˆ°æ¨¡å‹ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤º:****

```
***## Input*
x_in = layers.Input(name="x_in", shape=(500,500,3))***## Data Augmentation*
*x_augm = data_augmentation(x_in)****## Conv + MaxPool*
x_conv2d = layers.Conv2D(name="x_conv2d", filters=32, kernel_size=(3,3), activation="relu")(***x_augm***)
x_maxpool = layers.MaxPooling2D(name='x_maxpool', pool_size=(2,2))(x_conv2d)

*## Conv + MaxPool*
x_conv2d2 = layers.Conv2D(name="x_conv2d2", filters=32, kernel_size=(3,3), activation="relu")(x_maxpool)
x_maxpool2 = layers.MaxPooling2D(name='x_maxpool2', pool_size=(2,2))(x_conv2d2)

*## Flat + Dense*
flat = layers.Flatten(name="flat")(x_maxpool2)
dense = layers.Dense(name="dense", units=128, activation='relu')(flat)

*## Output*
y_out = layers.Dense(name="y_out", units=n_classes, activation="softmax")(dense)*## Compile*
model = models.Model(inputs=x_in, outputs=y_out, name="CNN")
model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])**
```

****è¯·æ³¨æ„ï¼Œå°†å®ƒä½œä¸ºæ¨¡å‹ä¸­çš„ä¸€ä¸ªå±‚ä¸ä¼šå¢åŠ è§‚å¯Ÿçš„æ•°é‡ï¼Œå®ƒåªæ˜¯åœ¨æ¯ä¸ªæ—¶æœŸéšæœºä¿®æ”¹å›¾åƒä»¥å‡å°‘è¿‡åº¦æ‹Ÿåˆã€‚****

****æˆ–è€…ï¼Œäººä»¬å¯ä»¥ä½¿ç”¨è¿ç§»å­¦ä¹ ã€‚****

## ****è¿ç§»å­¦ä¹ ****

****ç®€è€Œè¨€ä¹‹ï¼Œ[è¿ç§»å­¦ä¹ ](https://en.wikipedia.org/wiki/Transfer_learning)æ„å‘³ç€é‡‡ç”¨ä¸€ä¸ªå·²ç»åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¹¶ä½¿å…¶é€‚åº”æ‚¨çš„ç”¨ä¾‹ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘å°†é€‰æ‹©ä¸€ä¸ªå·²ç»å¯ä»¥è¯†åˆ«ç‹—çš„æ¨¡å‹ï¼Œå¹¶æ ¹æ®ç‹—çš„å“ç§(æˆ‘çš„æ ‡ç­¾)å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚æ˜¾ç„¶ï¼Œæ•°æ®é›†è¶Šç›¸ä¼¼ï¼Œè¿ç§»å­¦ä¹ å°±è¶Šæœ‰æ•ˆâ€¦â€¦ç”¨ä¸€ä¸ªåœ¨æ±½è½¦ä¸Šè®­ç»ƒè¿‡çš„æ¨¡å‹å¯¹åŠ¨ç‰©è¿›è¡Œåˆ†ç±»æ˜¯è¡Œä¸é€šçš„ã€‚****

****æˆ‘å°†ä½¿ç”¨[***vgg 16***](https://arxiv.org/abs/1409.1556)*ä¸€ä¸ª 16 å±‚çš„æ·±åº¦ *CNN* å¯¹æ¥è‡ª [*ImageNet* æ•°æ®åº“](https://www.image-net.org/)çš„ 100 å¤šä¸‡å¼ å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œä»¥è¯†åˆ«æˆåƒä¸Šä¸‡çš„ç‰©ä½“å’ŒåŠ¨ç‰©ã€‚æ‰€ä»¥è®¡åˆ’æ˜¯è¿™æ ·çš„:åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå®ƒä¸ä¼šè¢«é‡æ–°è®­ç»ƒï¼Œæ²¡æœ‰æœ€ç»ˆå±‚ï¼Œå¹¶ç”¨ä¸€äº›æ–°çš„æœ€ç»ˆå±‚æ›¿æ¢å®ƒçš„å¤´éƒ¨ï¼Œè¿™äº›æœ€ç»ˆå±‚å°†å­¦ä¹ å¦‚ä½•é¢„æµ‹æˆ‘çš„ç›®æ ‡ã€‚*****

****![](img/2a453bc8d6f6af69da047651dc03cd8f.png)****

****ä½œè€…å›¾ç‰‡****

****å¯¹äºè¿™ä¸ªå°æ“ä½œï¼Œæˆ‘å°†ä½¿ç”¨ [*åºåˆ—*](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) ç±»ï¼Œå› ä¸ºå®ƒå¯ä»¥è‡ªåŠ¨å¤„ç†å¼ é‡å½¢çŠ¶çš„å·®å¼‚ï¼Œä»è€Œç®€åŒ–åˆ†ç¦»æ¨¡å‹çš„åˆå¹¶ã€‚****

```
**from **tensorflow.keras.applications** import **vgg16*****## Load pre-trained*** base = vgg16.VGG16(weights="imagenet", include_top=False, 
                   input_shape=(500,500,3))
base.trainable = False***## Add new head***model = models.Sequential(name="TransferLearning", layers=[
    base,
    layers.Flatten(name="flat"),
    layers.Dense(name="dense", units=128, activation='relu'),
    layers.Dense(name="y_out", units=n_classes, activation="softmax")
])

model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
model.summary()**
```

****![](img/6d19a5d1bbd6a6cdfbf2a23eee51bcb4.png)****

****ä½œè€…å›¾ç‰‡****

****é€šè¿‡ä½¿ç”¨ç›¸åŒçš„ä»£ç è¿›è¡Œè®­ç»ƒã€æµ‹è¯•å’Œè¯„ä¼°ï¼Œæˆ‘ä»¬è¿™æ¬¡å¾—åˆ°äº†æ›´å¥½çš„ç»“æœ(*ç²¾ç¡®åº¦*ä¸º 0.7ï¼Œè¯¦æƒ…è¯·è§ç¬”è®°æœ¬)ã€‚æ­¤å¤–ï¼Œæ„Ÿè°¢ *lime* è®²è§£å™¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸ªæ¨¡å‹çŸ¥é“å®ƒåœ¨åšä»€ä¹ˆ:****

****![](img/f63452eef178ae1bbbd4230bd54b045f.png)****

****ä½œè€…å›¾ç‰‡****

## ****å˜å½¢é‡‘åˆš(ç”µå½±å)****

****[*å˜å½¢é‡‘åˆš*](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) æ˜¯ Google çš„è®ºæ–‡ [*æå‡ºçš„ä¸€ç§æ–°çš„å»ºæ¨¡æŠ€æœ¯*](https://arxiv.org/abs/1706.03762)*ã€2017ã€‘*ï¼Œå…¶ä¸­è®ºè¯äº†ç»å…¸çš„æ·±åº¦ç¥ç»ç½‘ç»œå®Œå…¨å¯ä»¥è¢«[æ³¨æ„åŠ›æœºåˆ¶](https://en.wikipedia.org/wiki/Attention_(machine_learning))æ‰€å–ä»£ï¼Œç”šè‡³è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚è™½ç„¶å®ƒä»¬å·²ç»è¿…é€Ÿæ¥ç®¡äº† NLP é¢†åŸŸï¼Œä½†æ˜¯å¯¹ CV çš„åº”ç”¨ä»ç„¶æœ‰é™ã€‚******

*****2020 å¹´ï¼Œæå‡ºäº† [*è§†è§‰è½¬æ¢å™¨* ( *ViT* )](https://github.com/google-research/vision_transformer) ï¼Œè¿™æ˜¯ä¸€ç§å°†æ–‡å­—åµŒå…¥åº”ç”¨äºå›¾åƒçš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯åƒ *CNN* é‚£æ ·ä½¿ç”¨åƒç´ é˜µåˆ—ã€‚åŸºæœ¬ä¸Šï¼Œè¾“å…¥å›¾åƒè¢«åˆ†è§£æˆå›ºå®šå¤§å°çš„å°å—(æˆ–æ‰å¹³çš„åƒç´ ç»„)ï¼Œå°±åƒä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼Œç„¶åæ¯ä¸ªå°å—è¢«åµŒå…¥å¹¶ä¼ é€’ç»™å…³æ³¨å±‚(ç¼–ç å™¨)ã€‚è¿™ç§æ¶æ„å…è®¸æ¨¡å‹å­¦ä¹ å±€éƒ¨ç‰¹å¾ä»¥åŠé‡å»ºå›¾åƒçš„å®Œæ•´ç»“æ„ã€‚*****

****![](img/5adabce73ca15cebd40f2917f476eee5.png)****

****ä½œè€…å›¾ç‰‡****

****è¿™äº›æ¨¡å‹çš„ä¸»åº“æ˜¯ [*å˜å½¢é‡‘åˆš*](https://huggingface.co/transformers/) by [æ‹¥æŠ±è„¸](https://huggingface.co/):****

```
*****## Load model*** model_name = "**google/vit-base-patch16-224-in21k**"

prep = transformers.AutoFeatureExtractor.from_pretrained(model_name)
vit = transformers.TFAutoModel.from_pretrained(model_name)**
```

****é€šå¸¸ï¼Œæ¯ä¸ªå˜å½¢é‡‘åˆšæ¨¡å‹éƒ½æœ‰è‡ªå·±çš„é¢„å¤„ç†å™¨ã€‚äº‹å®ä¸Šï¼Œå¦‚æœæ‚¨æ‰“å° *prep* å¯¹è±¡ï¼Œæ‚¨ä¼šçœ‹åˆ° *ViT* éœ€è¦ä¸€äº›è§„èŒƒåŒ–å’Œè°ƒæ•´å¤§å°:****

****![](img/6d13391ab7bfcbded9634581caf0cc01.png)****

****ä½œè€…å›¾ç‰‡****

****è®©æˆ‘ä»¬è¿™æ ·åš:****

```
*****# Preprocess*** X_train_vit = np.array([prep(img)["pixel_values"][0] for img in X_train])
X_test_vit = np.array([prep(img)["pixel_values"][0] for img in X_test])

print(X_train_vit[0].shape)**
```

****æ–°çš„å½¢çŠ¶æ˜¯ *(3ï¼Œ224ï¼Œ224)* ã€‚è¿™æ„å‘³ç€ RGB é€šé“æ˜¯ç¬¬ä¸€ç»´åº¦ï¼Œå›¾åƒéœ€è¦ä¸º *224x224ã€‚*****

```
*****# Model***
x_in = layers.Input(name="x_in", shape=(3,224,224))vit_out = vit(x_in)[0][:,0,:]y_out = layers.Dense(name="y_out", units=n_classes, 
                     activation="softmax")(vit_out)

model = models.Model(inputs=x_in, outputs=y_out, name="ViT")model.compile(loss="sparse_categorical_crossentropy", 
              optimizer="adam", metrics=["accuracy"])model.summary()**
```

****![](img/91c4bb0be2fa9edff46dc75c139c7654.png)****

****ä½œè€…å›¾ç‰‡****

****æ‚¨å¯ä»¥ä½¿ç”¨ä¸ä¹‹å‰ç›¸åŒçš„ä»£ç æ¥è®­ç»ƒã€æµ‹è¯•å’Œè¯„ä¼°æ¨¡å‹ã€‚ä¸å¹¸çš„æ˜¯ï¼Œå¯¹äº *ViT* è¦æ±‚çš„è¾“å…¥å½¢çŠ¶ï¼Œä¸å¯èƒ½ä½¿ç”¨ *lime* è§£é‡Šå™¨ã€‚****

## ****ç»“è®º****

****è¿™ç¯‡æ–‡ç« æ˜¯ä¸€ä¸ªæ•™ç¨‹ï¼Œæ¼”ç¤ºå¦‚ä½•åº”ç”¨ä¸åŒçš„è®¡ç®—æœºè§†è§‰æ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚æˆ‘æ¯”è¾ƒäº† 3 ç§æ–¹æ³•: *CNN* ä»å¤´å¼€å§‹ï¼Œä»ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„ *CNN (VGG16)* è¿ç§»å­¦ä¹ ï¼Œä»¥åŠå›¾åƒçš„å‰æ²¿å˜å½¢é‡‘åˆš( *ViT* )ã€‚æˆ‘ç»å†äº†æ•°æ®åˆ†æã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ•°æ®æ‰©å……ã€è¯„ä¼°å’Œå¯è§£é‡Šæ€§ã€‚****

****æˆ‘å¸Œæœ›ä½ å–œæ¬¢å®ƒï¼å¦‚æœ‰é—®é¢˜å’Œåé¦ˆï¼Œæˆ–è€…åªæ˜¯åˆ†äº«æ‚¨æ„Ÿå…´è¶£çš„é¡¹ç›®ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ã€‚****

> ****ğŸ‘‰[æˆ‘ä»¬æ¥è¿çº¿](https://linktr.ee/maurodp)ğŸ‘ˆ****

> ****æœ¬æ–‡æ˜¯ Python ç³»åˆ— **CV çš„ä¸€éƒ¨åˆ†ï¼Œå‚è§:******

****[](https://towardsdatascience.com/how-to-detect-objects-with-your-webcam-82693c47bd8) [## ç”¨ Python å’Œ YOLO è¿›è¡Œå¯¹è±¡æ£€æµ‹

### ä½¿ç”¨ç½‘ç»œæ‘„åƒå¤´çš„è®¡ç®—æœºè§†è§‰

towardsdatascience.com](https://towardsdatascience.com/how-to-detect-objects-with-your-webcam-82693c47bd8) [](https://towardsdatascience.com/document-parsing-with-python-ocr-75543448e581) [## ä½¿ç”¨ Python å’Œ OCR è¿›è¡Œæ–‡æ¡£è§£æ

### ä½¿ç”¨è®¡ç®—æœºè§†è§‰ä»ä»»ä½•ç±»å‹çš„æ–‡æ¡£ä¸­æ£€æµ‹å’Œæå–æ–‡æœ¬ã€å›¾å½¢ã€è¡¨æ ¼

towardsdatascience.com](https://towardsdatascience.com/document-parsing-with-python-ocr-75543448e581)****