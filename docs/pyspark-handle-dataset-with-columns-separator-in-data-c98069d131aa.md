# æ•°æ®ä¸­å¸¦æœ‰åˆ—åˆ†éš”ç¬¦çš„ Pyspark å¥æŸ„æ•°æ®é›†

> åŸæ–‡ï¼š<https://pub.towardsai.net/pyspark-handle-dataset-with-columns-separator-in-data-c98069d131aa?source=collection_archive---------4----------------------->

## [ç¼–ç¨‹](https://towardsai.net/p/category/programming)

è¿™ç¯‡åšå®¢çš„ç›®çš„æ˜¯å¤„ç†æ•°æ®é›†ä¸­å‡ºç°åˆ—åˆ†éš”ç¬¦æˆ–å®šç•Œç¬¦çš„ç‰¹æ®Šæƒ…å†µã€‚å¯¹äº Pyspark å¼€å‘äººå‘˜æ¥è¯´ï¼Œå¤„ç†è¿™ç§ç±»å‹çš„æ•°æ®é›†æœ‰æ—¶æ˜¯ä¸€ä»¶ä»¤äººå¤´ç–¼çš„äº‹æƒ…ï¼Œä½†æ— è®ºå¦‚ä½•ï¼Œè¿™æ˜¯å¿…é¡»è¦å¤„ç†çš„ã€‚åœ¨æˆ‘çš„åšå®¢ä¸­ï¼Œæˆ‘å°†åˆ†äº«æˆ‘åº”å¯¹æŒ‘æˆ˜çš„æ–¹æ³•ï¼Œæˆ‘ä¹äºå­¦ä¹ ï¼Œæ‰€ä»¥ä¹Ÿè¯·åˆ†äº«ä½ çš„æ–¹æ³•ã€‚

![](img/998934bb933cfa1ec302f8c8e84fb36c.png)

æ¥æº: [PySpark](https://spark.apache.org/docs/latest/api/python/index.html)

æ•°æ®é›†åŸºæœ¬å¦‚ä¸‹å›¾æ‰€ç¤º:

```
#first line is the headerNAME|AGE|DEP
Vivek|Chaudhary|32|BSC
John|Morgan|30|BE
Ashwin|Rao|30|BE
```

æ•°æ®é›†åŒ…å«ç”±åˆ†éš”ç¬¦â€œ|â€åˆ†éš”çš„ä¸‰åˆ—**ã€ã€å§“åã€‘ã€ã€å¹´é¾„ã€‘ã€**ã€‚å¦‚æœæˆ‘ä»¬å…³æ³¨æ•°æ®é›†ï¼Œå®ƒè¿˜åŒ…å«â€œ|â€ä½œä¸ºåˆ—å**ã€‚**

è®©æˆ‘ä»¬è¿›ä¸€æ­¥çœ‹çœ‹å¦‚ä½•è¿›è¡Œç›¸åŒçš„æ“ä½œ:

**æ­¥éª¤ 1ã€‚ä½¿ç”¨ spark çš„ read.csv()æ–¹æ³•è¯»å–æ•°æ®é›†:**

```
#create spark session import pyspark
from pyspark.sql import SparkSession
spark=SparkSession.builder.appName(â€˜delimitâ€™).getOrCreate()
```

ä¸Šé¢çš„å‘½ä»¤å¸®åŠ©æˆ‘ä»¬è¿æ¥åˆ° spark ç¯å¢ƒï¼Œå¹¶è®©æˆ‘ä»¬ä½¿ç”¨ spark.read.csv()è¯»å–æ•°æ®é›†

```
#create dataframedf=spark.read.option(â€˜delimiterâ€™,â€™|â€™).csv(râ€™<path>\delimit_data.txtâ€™,inferSchema=True,header=True)df.show()
```

![](img/166d9bbb99523d20dbd27b149193e87b.png)

ä»æ–‡ä»¶ä¸­è¯»å–æ•°æ®å¹¶å°†æ•°æ®æ”¾å…¥å†…å­˜åï¼Œå®ƒçœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ã€‚ä½†æ˜¯ç­‰ç­‰ï¼Œæœ€åä¸€åˆ—æ•°æ®åœ¨å“ªé‡Œï¼Œåˆ—**å¹´é¾„**å¿…é¡»æœ‰ä¸€ä¸ªæ•´æ•°æ•°æ®ç±»å‹ï¼Œä½†æ˜¯æˆ‘ä»¬çœ‹åˆ°äº†åˆ«çš„ä¸œè¥¿ã€‚è¿™ä¸æ˜¯æˆ‘ä»¬æ‰€æœŸæœ›çš„ã€‚ä¹±ä¸ƒå…«ç³Ÿå®Œå…¨ä¸åŒ¹é…ï¼Œä¸æ˜¯å—ï¼Ÿç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œä¸€å›¢ç³Ÿã€‚è®©æˆ‘æƒ³èµ·ç¢§ç¢§Â·é›·å…‹è¨çš„æ­Œã€Šæˆ‘ä¸€å›¢ç³Ÿã€‹ğŸ˜‚ğŸ˜‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

**æ­¥éª¤ 2ã€‚å†æ¬¡è¯»å–æ•°æ®ï¼Œä½†è¿™æ¬¡ä½¿ç”¨ read.text()æ–¹æ³•:**

```
df=spark.read.text(râ€™C:\Users\lenovo\Python_Pyspark_Corp_Training\delimit_data.txtâ€™)
df.show(truncate=0)
```

![](img/60e8f422b82d0672c45789881352a783.png)

```
#extract first row as this is our header
head=df.first()[0]schema=[â€˜fnameâ€™,â€™lnameâ€™,â€™ageâ€™,â€™depâ€™]
print(schema)Output: ['fname', 'lname', 'age', 'dep']
```

ä¸‹ä¸€æ­¥æ˜¯æ ¹æ®åˆ—åˆ†éš”ç¬¦åˆ†å‰²æ•°æ®é›†:

```
#filter the header, separate the columns and apply the schema
df_new=df.filter(df[â€˜valueâ€™]!=head).rdd.map(lambda x:x[0].split(â€˜|â€™)).toDF(schema)
df_new.show()
```

![](img/560d3717f9b81907eefaaa6a32a7c84e.png)

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»æˆåŠŸåˆ†ç¦»å‡ºäº†**èŒæ ª**ã€‚ç­‰ç­‰ä»€ä¹ˆ**åº”å˜**ï¼Ÿä¸ï¼Œä¼™è®¡ï¼Œè¿™ä¸æ˜¯ç”µæ™•ç—…æ¯’ï¼Œè¿™åªæ˜¯æ–‡æœ¬æ•°æ®ã€‚ç•™ç€å§ï¼Œç®€å•çš„ä¼™ä¼´ã€‚ğŸ˜œğŸ˜œ

æˆ‘ä»¬å·²ç»æˆåŠŸåœ°å°†ç®¡é“â€œ|â€åˆ†éš”çš„åˆ—(â€œåç§°â€)æ•°æ®åˆ†æˆä¸¤åˆ—ã€‚ç°åœ¨æ•°æ®æ›´åŠ å¹²å‡€ï¼Œå¯ä»¥è½»æ¾æ’­æ”¾ã€‚

æ¥ä¸‹æ¥ï¼Œè¿æ¥åˆ—**â€œfnameâ€**å’Œ**â€œlnameâ€**:

```
from pyspark.sql.functions import concat, col, lit
df1=df_new.withColumn(â€˜fullnameâ€™,concat(col(â€˜fnameâ€™),lit(â€œ|â€),col(â€˜lnameâ€™)))
df1.show()
```

![](img/62d4653883262b46980d34a768611650.png)

ä¸ºäº†éªŒè¯æ•°æ®è½¬æ¢ï¼Œæˆ‘ä»¬å°†æŠŠè½¬æ¢åçš„æ•°æ®é›†å†™å…¥ä¸€ä¸ª CSV æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨ **read.csv()** æ–¹æ³•è¯»å–å®ƒã€‚

```
df1.write.option(â€˜sepâ€™,â€™|â€™).mode(â€˜overwriteâ€™).option(â€˜headerâ€™,â€™trueâ€™).csv(râ€™<*file_path*>\cust_sep.csvâ€™)
```

**ä¸‹ä¸€æ­¥æ˜¯æ•°æ®éªŒè¯:**

```
df=spark.read.option(â€˜delimiterâ€™,â€™|â€™).csv(r<*filepath*>,inferSchema=True,header=True)
df.show()
```

![](img/9bd3e0d23fc68368616ecf5f25993f25.png)

æ•°æ®ç°åœ¨çœ‹èµ·æ¥ç¬¦åˆæˆ‘ä»¬çš„è¦æ±‚ã€‚ä¸€ä¸ªå°ç»ƒä¹ ï¼Œå°è¯•ä½¿ç”¨ä¸åŒçš„åˆ†éš”ç¬¦ï¼Œå¦‚æœå‘ç°ä»»ä½•å¼‚å¸¸ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚è¿™ä¸ªåšå®¢åˆ°æ­¤ä¸ºæ­¢ã€‚ä¸‹æ¬¡ä¼šæœ‰ä¸åŒçš„åœºæ™¯ã€‚

æ„Ÿè°¢å¤§å®¶é˜…è¯»æˆ‘çš„åšå®¢ã€‚è¯·åˆ†äº«æ‚¨çš„è§‚ç‚¹æˆ–åé¦ˆã€‚