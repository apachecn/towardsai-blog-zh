# CLIP(å¯¹æ¯”è¯­è¨€â€”å›¾åƒé¢„è®­ç»ƒ)æ˜¯ä»€ä¹ˆï¼Œå¦‚ä½•ç”¨äºè¯­ä¹‰å›¾åƒæœç´¢ï¼Ÿ

> åŸæ–‡ï¼š<https://pub.towardsai.net/what-is-clip-contrastive-language-image-pre-training-and-how-it-can-be-used-for-semantic-image-b02ccf49414e?source=collection_archive---------0----------------------->

## [è®¡ç®—æœºè§†è§‰](https://towardsai.net/p/category/computer-vision)

## æ·±åº¦å­¦ä¹ æœç´¢å›¾åƒçš„æ–¹æ³•

![](img/2addf57e184359ae01d7cb98d8ff5c4d.png)

ç”±[ç›åˆ©äºšÂ·ç‰¹å†…å¨ƒ](https://unsplash.com/@miteneva?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)åœ¨ [Unsplash](https://unsplash.com/s/photos/deep-learning?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

æœ€è¿‘ï¼ŒOpenAI çš„ç ”ç©¶äººå‘˜å‘è¡¨äº†ä¸€ç§å¤šæ¨¡æ€æ¶æ„ï¼Œä¸€æ—¦åœ¨å¤§çº¦ 4 äº¿ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå°±å¯ä»¥ç”¨äº 30 ç§ä¸åŒçš„ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•å¹¶ä¸æ–°é²œï¼Œä»¥å‰è®¸å¤šå…¶ä»–ç ”ç©¶äººå‘˜è¯•å›¾ä½¿ç”¨æ–‡æœ¬è½¬æ¢å™¨å’Œé¢„è®­ç»ƒ CNN æ¨¡å‹çš„ç»„åˆæ¥é¢„è®­ç»ƒå›¾åƒ-æ–‡æœ¬å¯¹çš„æ¨¡å‹ï¼Œç„¶åå°†å…¶ç”¨äºä¸åŒçš„å‘ä¸‹ä»»åŠ¡ã€‚ä½†æ˜¯ç”±äºç§ç§åŸå› ï¼Œè¿™äº›æ–¹æ³•å¹¶ä¸åƒåœ¨[è®ºæ–‡](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)ä¸­è®¨è®ºçš„é‚£æ ·æˆåŠŸã€‚å°è¯•äº†å„ç§é¢„è®­ç»ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬é¢„æµ‹å’Œå¯¹æ¯”ï¼›åœ¨ä¸åŒçš„å‘ä¸‹ä»»åŠ¡ä¸­è¾¾åˆ° SOTA æ°´å¹³çš„ç²¾ç¡®åº¦ã€‚åœ¨é¢„æµ‹æ–¹æ³•ä¸­ï¼Œè®­ç»ƒå¤šæ¨¡æ€æ¶æ„æ¥åŸºäºå›¾åƒé¢„æµ‹å­—å¹•ã€‚ä½†è¿™ç§æ–¹æ³•åœ¨å‘ä¸‹çš„ä»»åŠ¡ä¸­å¹¶ä¸å¥æ•ˆï¼Œå› ä¸ºæ¨¡å‹è¯•å›¾åŒ¹é…æ–‡æœ¬ä¸­çš„ç²¾ç¡®å•è¯ã€‚å› æ­¤ï¼Œä½¿ç”¨å¯¹æ¯”æ–¹æ³•é€šè¿‡è”åˆè®­ç»ƒå›¾åƒç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨æ¥ä»å¤šæ¨¡æ€è¡¨ç¤ºä¸­å­¦ä¹ ï¼Œä»¥æœ€å¤§åŒ–æ­£ç¡®(å›¾åƒ-æ–‡æœ¬)å¯¹ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œå¹¶æœ€å°åŒ–ä¸æ­£ç¡®(å›¾åƒ-æ–‡æœ¬)å¯¹ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼æ€§ã€‚

![](img/98334f5848aaa1f9664854fd9ab4cccf.png)

æ¥æº:[å›å½¢é’ˆ](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)

ç°åœ¨ï¼Œæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨è¿™ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œè¯­ä¹‰å›¾åƒæœç´¢å‘¢ï¼Ÿæˆ‘ä»¬æœ‰ä¸€ä¸ªå›¾åƒæŸ¥è¯¢æ–‡æœ¬ T å’Œä¸€å †ä¸åŒçš„å›¾åƒã€‚æ–‡æœ¬ç¼–ç å™¨æä¾›æŸ¥è¯¢æ–‡æœ¬ t çš„æ–‡æœ¬ç‰¹å¾(`Tfeat`)ã€‚ç„¶åï¼Œæˆ‘ä»¬éå†å›¾åƒ Isï¼Œå¹¶ä½¿ç”¨å›¾åƒç¼–ç å™¨ä¸ºæ¯ä¸ªå›¾åƒ I è®¡ç®—å›¾åƒç‰¹å¾(`Ifeat`)ï¼Œå¹¶è®¡ç®—å›¾åƒç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾ä¹‹é—´çš„ç‚¹ç§¯ç›¸ä¼¼åº¦ã€‚ç”±äºé¢„è®­ç»ƒç›®æ ‡æœ€å¤§åŒ–äº†æ­£ç¡®(å›¾åƒã€æ–‡æœ¬)å¯¹çš„ç›¸ä¼¼æ€§å¾—åˆ†ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è®¤ä¸ºæœ€å¤§ç‚¹ç§¯å€¼æ„å‘³ç€æœ€å¤§ç›¸ä¼¼æ€§ã€‚æ‰€ä»¥å¯¹äºæ¯å¼ å›¾ç‰‡ï¼Œæˆ‘ä»¬è®¡ç®—ç‚¹ç§¯ç›¸ä¼¼åº¦ï¼Œç„¶åæŒ‰ç…§åˆ†æ•°é™åºæ’åˆ—ã€‚ä½™å¼¦ç›¸ä¼¼æ€§ä¹Ÿå¯ä»¥ç”¨æ¥è®¡ç®—ç›¸ä¼¼æ€§å¾—åˆ†ï¼Œä½† GPU åœ¨çŸ©é˜µä¹˜æ³•ä¸Šæ›´å¿«ï¼Œå› æ­¤ï¼Œè¿™é‡Œæˆ‘å°†ä½¿ç”¨ç‚¹ç§¯ã€‚è®©æˆ‘ä»¬è¿›å…¥ç¼–ç ã€‚åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Unsplash API ä»æŸ¥è¯¢æ–‡æœ¬ä¸­è·å–å›¾åƒã€‚ä½¿ç”¨æ¥è‡ª Unsplash API çš„æŸ¥è¯¢æ–‡æœ¬å’Œå›¾åƒï¼Œæˆ‘ä»¬å°†æ ¹æ®ä¸Šé¢è®¨è®ºçš„æŠ€æœ¯å¯¹å®ƒä»¬è¿›è¡Œæ’åºã€‚

# ä¸‹è½½å‰ªè¾‘æ¨¡å‹å’ŒåŒ…

```
pip install git+https://github.com/openai/CLIP.git
```

# åŠ è½½æ¨¡å‹å¹¶è®¡ç®—ç›¸ä¼¼æ€§

è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä» **COCO Captions** æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸‰å¼ å›¾ç‰‡ï¼Œå¹¶æä¾›ä¸€ä¸ªæ ‡é¢˜ï¼Œç„¶åæ£€æŸ¥å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

```
import torch
import clip
from PIL import Imageimages = ['391895.png', '522418.png', '318219.png']
text = 'a man with red helmet on a moped'simScore = []
tokenizedText = clip.tokenize(text).to(device)
for img in images:
    image = preprocess(Image.open(os.path.join(path, img))).unsqueeze(0).to(device)
    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(tokenizedText)

		# append image name with similarity score
    simScore.append((img, torch.matmul(text_features, image_features.T)[0][0]))print(simScore)# output
[('391895.png', tensor(21.2141)),
 ('522418.png', tensor(11.7804)),
 ('318219.png', tensor(10.6959))]
```

![](img/2762df0cab87dc5b856ebf3f4d08e4a5.png)![](img/1d9f921c3b7e0a8c5aed5a30ab814500.png)![](img/3b0f286a23b8a09311507b039ec04ee4.png)

æ¥æº:å¯å¯å­—å¹•æ•°æ®é›†(391895.pngï¼Œ391895.png)

# ä½¿ç”¨ Streamlit share éƒ¨ç½²å›¾åƒè¯­ä¹‰æœç´¢åº”ç”¨ç¨‹åº

åœ¨ [Unsplash](https://unsplash.com/join) ä¸Šæ³¨å†Œä¸€ä¸ªå¼€å‘è€…è´¦æˆ·ï¼Œåˆ›å»ºä¸€ä¸ªåº”ç”¨ç¨‹åºå¹¶è·å¾—è®¿é—®å¯†é’¥ã€‚

**åˆ›å»º** `**streamlitcliputils.py**` **æ–‡ä»¶å¹¶è·Ÿéš**

*   å¯¼å…¥å’Œæ¨¡å‹åŠ è½½

```
import torch
import clip
from PIL import Image
import os
import re
from tqdm import tqdm, trange
import random
import requests
import numpy as np
import streamlit as stglobal model, preprocess, devicedevice = 'cpu'model, preprocess = clip.load("ViT-B/32", device = 'cpu')
```

*   ä½¿ç”¨ API ä» Unsplash è·å–åŸºäºæŸ¥è¯¢æ–‡æœ¬çš„å›¾åƒ

```
def getImagesFromUnsplash(total: int, query_text: str):
    '''
    Images from query text
    '''
    num_page = 1
    imgs_total = total
    query = query_text
    url = f"<https://api.unsplash.com/search/photos?query={query_text}&page={num_page}&per_page={imgs_total}>" headers = {
        "Authorization": f"Bearer Client-ID {UPSPLASH_API_KEY}", } req = requests.get(url, headers = headers) resp = req.json() regUrls = [r['urls']['regular'] for r in resp['results']] return regUrls
```

*   å›¾ç‰‡é“¾æ¥åˆ°`PIL.Image`

```
def linkToImage(link):
    '''
    Image URL to PIL.Image
    '''
    content = requests.get(link, stream = True)
    content = content.raw
    img = Image.open(content)
    return img
```

*   è®¡ç®—ç›¸ä¼¼æ€§å¾—åˆ†

```
@st.cache(show_spinner=False)
def getImageTextSimScore(link, text):
    '''
    Compute similarity score from image feature
    and text feature
    '''
    image = preprocess(linkToImage(link)).unsqueeze(0).to(device)
    tokenizedText = clip.tokenize(text).to(device)
    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(tokenizedText)

    simScore = torch.matmul(text_features, image_features.T)[0][0] return simScore.item()
```

*   ä» Unsplash è·å–å›¾åƒå¹¶æ’åº

```
@st.cache(show_spinner=False)
def getSortedQuery(text):
    '''
    Get images from text and sort
    using similarity score
    ''' upSplashImages = getImagesFromUnsplash(10, text)

    imgSimScore = [] for ix, img in enumerate(tqdm(upSplashImages)): imgSimScore.append((img, getImageTextSimScore(img, text)))

    imgSimScore = sorted(imgSimScore, key = lambda x: x[1], reverse=True) return imgSimScore, upSplashImages
```

**åˆ›å»º** `**streamlitapp.py**` **æ–‡ä»¶**

```
from streamlitcliputils import *
import streamlit as st
import io
from PIL import Imagest.set_page_config(
    page_title = 'CLIP',
    page_icon = 'ğŸ‘'
)st.header("CLIP - Semantic Image Search")
imageText = st.text_input("Search Image")if imageText:
    with st.spinner(text = 'Getting Images from Unsplash and sorting with clip ...'):

        imgSimScore, upSplashImages = getSortedQuery(imageText) images = [linkToImage(img) for img, score in imgSimScore]
        simScore = [f'Sim Score: {score:.2f}' for img, score in imgSimScore] upSplashImages = [linkToImage(img) for img in upSplashImages]
        upSplashIx = [i+1 for i in range(len(upSplashImages))] col1, col2 = st.beta_columns(2) col1.header("Semantic Search")
        col1.image(images, width = 300, caption = simScore) col2.header("Images from Unsplash")
        col2.image(upSplashImages, width = 300, caption = upSplashIx)
```

ç°åœ¨ï¼Œè¦ä½¿ç”¨ Streamlit share éƒ¨ç½²åº”ç”¨ç¨‹åºï¼Œæ‚¨éœ€è¦æœ‰ä¸€ä¸ªç»è¿‡æ‰¹å‡†çš„ Streamlit Share å¸æˆ·ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤å¤„æ³¨å†Œä¸€ä¸ªã€‚è¦ä½¿ç”¨ streamlit share éƒ¨ç½²æ‚¨çš„åº”ç”¨ç¨‹åºï¼Œæ‚¨éœ€è¦ä½¿ç”¨ä¸€ä¸ª`requirements.txt`æ–‡ä»¶å°†ä»£ç æ¨é€åˆ° GitHubã€‚

*   å°†åŒ…æ·»åŠ åˆ°`requirements.txt`

```
tqdm==4.56.0
git+https://github.com/openai/CLIP.git
requests==2.25.1
streamlit==0.74.1
torch==1.7.1
numpy==1.20.0rc2
Pillow==8.1.0
```

æ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ª GitHub å­˜å‚¨åº“å¹¶æ¨é€æ‚¨çš„æ–‡ä»¶ã€‚ç„¶åè½¬åˆ° streamlit share æ§åˆ¶å°ï¼Œå•å‡»æ–°åº”ç”¨ç¨‹åºä¸‹æ‹‰èœå•ï¼Œé€‰æ‹©â€œFrom Existing Repoâ€ã€‚

![](img/0e79074c8c390d6c08d36a8243692744.png)

æ¥æº:ä½œè€…

é€‰æ‹© repo åç§°ï¼Œå¹¶åœ¨ä¸»æ–‡ä»¶è·¯å¾„è¾“å…¥ä¸­æä¾›æ–‡ä»¶å

![](img/bf91b4b98040129cb77ad171cb94c3b6.png)

æ¥æº:ä½œè€…

å•å‡»éƒ¨ç½²ï¼Œæ‚¨å°†è¿›å…¥éƒ¨ç½²å±å¹•ï¼Œæ‚¨çš„åº”ç”¨å°†åœ¨å‡ åˆ†é’Ÿå†…å®Œæˆéƒ¨ç½²ã€‚è¯­ä¹‰æœç´¢çš„å®æ—¶ç‰ˆæœ¬å¯ä»[è¿™é‡Œ](https://share.streamlit.io/vatsalsaglani/clipsemanticimagesearch/streamlitClip1/streamlitapp.py)è·å¾—

ä½ å¯ä»¥çœ‹çœ‹è¿™ä¸ªè§†é¢‘ï¼Œçœ‹çœ‹è¿™ä¸ªæ¨¡å‹çš„è¡¨ç°ã€‚

æ¥æº:ä½œè€…

ä½œä¸ºåšå®¢çš„æ€»ç»“ï¼Œæˆ‘ä»¬è®¨è®ºäº† CLIP çš„è®­ç»ƒæ–¹æ³•ä»¥åŠå¦‚ä½•å°†å…¶ç”¨äºè¯­ä¹‰å›¾åƒæœç´¢ï¼Œç„¶åæˆ‘ä»¬ä½¿ç”¨ Unsplash API æ¥æŸ¥è¯¢å›¾åƒï¼Œå¹¶ä½¿ç”¨ä½¿ç”¨ CLIP è®¡ç®—çš„ç›¸ä¼¼æ€§å¾—åˆ†è¿›è¡Œæ’åºã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢çœ‹è¿™ä¸ªåšå®¢ã€‚